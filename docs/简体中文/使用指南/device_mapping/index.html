<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-简体中文/使用指南/device_mapping" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">ROLL 资源配置 | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/docs/简体中文/使用指南/device_mapping"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ROLL 资源配置 | ROLL"><meta data-rh="true" name="description" content="在 ROLL 框架中，资源设置是通过 YAML 配置文件中的 device_mapping 参数来指定每个 worker 使用哪些 GPU 设备。本文档将详细介绍如何配置资源，包括共置和分离模式、多角色资源配置以及 worker 数量的计算方式。"><meta data-rh="true" property="og:description" content="在 ROLL 框架中，资源设置是通过 YAML 配置文件中的 device_mapping 参数来指定每个 worker 使用哪些 GPU 设备。本文档将详细介绍如何配置资源，包括共置和分离模式、多角色资源配置以及 worker 数量的计算方式。"><link data-rh="true" rel="icon" href="/ROLL/img/logo.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/docs/简体中文/使用指南/device_mapping"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/简体中文/使用指南/device_mapping" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/简体中文/使用指南/device_mapping" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ROLL 资源配置","item":"https://alibaba.github.io/ROLL/docs/简体中文/使用指南/device_mapping"}]}</script><link rel="stylesheet" href="/ROLL/assets/css/styles.7a49f82a.css">
<script src="/ROLL/assets/js/runtime~main.a75ba510.js" defer="defer"></script>
<script src="/ROLL/assets/js/main.5c2f734a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"dark"),document.documentElement.setAttribute("data-theme-choice",t||"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbar_MONK"><div class="navbar__inner"><div class="logoWrap_HHlA navbar__items"><div class="logo_Ufb2"><span style="width:40px;height:40px;font-size:18px" class="ant-avatar ant-avatar-circle ant-avatar-image css-10y1chj"><img src="/ROLL/img/logo.png"></span></div><div><div class="title_E_95">ROLL</div><div class="subTitle_M9Ik">like a Reinforcement Learning Algorithm Developer</div></div></div><div class="navbar__items navbar__items--right"><a href="/ROLL/" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Home</span></a><a href="/ROLL/#core" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Core Algorithms</span></a><a href="/ROLL/#research" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Research Community</span></a><a href="/ROLL/docs/English/start" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3 primary_vbUC" tabindex="0" aria-disabled="false"><span>API Docs</span></a><a href="https://github.com/alibaba/ROLL" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Github</span><span role="img" aria-label="export" class="anticon anticon-export"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="export" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 912H144c-17.7 0-32-14.3-32-32V144c0-17.7 14.3-32 32-32h360c4.4 0 8 3.6 8 8v56c0 4.4-3.6 8-8 8H184v656h656V520c0-4.4 3.6-8 8-8h56c4.4 0 8 3.6 8 8v360c0 17.7-14.3 32-32 32zM770.87 199.13l-52.2-52.2a8.01 8.01 0 014.7-13.6l179.4-21c5.1-.6 9.5 3.7 8.9 8.9l-21 179.4c-.8 6.6-8.9 9.4-13.6 4.7l-52.4-52.4-256.2 256.2a8.03 8.03 0 01-11.3 0l-42.4-42.4a8.03 8.03 0 010-11.3l256.1-256.3z"></path></svg></span></a><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div><button type="button" class="ant-btn css-10y1chj ant-btn-text ant-btn-color-default ant-btn-variant-text ant-btn-icon-only" style="margin-left:6px"><span class="ant-btn-icon"><span role="img" aria-label="sun" style="font-size:20px" class="anticon anticon-sun"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="sun" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M548 818v126a16 16 0 01-16 16h-40a16 16 0 01-16-16V818c15.85 1.64 27.84 2.46 36 2.46 8.15 0 20.16-.82 36-2.46m205.25-115.66l89.1 89.1a16 16 0 010 22.62l-28.29 28.29a16 16 0 01-22.62 0l-89.1-89.1c12.37-10.04 21.43-17.95 27.2-23.71 5.76-5.77 13.67-14.84 23.71-27.2m-482.5 0c10.04 12.36 17.95 21.43 23.71 27.2 5.77 5.76 14.84 13.67 27.2 23.71l-89.1 89.1a16 16 0 01-22.62 0l-28.29-28.29a16 16 0 010-22.63zM512 278c129.24 0 234 104.77 234 234S641.24 746 512 746 278 641.24 278 512s104.77-234 234-234m0 72c-89.47 0-162 72.53-162 162s72.53 162 162 162 162-72.53 162-162-72.53-162-162-162M206 476c-1.64 15.85-2.46 27.84-2.46 36 0 8.15.82 20.16 2.46 36H80a16 16 0 01-16-16v-40a16 16 0 0116-16zm738 0a16 16 0 0116 16v40a16 16 0 01-16 16H818c1.64-15.85 2.46-27.84 2.46-36 0-8.15-.82-20.16-2.46-36zM814.06 180.65l28.29 28.29a16 16 0 010 22.63l-89.1 89.09c-10.04-12.37-17.95-21.43-23.71-27.2-5.77-5.76-14.84-13.67-27.2-23.71l89.1-89.1a16 16 0 0122.62 0m-581.5 0l89.1 89.1c-12.37 10.04-21.43 17.95-27.2 23.71-5.76 5.77-13.67 14.84-23.71 27.2l-89.1-89.1a16 16 0 010-22.62l28.29-28.29a16 16 0 0122.62 0M532 64a16 16 0 0116 16v126c-15.85-1.64-27.84-2.46-36-2.46-8.15 0-20.16.82-36 2.46V80a16 16 0 0116-16z"></path></svg></span></span></button></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/ROLL/docs/English/DesignImplementation/AgenticPipeline"><span title="English" class="categoryLinkLabel_W154">English</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ROLL/docs/"><span title="index" class="linkLabel_WmDU">index</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ROLL/docs/简体中文/使用指南/agentic/Tool_Use"><span title="简体中文" class="categoryLinkLabel_W154">简体中文</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ROLL/docs/简体中文/使用指南/agentic/Tool_Use"><span title="使用指南" class="categoryLinkLabel_W154">使用指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/使用指南/agentic/Tool_Use"><span title="agentic" class="categoryLinkLabel_W154">agentic</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/使用指南/algorithms/GRPO"><span title="algorithms" class="categoryLinkLabel_W154">algorithms</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/使用指南/ascend/ascend_usage"><span title="ascend" class="categoryLinkLabel_W154">ascend</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/async_parallel_rollout"><span title="Agentic 异步并行 Rollout" class="linkLabel_WmDU">Agentic 异步并行 Rollout</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/async_training"><span title="ROLL 异步训练功能使用指南" class="linkLabel_WmDU">ROLL 异步训练功能使用指南</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/使用指南/backend/deepspeed"><span title="backend" class="categoryLinkLabel_W154">backend</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/checkpoint_and_resume"><span title="检查点保存与恢复指南" class="linkLabel_WmDU">检查点保存与恢复指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/docs/简体中文/使用指南/device_mapping"><span title="ROLL 资源配置" class="linkLabel_WmDU">ROLL 资源配置</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/megatron_convert_2_hf"><span title="MCoreAdapter 模型转换为 Hugging Face 格式" class="linkLabel_WmDU">MCoreAdapter 模型转换为 Hugging Face 格式</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/offload_reload_control"><span title="GPU 时分复用控制指南" class="linkLabel_WmDU">GPU 时分复用控制指南</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/使用指南/pipeline/agentic_pipeline_start"><span title="pipeline" class="categoryLinkLabel_W154">pipeline</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/简体中文/使用指南/trackers_and_metrics"><span title="tracker和metrics" class="linkLabel_WmDU">tracker和metrics</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/快速开始/config_guide_cn"><span title="快速开始" class="categoryLinkLabel_W154">快速开始</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/性能调优指南/megatron_config_simple_guide"><span title="性能调优指南" class="categoryLinkLabel_W154">性能调优指南</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/扩展开发手册/support_new_models_cn"><span title="扩展开发手册" class="categoryLinkLabel_W154">扩展开发手册</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/简体中文/设计实现文档/AgenticPipeline_cn"><span title="设计实现文档" class="categoryLinkLabel_W154">设计实现文档</span></a></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ROLL/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">简体中文</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">使用指南</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">ROLL 资源配置</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>ROLL 资源配置</h1></header>
<p>在 ROLL 框架中，资源设置是通过 YAML 配置文件中的 <code>device_mapping</code> 参数来指定每个 worker 使用哪些 GPU 设备。本文档将详细介绍如何配置资源，包括共置和分离模式、多角色资源配置以及 worker 数量的计算方式。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="gpu-资源配置">GPU 资源配置<a href="#gpu-资源配置" class="hash-link" aria-label="Direct link to GPU 资源配置" title="Direct link to GPU 资源配置" translate="no">​</a></h2>
<p>在 ROLL 中，GPU 资源的设置通过在 YAML 配置文件中为每个 worker 指定 <code>device_mapping</code> 参数来完成。该参数是一个能被 Python <code>eval()</code> 函数解析为列表的字符串，列表中的值表示全局逻辑 GPU RANK。</p>
<p>例如：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(16</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">24))</span><br></span></code></pre></div></div>
<p>在这个例子中，系统总共需要 24 块 GPU，其中 <code>actor_train</code> 部署在 GPU [0,16) 上，<code>actor_infer</code> 部署在 GPU [16,24) 上。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="cpu-资源配置">CPU 资源配置<a href="#cpu-资源配置" class="hash-link" aria-label="Direct link to CPU 资源配置" title="Direct link to CPU 资源配置" translate="no">​</a></h2>
<p>对于仅使用 CPU 资源的 worker，只需配置 <code>world_size</code> 参数，系统会自动在 CPU 资源上部署相应数量的 worker (ray.Actor)。</p>
<p>例如：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">code_sandbox</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">world_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="共置-colocated-与分离-disaggregated-模式">共置 (Colocated) 与分离 (Disaggregated) 模式<a href="#共置-colocated-与分离-disaggregated-模式" class="hash-link" aria-label="Direct link to 共置 (Colocated) 与分离 (Disaggregated) 模式" title="Direct link to 共置 (Colocated) 与分离 (Disaggregated) 模式" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="共置模式">共置模式<a href="#共置模式" class="hash-link" aria-label="Direct link to 共置模式" title="Direct link to 共置模式" translate="no">​</a></h3>
<p>在共置模式下，多个角色共享相同的 GPU 资源。这种方式可以提高资源利用率，减少资源  浪费。</p>
<p>例如，在 <code>examples/docs_examples/example_grpo.yaml</code> 中：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8)) </span><span class="token comment" style="color:rgb(98, 114, 164)"># 与actor_train共享[0,8) GPU, GPU时分复用</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8))</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="分离模式">分离模式<a href="#分离模式" class="hash-link" aria-label="Direct link to 分离模式" title="Direct link to 分离模式" translate="no">​</a></h3>
<p>在分离模式下，不同角色使用不同的 GPU 资源。这种独立部署的方式是实现异步训练的关键。
ROLL里面通过为不同的worker设置不同的<code>device_mapping</code>直接实现分离部署。</p>
<p>例如，在 <code>examples/qwen2.5-7B-agentic_megatron/agentic_val_webshop_async.yaml</code> 中：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># actor train 使用GPU[0, 1, 2, 3], actor_infer 使用GPU[4, 5, 6, 7]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># </span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">4))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(4</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8))</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="多角色资源配置的灵活性">多角色资源配置的灵活性<a href="#多角色资源配置的灵活性" class="hash-link" aria-label="Direct link to 多角色资源配置的灵活性" title="Direct link to 多角色资源配置的灵活性" translate="no">​</a></h2>
<p>ROLL 框架支持为不同角色配置不同的资源策略，以满足各种应用场景的需求：</p>
<ol>
<li class="">不同角色可以使用不同数量的 GPU</li>
<li class="">不同角色可以使用不同的推理引擎（如 vLLM、SGLang 等）</li>
<li class="">不同角色可以设置不同的 <code>num_gpus_per_worker</code> 参数<!-- -->
<ol>
<li class="">训练角色的num_gpus_per_worker始终为1</li>
<li class="">推理角色的num_gpus_per_worker根据所需资源会&gt;=1，vllm根据并行设置自动计算，sglang直接指定</li>
</ol>
</li>
</ol>
<p>例如，在使用 vLLM 作为推理引擎时，会根据张量并行 (tensor_parallel_size) 和流水线并行 (pipeline_parallel_size) 的设置自动计算 <code>num_gpus_per_worker</code>：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">pipeline_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">num_gpus_per_worker</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 自动计算为 tensor_parallel_size * pipeline_parallel_size</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="worker-数量计算方式">Worker 数量计算方式<a href="#worker-数量计算方式" class="hash-link" aria-label="Direct link to Worker 数量计算方式" title="Direct link to Worker 数量计算方式" translate="no">​</a></h2>
<p>Worker 的数量 (<code>world_size</code>) 是根据 <code>device_mapping</code> 和 <code>num_gpus_per_worker</code> 参数自动计算的：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">world_size </span><span class="token operator">=</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">//</span><span class="token plain"> num_gpus_per_worker</span><br></span></code></pre></div></div>
<p>在 <code>WorkerConfig.__post_init__()</code> 方法中，如果 <code>device_mapping</code> 不为 None，则会执行以下逻辑：</p>
<ol>
<li class="">通过 <code>eval(device_mapping)</code> 将字符串解析为列表</li>
<li class="">验证 <code>len(device_mapping)</code> 能被 <code>num_gpus_per_worker</code> 整除</li>
<li class="">计算 <code>world_size = len(device_mapping) // num_gpus_per_worker</code></li>
</ol>
<p>对于仅使用 CPU 的 worker，直接通过 <code>world_size</code> 参数指定 worker 数量，此时 <code>num_gpus_per_worker</code> 被设置为 0。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="配置示例">配置示例<a href="#配置示例" class="hash-link" aria-label="Direct link to 配置示例" title="Direct link to 配置示例" translate="no">​</a></h2>
<p>以下是一个完整的资源配置示例：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">num_gpus_per_node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用 16 块 GPU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># world_size 自动计算为 16 // 1 = 16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">num_gpus_per_worker</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 每个 worker 使用 2 块 GPU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">12))  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用 12 块 GPU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># world_size 自动计算为 12 // 2 = 6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">rewards</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">code_sandbox</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">world_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 仅使用 CPU，部署 8 个 worker</span><br></span></code></pre></div></div>
<p>通过合理配置这些参数，可以灵活地为不同角色分配资源，以满足各种训练和推理需求。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/简体中文/使用指南/device_mapping.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-11-07T06:04:57.000Z" itemprop="dateModified">Nov 7, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/docs/简体中文/使用指南/checkpoint_and_resume"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">检查点保存与恢复指南</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/docs/简体中文/使用指南/megatron_convert_2_hf"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">MCoreAdapter 模型转换为 Hugging Face 格式</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#gpu-资源配置" class="table-of-contents__link toc-highlight">GPU 资源配置</a></li><li><a href="#cpu-资源配置" class="table-of-contents__link toc-highlight">CPU 资源配置</a></li><li><a href="#共置-colocated-与分离-disaggregated-模式" class="table-of-contents__link toc-highlight">共置 (Colocated) 与分离 (Disaggregated) 模式</a><ul><li><a href="#共置模式" class="table-of-contents__link toc-highlight">共置模式</a></li><li><a href="#分离模式" class="table-of-contents__link toc-highlight">分离模式</a></li></ul></li><li><a href="#多角色资源配置的灵活性" class="table-of-contents__link toc-highlight">多角色资源配置的灵活性</a></li><li><a href="#worker-数量计算方式" class="table-of-contents__link toc-highlight">Worker 数量计算方式</a></li><li><a href="#配置示例" class="table-of-contents__link toc-highlight">配置示例</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/快速开始/single_node_quick_start_cn">ROLL单机实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/简体中文/快速开始/config_guide_cn">配置指南</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
</body>
</html>