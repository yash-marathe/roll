<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-User Guides/Configuration/config_guide" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Configuration Guide | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="zh_Hans"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Configuration Guide | ROLL"><meta data-rh="true" name="description" content="Pipeline Config"><meta data-rh="true" property="og:description" content="Pipeline Config"><link data-rh="true" rel="icon" href="https://img.alicdn.com/imgextra/i4/O1CN01bo6EZl2192CAIjFwE_!!6000000006941-2-tps-465-367.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Configuration Guide","item":"https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D6R4GXHVFP"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D6R4GXHVFP",{anonymize_ip:!0})</script><link rel="stylesheet" href="/ROLL/assets/css/styles.f65cd7c3.css">
<script src="/ROLL/assets/js/runtime~main.87002e25.js" defer="defer"></script>
<script src="/ROLL/assets/js/main.90dbb0eb.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"dark"),document.documentElement.setAttribute("data-theme-choice",t||"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbar_MONK"><div class="navbar__inner"><div class="logoWrap_HHlA navbar__items"><div class="logo_Ufb2"><div class="ant-image css-zmd3lp" style="width:40px;height:32px"><img alt="ROLL" class="ant-image-img css-zmd3lp" style="height:32px" src="https://img.alicdn.com/imgextra/i3/O1CN016Mlxas1MHNA3NEbZ0_!!6000000001409-2-tps-465-367.png" width="40" height="32"></div></div><div><div class="title_E_95">ROLL</div><div class="subTitle_M9Ik">like a Reinforcement Learning Algorithm Developer</div></div></div><div class="navbar__items navbar__items--right"><a href="/ROLL/" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">Home</a><a href="/ROLL/#core" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">Core Algorithms</a><a href="/ROLL/#research" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">Research Community</a><a href="/ROLL/docs/Overview" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3 primary_vbUC" tabindex="0" aria-disabled="false">API Docs</a><a href="https://github.com/alibaba/ROLL" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Github</span><span role="img" aria-label="export" class="anticon anticon-export"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="export" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 912H144c-17.7 0-32-14.3-32-32V144c0-17.7 14.3-32 32-32h360c4.4 0 8 3.6 8 8v56c0 4.4-3.6 8-8 8H184v656h656V520c0-4.4 3.6-8 8-8h56c4.4 0 8 3.6 8 8v360c0 17.7-14.3 32-32 32zM770.87 199.13l-52.2-52.2a8.01 8.01 0 014.7-13.6l179.4-21c5.1-.6 9.5 3.7 8.9 8.9l-21 179.4c-.8 6.6-8.9 9.4-13.6 4.7l-52.4-52.4-256.2 256.2a8.03 8.03 0 01-11.3 0l-42.4-42.4a8.03 8.03 0 010-11.3l256.1-256.3z"></path></svg></span></a><button type="button" class="ant-btn css-zmd3lp ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-dropdown-trigger language_XaW5"><span class="ant-btn-icon"><span role="img" aria-label="global" class="anticon anticon-global"><svg viewBox="64 64 896 896" focusable="false" data-icon="global" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M854.4 800.9c.2-.3.5-.6.7-.9C920.6 722.1 960 621.7 960 512s-39.4-210.1-104.8-288c-.2-.3-.5-.5-.7-.8-1.1-1.3-2.1-2.5-3.2-3.7-.4-.5-.8-.9-1.2-1.4l-4.1-4.7-.1-.1c-1.5-1.7-3.1-3.4-4.6-5.1l-.1-.1c-3.2-3.4-6.4-6.8-9.7-10.1l-.1-.1-4.8-4.8-.3-.3c-1.5-1.5-3-2.9-4.5-4.3-.5-.5-1-1-1.6-1.5-1-1-2-1.9-3-2.8-.3-.3-.7-.6-1-1C736.4 109.2 629.5 64 512 64s-224.4 45.2-304.3 119.2c-.3.3-.7.6-1 1-1 .9-2 1.9-3 2.9-.5.5-1 1-1.6 1.5-1.5 1.4-3 2.9-4.5 4.3l-.3.3-4.8 4.8-.1.1c-3.3 3.3-6.5 6.7-9.7 10.1l-.1.1c-1.6 1.7-3.1 3.4-4.6 5.1l-.1.1c-1.4 1.5-2.8 3.1-4.1 4.7-.4.5-.8.9-1.2 1.4-1.1 1.2-2.1 2.5-3.2 3.7-.2.3-.5.5-.7.8C103.4 301.9 64 402.3 64 512s39.4 210.1 104.8 288c.2.3.5.6.7.9l3.1 3.7c.4.5.8.9 1.2 1.4l4.1 4.7c0 .1.1.1.1.2 1.5 1.7 3 3.4 4.6 5l.1.1c3.2 3.4 6.4 6.8 9.6 10.1l.1.1c1.6 1.6 3.1 3.2 4.7 4.7l.3.3c3.3 3.3 6.7 6.5 10.1 9.6 80.1 74 187 119.2 304.5 119.2s224.4-45.2 304.3-119.2a300 300 0 0010-9.6l.3-.3c1.6-1.6 3.2-3.1 4.7-4.7l.1-.1c3.3-3.3 6.5-6.7 9.6-10.1l.1-.1c1.5-1.7 3.1-3.3 4.6-5 0-.1.1-.1.1-.2 1.4-1.5 2.8-3.1 4.1-4.7.4-.5.8-.9 1.2-1.4a99 99 0 003.3-3.7zm4.1-142.6c-13.8 32.6-32 62.8-54.2 90.2a444.07 444.07 0 00-81.5-55.9c11.6-46.9 18.8-98.4 20.7-152.6H887c-3 40.9-12.6 80.6-28.5 118.3zM887 484H743.5c-1.9-54.2-9.1-105.7-20.7-152.6 29.3-15.6 56.6-34.4 81.5-55.9A373.86 373.86 0 01887 484zM658.3 165.5c39.7 16.8 75.8 40 107.6 69.2a394.72 394.72 0 01-59.4 41.8c-15.7-45-35.8-84.1-59.2-115.4 3.7 1.4 7.4 2.9 11 4.4zm-90.6 700.6c-9.2 7.2-18.4 12.7-27.7 16.4V697a389.1 389.1 0 01115.7 26.2c-8.3 24.6-17.9 47.3-29 67.8-17.4 32.4-37.8 58.3-59 75.1zm59-633.1c11 20.6 20.7 43.3 29 67.8A389.1 389.1 0 01540 327V141.6c9.2 3.7 18.5 9.1 27.7 16.4 21.2 16.7 41.6 42.6 59 75zM540 640.9V540h147.5c-1.6 44.2-7.1 87.1-16.3 127.8l-.3 1.2A445.02 445.02 0 00540 640.9zm0-156.9V383.1c45.8-2.8 89.8-12.5 130.9-28.1l.3 1.2c9.2 40.7 14.7 83.5 16.3 127.8H540zm-56 56v100.9c-45.8 2.8-89.8 12.5-130.9 28.1l-.3-1.2c-9.2-40.7-14.7-83.5-16.3-127.8H484zm-147.5-56c1.6-44.2 7.1-87.1 16.3-127.8l.3-1.2c41.1 15.6 85 25.3 130.9 28.1V484H336.5zM484 697v185.4c-9.2-3.7-18.5-9.1-27.7-16.4-21.2-16.7-41.7-42.7-59.1-75.1-11-20.6-20.7-43.3-29-67.8 37.2-14.6 75.9-23.3 115.8-26.1zm0-370a389.1 389.1 0 01-115.7-26.2c8.3-24.6 17.9-47.3 29-67.8 17.4-32.4 37.8-58.4 59.1-75.1 9.2-7.2 18.4-12.7 27.7-16.4V327zM365.7 165.5c3.7-1.5 7.3-3 11-4.4-23.4 31.3-43.5 70.4-59.2 115.4-21-12-40.9-26-59.4-41.8 31.8-29.2 67.9-52.4 107.6-69.2zM165.5 365.7c13.8-32.6 32-62.8 54.2-90.2 24.9 21.5 52.2 40.3 81.5 55.9-11.6 46.9-18.8 98.4-20.7 152.6H137c3-40.9 12.6-80.6 28.5-118.3zM137 540h143.5c1.9 54.2 9.1 105.7 20.7 152.6a444.07 444.07 0 00-81.5 55.9A373.86 373.86 0 01137 540zm228.7 318.5c-39.7-16.8-75.8-40-107.6-69.2 18.5-15.8 38.4-29.7 59.4-41.8 15.7 45 35.8 84.1 59.2 115.4-3.7-1.4-7.4-2.9-11-4.4zm292.6 0c-3.7 1.5-7.3 3-11 4.4 23.4-31.3 43.5-70.4 59.2-115.4 21 12 40.9 26 59.4 41.8a373.81 373.81 0 01-107.6 69.2z"></path></svg></span></span><span>English</span></button><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="Search" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div><button type="button" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text ant-btn-icon-only" style="margin-left:6px"><span class="ant-btn-icon"><span role="img" aria-label="sun" style="font-size:20px" class="anticon anticon-sun"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="sun" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M548 818v126a16 16 0 01-16 16h-40a16 16 0 01-16-16V818c15.85 1.64 27.84 2.46 36 2.46 8.15 0 20.16-.82 36-2.46m205.25-115.66l89.1 89.1a16 16 0 010 22.62l-28.29 28.29a16 16 0 01-22.62 0l-89.1-89.1c12.37-10.04 21.43-17.95 27.2-23.71 5.76-5.77 13.67-14.84 23.71-27.2m-482.5 0c10.04 12.36 17.95 21.43 23.71 27.2 5.77 5.76 14.84 13.67 27.2 23.71l-89.1 89.1a16 16 0 01-22.62 0l-28.29-28.29a16 16 0 010-22.63zM512 278c129.24 0 234 104.77 234 234S641.24 746 512 746 278 641.24 278 512s104.77-234 234-234m0 72c-89.47 0-162 72.53-162 162s72.53 162 162 162 162-72.53 162-162-72.53-162-162-162M206 476c-1.64 15.85-2.46 27.84-2.46 36 0 8.15.82 20.16 2.46 36H80a16 16 0 01-16-16v-40a16 16 0 0116-16zm738 0a16 16 0 0116 16v40a16 16 0 01-16 16H818c1.64-15.85 2.46-27.84 2.46-36 0-8.15-.82-20.16-2.46-36zM814.06 180.65l28.29 28.29a16 16 0 010 22.63l-89.1 89.09c-10.04-12.37-17.95-21.43-23.71-27.2-5.77-5.76-14.84-13.67-27.2-23.71l89.1-89.1a16 16 0 0122.62 0m-581.5 0l89.1 89.1c-12.37 10.04-21.43 17.95-27.2 23.71-5.76 5.77-13.67 14.84-23.71 27.2l-89.1-89.1a16 16 0 010-22.62l28.29-28.29a16 16 0 0122.62 0M532 64a16 16 0 0116 16v126c-15.85-1.64-27.84-2.46-36-2.46-8.15 0-20.16.82-36 2.46V80a16 16 0 0116-16z"></path></svg></span></span></button></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ROLL/docs/Overview"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/docs/Getting Started/Installation/image_address"><span title="Getting Started" class="categoryLinkLabel_W154">Getting Started</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Getting Started/Installation/image_address"><span title="Installation" class="categoryLinkLabel_W154">Installation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Getting Started/Quick Start/aliyun_serverless_devpod_quick_start"><span title="Quick Start" class="categoryLinkLabel_W154">Quick Start</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Getting Started/Debugging Guide/debug_guide"><span title="Debugging Guide" class="categoryLinkLabel_W154">Debugging Guide</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Getting Started/FAQ/qa_issues"><span title="FAQ" class="categoryLinkLabel_W154">FAQ</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ROLL/docs/User Guides/Configuration/config_guide"><span title="User Guides" class="categoryLinkLabel_W154">User Guides</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ROLL/docs/User Guides/Configuration/config_guide"><span title="Configuration" class="categoryLinkLabel_W154">Configuration</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/docs/User Guides/Configuration/config_guide"><span title="Configuration Guide" class="linkLabel_WmDU">Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/config_system"><span title="ROLL Configuration System Detailed Explanation" class="linkLabel_WmDU">ROLL Configuration System Detailed Explanation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/deepspeed"><span title="DeepSpeed Training Backend Configuration Guide" class="linkLabel_WmDU">DeepSpeed Training Backend Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/device_mapping"><span title="ROLL Resource Configuration" class="linkLabel_WmDU">ROLL Resource Configuration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/fp8_rollout"><span title="FP8 Quantization Configuration Guide" class="linkLabel_WmDU">FP8 Quantization Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/lora"><span title="LoRA Fine-tuning Configuration Guide" class="linkLabel_WmDU">LoRA Fine-tuning Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/megatron"><span title="Megatron Inference and Training Backend Configuration Guide" class="linkLabel_WmDU">Megatron Inference and Training Backend Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/offpolicy_setting"><span title="Off-Policy Algorithms Configuration Guide" class="linkLabel_WmDU">Off-Policy Algorithms Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/sglang"><span title="SGLang Inference Backend Configuration Guide" class="linkLabel_WmDU">SGLang Inference Backend Configuration Guide</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/docs/User Guides/Configuration/vllm"><span title="vLLM Inference Backend Configuration Guide" class="linkLabel_WmDU">vLLM Inference Backend Configuration Guide</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Pipeline/agent_pipeline_start"><span title="Pipeline" class="categoryLinkLabel_W154">Pipeline</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Algorithms/GRPO"><span title="Algorithms" class="categoryLinkLabel_W154">Algorithms</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Agentic/Tool_Use"><span title="Agentic" class="categoryLinkLabel_W154">Agentic</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Advanced Features/async_parallel_rollout"><span title="Advanced Features" class="categoryLinkLabel_W154">Advanced Features</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Tracker &amp; Metrics/trackers_and_metrics"><span title="Tracker &amp; Metrics" class="categoryLinkLabel_W154">Tracker &amp; Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/User Guides/Hardware Support/ascend_usage"><span title="Hardware Support" class="categoryLinkLabel_W154">Hardware Support</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/docs/Development/Architecture/AgenticPipeline"><span title="Development" class="categoryLinkLabel_W154">Development</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Development/Architecture/AgenticPipeline"><span title="Architecture" class="categoryLinkLabel_W154">Architecture</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/docs/Development/Developer Guide/support_new_models"><span title="Developer Guide" class="categoryLinkLabel_W154">Developer Guide</span></a></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ROLL/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">User Guides</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Configuration</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Configuration Guide</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Configuration Guide</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="pipeline-config">Pipeline Config<a href="#pipeline-config" class="hash-link" aria-label="Direct link to Pipeline Config" title="Direct link to Pipeline Config" translate="no">​</a></h2>
<p>Refer to <a href="https://alibaba.github.io/ROLL/docs/StepByStep/rlvr_pipeline_start" target="_blank" rel="noopener noreferrer" class="">RLVR Pipeline Start</a> and <a href="https://alibaba.github.io/ROLL/docs/StepByStep/agent_pipeline_start" target="_blank" rel="noopener noreferrer" class="">Agentic Pipeline Start</a> for more details about RLVR/Agentic pipeline configurations and reward settings.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">rollout_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">prompt_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">response_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4096</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">num_return_sequences_in_group</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><br></span></code></pre></div></div>
<ul>
<li class=""><code>rollout_batch_size</code>: The number of prompt samples to process in each inference batch.</li>
<li class=""><code>num_return_sequences_in_group</code>: The number of sequences to generate for each prompt. Notice that its value proportionally scales the actual training samples. In other words, the actual training global batch size is equivalent to <code>num_return_sequences_in_group</code> * <code>rollout_batch_size</code>.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="worker-config">Worker Config<a href="#worker-config" class="hash-link" aria-label="Direct link to Worker Config" title="Direct link to Worker Config" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="actortrainactorinfercriticreference">ActorTrain/ActorInfer/Critic/Reference<a href="#actortrainactorinfercriticreference" class="hash-link" aria-label="Direct link to ActorTrain/ActorInfer/Critic/Reference" title="Direct link to ActorTrain/ActorInfer/Critic/Reference" translate="no">​</a></h3>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">disable_gradient_checkpointing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">learning_rate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1.0e-6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">weight_decay</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">per_device_train_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">gradient_accumulation_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">32</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">warmup_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">20</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">data_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> native</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">file_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> xxx/train.json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> instruction</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_train  </span><span class="token comment" style="color:rgb(98, 114, 164)"># deepspeed_train/megatron_train for training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">pipeline_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">expert_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">infer_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">generating_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">max_new_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">response_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm  </span><span class="token comment" style="color:rgb(98, 114, 164)"># vllm/sglang/hf_infer for inference</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">block_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">max_model_len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">num_gpus_per_worker</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">reference</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_infer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span></code></pre></div></div>
<ul>
<li class=""><code>device_mapping</code>: The list of device ids to use when training for the worker. Configure for any worker used gpu devices, including <code>actor_train</code>, <code>actor_infer</code>, <code>critic</code> and <code>reference</code>.</li>
<li class=""><code>num_gpus_per_worker</code>: The number of GPUs assigned per worker. Applicable to <code>actor_infer</code> only.</li>
<li class=""><code>infer_batch_size</code>: The batch size to used for inference or computing logprobs.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-arguments-model_args">Model Arguments (<strong>model_args</strong>)<a href="#model-arguments-model_args" class="hash-link" aria-label="Direct link to model-arguments-model_args" title="Direct link to model-arguments-model_args" translate="no">​</a></h3>
<ul>
<li class=""><code>model_args.dtype</code>: Set model dtype as fp32, bf16, or fp16, otherwise use config&#x27;s torch_dtype</li>
<li class=""><code>model_args.disable_gradient_checkpointing</code>: Disable gradient checkpointing. Applicable only to <code>actor_train</code> when <code>strategy_name</code> is <code>deepspeed_train</code></li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="data-arguments-data_args">Data Arguments (<strong>data_args</strong>)<a href="#data-arguments-data_args" class="hash-link" aria-label="Direct link to data-arguments-data_args" title="Direct link to data-arguments-data_args" translate="no">​</a></h3>
<p>Configure data_args under <code>actor_train</code>.</p>
<ul>
<li class=""><code>data_args.template</code>: The chat template used for constructing prompts during training and inference. Setting to <code>native</code> utilizes the default chat template <code>tokenizer.apply_chat_template</code> for prompt construction.</li>
<li class=""><code>data_args.file_name</code>: The file path for training data. Supported formats include JSON, JSONL, and CSV.</li>
<li class=""><code>data_args.prompt</code>: Which column in the file to use as prompt.</li>
<li class=""><code>data_args.messages</code>: Which column in the file to use as messages. (conflicts with prompt)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="generating-arguments-generating_args">Generating Arguments (<strong>generating_args</strong>)<a href="#generating-arguments-generating_args" class="hash-link" aria-label="Direct link to generating-arguments-generating_args" title="Direct link to generating-arguments-generating_args" translate="no">​</a></h3>
<p>Configure generating_args under <code>actor_infer</code>.</p>
<ul>
<li class=""><code>generating_args.max_new_tokens</code>: The maximum length of the generated text.</li>
<li class=""><code>generating_args.temperature</code>: The temperature to use for sampling.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="strategy-arguments-strategy_args">Strategy Arguments (<strong>strategy_args</strong>)<a href="#strategy-arguments-strategy_args" class="hash-link" aria-label="Direct link to strategy-arguments-strategy_args" title="Direct link to strategy-arguments-strategy_args" translate="no">​</a></h3>
<ul>
<li class=""><code>strategy_args.strategy_name</code>: The name of training/inference strategy. <code>deepspeed_train</code>/<code>megatron_train</code> for training, <code>vllm</code>/<code>sglang</code>/<code>hf_infer</code> for inference.</li>
<li class=""><code>strategy_args.strategy_config</code>: The config of training/inference strategy. Will be passed to <code>strategy_name</code>&#x27;s constructor. E.g. <code>strategy_config.tensor_model_parallel_size</code> for <code>megatron_train</code> strategy and <code>strategy_config.gpu_memory_utilization</code> for <code>vllm</code> strategy.</li>
</ul>
<p>Commonly used strategy configs are listed below:</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="megatron-strategy-config">Megatron Strategy Config<a href="#megatron-strategy-config" class="hash-link" aria-label="Direct link to Megatron Strategy Config" title="Direct link to Megatron Strategy Config" translate="no">​</a></h4>
<ul>
<li class=""><code>tensor_model_parallel_size</code>: Degree of tensor model parallelism.</li>
<li class=""><code>pipeline_model_parallel_size</code>: Degree of pipeline model parallelism.</li>
<li class=""><code>expert_model_parallel_size</code>: Degree of expert model parallelism.</li>
<li class=""><code>context_parallel_size</code>: Degree of context parallelism.</li>
<li class=""><code>virtual_pipeline_model_parallel_size</code>: Num of virtual pipeline in a pipeline.</li>
<li class=""><code>sequence_parallel</code>: Enable sequence parallel optimization.</li>
<li class=""><code>recompute_granularity</code>: Checkpoint activations to allow for training with larger models, sequences, and batch sizes. It is supported at two granularities 1) full: whole transformer layer is recomputed, 2) selective: core attention part of the transformer layer is recomputed.</li>
<li class=""><code>moe_layer_recompute</code>: Memory optimization: checkpointing moe_layer to save activation memory.</li>
<li class=""><code>moe_token_dispatcher_type</code>: The type of token dispatcher to use. Options are &#x27;allgather&#x27; and &#x27;alltoall&#x27;.</li>
<li class=""><code>moe_grouped_gemm</code>: Enable grouped gemm for moe experts.</li>
<li class=""><code>moe_shared_expert_overlap</code>: Enable overlapping between shared expert computations and dispatcher communications.</li>
<li class=""><code>overlap_grad_reduce</code>: If true, overlap grad reduce-scatter with backward compute in distributed optimizer.</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="vllm-strategy-config">VLLM Strategy Config<a href="#vllm-strategy-config" class="hash-link" aria-label="Direct link to VLLM Strategy Config" title="Direct link to VLLM Strategy Config" translate="no">​</a></h3>
<ul>
<li class=""><code>gpu_memory_utilization</code>: The fraction of GPU memory to be used for the model executor.</li>
<li class=""><code>block_size</code>: Token block size for contiguous chunks of tokens.</li>
<li class=""><code>max_model_len</code>: Model context length. If unspecified, will be automatically derived from the model config.</li>
<li class=""><code>load_format</code>: The format of the model weights to load. Since there will be a <code>model update</code> in the beginning, this value should can be set to <code>dummy</code>.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="sglang-strategy-config">SGLang Strategy Config<a href="#sglang-strategy-config" class="hash-link" aria-label="Direct link to SGLang Strategy Config" title="Direct link to SGLang Strategy Config" translate="no">​</a></h4>
<ul>
<li class=""><code>mem_fraction_static</code>: Fraction of the free GPU memory used for static memory like model weights and KV cache. Increase it if KV cache building fails. Decrease it if CUDA runs out of memory.</li>
<li class=""><code>load_format</code>: The format of the model weights to load. Since there will be a <code>model update</code> in the beginning, this value should can be set to <code>dummy</code>.</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="deepspeed-strategy-config">DeepSpeed Strategy Config<a href="#deepspeed-strategy-config" class="hash-link" aria-label="Direct link to DeepSpeed Strategy Config" title="Direct link to DeepSpeed Strategy Config" translate="no">​</a></h4>
<p>There are DeepSpeed configurations in <code>./examples/config/</code> that can be overridden in the default list for strategy configuration.</p>
<p>For example, to use the deepspeed_zero2 strategy, add the following to your config:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">defaults</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/envs@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero2@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero3@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero3_cpuoffload@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> deepspeed_train</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">deepspeed_zero2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="training-arguments-training_args">Training Arguments (<strong>training_args</strong>)<a href="#training-arguments-training_args" class="hash-link" aria-label="Direct link to training-arguments-training_args" title="Direct link to training-arguments-training_args" translate="no">​</a></h3>
<p>Used for configuring training parameters such as <code>learning_rate</code>, <code>weight_decay</code>, <code>warmup_steps</code>, etc.</p>
<ul>
<li class=""><code>training_args.per_device_train_batch_size</code>: The batch size to use when training.</li>
<li class=""><code>training_args.gradient_accumulation_steps</code>: The number of gradient accumulation steps.</li>
</ul>
<p>In deepspeed training the global train batch size is <code>per_device_train_batch_size</code> * <code>gradient_accumulation_steps</code> * world_size (a.k.a length of <code>device_mapping</code> for <code>actor_train</code>/<code>critic</code>).</p>
<p>In megatron training the global train batch size is <code>per_device_train_batch_size</code> * <code>gradient_accumulation_steps</code> * world_size / <code>tensor_model_parallel_size</code> / <code>pipeline_model_parallel_size</code> / <code>context_parallel_size</code> (don&#x27;t need to divide <code>expert_model_parallel_size</code>).</p>
<p>If you want to perform one optimization step in each rollout, set <code>gradient_accumulation_steps</code> to <code>rollout_batch_size</code> * <code>num_return_sequences_in_group</code> * <code>tensor_model_parallel_size</code> * <code>pipeline_model_parallel_size</code> * <code>context_parallel_size</code>/ <code>per_device_train_batch_size</code> / world_size.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/User Guides/Configuration/config_guide.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2025-12-05T03:38:53.000Z" itemprop="dateModified">Dec 5, 2025</time></b></span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/docs/Getting Started/FAQ/qa_issues"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Frequently Asked Questions (Q&amp;A)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/docs/User Guides/Configuration/config_system"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">ROLL Configuration System Detailed Explanation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pipeline-config" class="table-of-contents__link toc-highlight">Pipeline Config</a></li><li><a href="#worker-config" class="table-of-contents__link toc-highlight">Worker Config</a><ul><li><a href="#actortrainactorinfercriticreference" class="table-of-contents__link toc-highlight">ActorTrain/ActorInfer/Critic/Reference</a></li><li><a href="#model-arguments-model_args" class="table-of-contents__link toc-highlight">Model Arguments (<strong>model_args</strong>)</a></li><li><a href="#data-arguments-data_args" class="table-of-contents__link toc-highlight">Data Arguments (<strong>data_args</strong>)</a></li><li><a href="#generating-arguments-generating_args" class="table-of-contents__link toc-highlight">Generating Arguments (<strong>generating_args</strong>)</a></li><li><a href="#strategy-arguments-strategy_args" class="table-of-contents__link toc-highlight">Strategy Arguments (<strong>strategy_args</strong>)</a></li><li><a href="#vllm-strategy-config" class="table-of-contents__link toc-highlight">VLLM Strategy Config</a></li><li><a href="#training-arguments-training_args" class="table-of-contents__link toc-highlight">Training Arguments (<strong>training_args</strong>)</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/Getting Started/Quick Start/single_node_quick_start">Single Node Quick Start</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/docs/User Guides/Configuration/config_guide">Config Guide</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
</body>
</html>