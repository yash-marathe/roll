<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-User Guides/Advanced Features/dynamic_batching" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">ROLL Dynamic Batching | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Advanced Features/dynamic_batching"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ROLL Dynamic Batching | ROLL"><meta data-rh="true" name="description" content="ROLL 框架支持对 Rollout Batch 做 Dynamic Batching 功能，尽量减少无效 token 计算，使得计算效率更高，本文档详细介绍如何使用这一功能。"><meta data-rh="true" property="og:description" content="ROLL 框架支持对 Rollout Batch 做 Dynamic Batching 功能，尽量减少无效 token 计算，使得计算效率更高，本文档详细介绍如何使用这一功能。"><link data-rh="true" rel="icon" href="https://img.alicdn.com/imgextra/i4/O1CN01bo6EZl2192CAIjFwE_!!6000000006941-2-tps-465-367.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Advanced Features/dynamic_batching"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Advanced Features/dynamic_batching" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Advanced Features/dynamic_batching" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Advanced Features/dynamic_batching" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ROLL Dynamic Batching","item":"https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Advanced Features/dynamic_batching"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D6R4GXHVFP"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D6R4GXHVFP",{anonymize_ip:!0})</script><link rel="stylesheet" href="/ROLL/zh-Hans/assets/css/styles.4016bf18.css">
<script src="/ROLL/zh-Hans/assets/js/runtime~main.138e3150.js" defer="defer"></script>
<script src="/ROLL/zh-Hans/assets/js/main.b037e3bf.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"dark"),document.documentElement.setAttribute("data-theme-choice",t||"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav class="navbar navbar--fixed-top navbar_MONK"><div class="navbar__inner"><div class="logoWrap_HHlA navbar__items"><div class="logo_Ufb2"><div class="ant-image css-plsjn" style="width:40px;height:32px"><img alt="ROLL" class="ant-image-img css-plsjn" style="height:32px" src="https://img.alicdn.com/imgextra/i3/O1CN016Mlxas1MHNA3NEbZ0_!!6000000001409-2-tps-465-367.png" width="40" height="32"></div></div><div><div class="title_E_95">ROLL</div><div class="subTitle_M9Ik">像一名强化学习算法开发者一样</div></div></div><div class="navbar__items navbar__items--right"><a href="/ROLL/zh-Hans/" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">首页</a><a href="/ROLL/zh-Hans/#core" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">核心算法</a><a href="/ROLL/zh-Hans/#research" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">开源社区</a><a href="/ROLL/zh-Hans/docs/Overview" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3 primary_vbUC" tabindex="0" aria-disabled="false">文档</a><a href="https://github.com/alibaba/ROLL" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Github</span><span role="img" aria-label="export" class="anticon anticon-export"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="export" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 912H144c-17.7 0-32-14.3-32-32V144c0-17.7 14.3-32 32-32h360c4.4 0 8 3.6 8 8v56c0 4.4-3.6 8-8 8H184v656h656V520c0-4.4 3.6-8 8-8h56c4.4 0 8 3.6 8 8v360c0 17.7-14.3 32-32 32zM770.87 199.13l-52.2-52.2a8.01 8.01 0 014.7-13.6l179.4-21c5.1-.6 9.5 3.7 8.9 8.9l-21 179.4c-.8 6.6-8.9 9.4-13.6 4.7l-52.4-52.4-256.2 256.2a8.03 8.03 0 01-11.3 0l-42.4-42.4a8.03 8.03 0 010-11.3l256.1-256.3z"></path></svg></span></a><button type="button" class="ant-btn css-plsjn ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-dropdown-trigger language_XaW5"><span class="ant-btn-icon"><span role="img" aria-label="global" class="anticon anticon-global"><svg viewBox="64 64 896 896" focusable="false" data-icon="global" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M854.4 800.9c.2-.3.5-.6.7-.9C920.6 722.1 960 621.7 960 512s-39.4-210.1-104.8-288c-.2-.3-.5-.5-.7-.8-1.1-1.3-2.1-2.5-3.2-3.7-.4-.5-.8-.9-1.2-1.4l-4.1-4.7-.1-.1c-1.5-1.7-3.1-3.4-4.6-5.1l-.1-.1c-3.2-3.4-6.4-6.8-9.7-10.1l-.1-.1-4.8-4.8-.3-.3c-1.5-1.5-3-2.9-4.5-4.3-.5-.5-1-1-1.6-1.5-1-1-2-1.9-3-2.8-.3-.3-.7-.6-1-1C736.4 109.2 629.5 64 512 64s-224.4 45.2-304.3 119.2c-.3.3-.7.6-1 1-1 .9-2 1.9-3 2.9-.5.5-1 1-1.6 1.5-1.5 1.4-3 2.9-4.5 4.3l-.3.3-4.8 4.8-.1.1c-3.3 3.3-6.5 6.7-9.7 10.1l-.1.1c-1.6 1.7-3.1 3.4-4.6 5.1l-.1.1c-1.4 1.5-2.8 3.1-4.1 4.7-.4.5-.8.9-1.2 1.4-1.1 1.2-2.1 2.5-3.2 3.7-.2.3-.5.5-.7.8C103.4 301.9 64 402.3 64 512s39.4 210.1 104.8 288c.2.3.5.6.7.9l3.1 3.7c.4.5.8.9 1.2 1.4l4.1 4.7c0 .1.1.1.1.2 1.5 1.7 3 3.4 4.6 5l.1.1c3.2 3.4 6.4 6.8 9.6 10.1l.1.1c1.6 1.6 3.1 3.2 4.7 4.7l.3.3c3.3 3.3 6.7 6.5 10.1 9.6 80.1 74 187 119.2 304.5 119.2s224.4-45.2 304.3-119.2a300 300 0 0010-9.6l.3-.3c1.6-1.6 3.2-3.1 4.7-4.7l.1-.1c3.3-3.3 6.5-6.7 9.6-10.1l.1-.1c1.5-1.7 3.1-3.3 4.6-5 0-.1.1-.1.1-.2 1.4-1.5 2.8-3.1 4.1-4.7.4-.5.8-.9 1.2-1.4a99 99 0 003.3-3.7zm4.1-142.6c-13.8 32.6-32 62.8-54.2 90.2a444.07 444.07 0 00-81.5-55.9c11.6-46.9 18.8-98.4 20.7-152.6H887c-3 40.9-12.6 80.6-28.5 118.3zM887 484H743.5c-1.9-54.2-9.1-105.7-20.7-152.6 29.3-15.6 56.6-34.4 81.5-55.9A373.86 373.86 0 01887 484zM658.3 165.5c39.7 16.8 75.8 40 107.6 69.2a394.72 394.72 0 01-59.4 41.8c-15.7-45-35.8-84.1-59.2-115.4 3.7 1.4 7.4 2.9 11 4.4zm-90.6 700.6c-9.2 7.2-18.4 12.7-27.7 16.4V697a389.1 389.1 0 01115.7 26.2c-8.3 24.6-17.9 47.3-29 67.8-17.4 32.4-37.8 58.3-59 75.1zm59-633.1c11 20.6 20.7 43.3 29 67.8A389.1 389.1 0 01540 327V141.6c9.2 3.7 18.5 9.1 27.7 16.4 21.2 16.7 41.6 42.6 59 75zM540 640.9V540h147.5c-1.6 44.2-7.1 87.1-16.3 127.8l-.3 1.2A445.02 445.02 0 00540 640.9zm0-156.9V383.1c45.8-2.8 89.8-12.5 130.9-28.1l.3 1.2c9.2 40.7 14.7 83.5 16.3 127.8H540zm-56 56v100.9c-45.8 2.8-89.8 12.5-130.9 28.1l-.3-1.2c-9.2-40.7-14.7-83.5-16.3-127.8H484zm-147.5-56c1.6-44.2 7.1-87.1 16.3-127.8l.3-1.2c41.1 15.6 85 25.3 130.9 28.1V484H336.5zM484 697v185.4c-9.2-3.7-18.5-9.1-27.7-16.4-21.2-16.7-41.7-42.7-59.1-75.1-11-20.6-20.7-43.3-29-67.8 37.2-14.6 75.9-23.3 115.8-26.1zm0-370a389.1 389.1 0 01-115.7-26.2c8.3-24.6 17.9-47.3 29-67.8 17.4-32.4 37.8-58.4 59.1-75.1 9.2-7.2 18.4-12.7 27.7-16.4V327zM365.7 165.5c3.7-1.5 7.3-3 11-4.4-23.4 31.3-43.5 70.4-59.2 115.4-21-12-40.9-26-59.4-41.8 31.8-29.2 67.9-52.4 107.6-69.2zM165.5 365.7c13.8-32.6 32-62.8 54.2-90.2 24.9 21.5 52.2 40.3 81.5 55.9-11.6 46.9-18.8 98.4-20.7 152.6H137c3-40.9 12.6-80.6 28.5-118.3zM137 540h143.5c1.9 54.2 9.1 105.7 20.7 152.6a444.07 444.07 0 00-81.5 55.9A373.86 373.86 0 01137 540zm228.7 318.5c-39.7-16.8-75.8-40-107.6-69.2 18.5-15.8 38.4-29.7 59.4-41.8 15.7 45 35.8 84.1 59.2 115.4-3.7-1.4-7.4-2.9-11-4.4zm292.6 0c-3.7 1.5-7.3 3-11 4.4 23.4-31.3 43.5-70.4 59.2-115.4 21 12 40.9 26 59.4 41.8a373.81 373.81 0 01-107.6 69.2z"></path></svg></span></span><span>简体中文</span></button><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div><button type="button" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text ant-btn-icon-only" style="margin-left:6px"><span class="ant-btn-icon"><span role="img" aria-label="sun" style="font-size:20px" class="anticon anticon-sun"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="sun" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M548 818v126a16 16 0 01-16 16h-40a16 16 0 01-16-16V818c15.85 1.64 27.84 2.46 36 2.46 8.15 0 20.16-.82 36-2.46m205.25-115.66l89.1 89.1a16 16 0 010 22.62l-28.29 28.29a16 16 0 01-22.62 0l-89.1-89.1c12.37-10.04 21.43-17.95 27.2-23.71 5.76-5.77 13.67-14.84 23.71-27.2m-482.5 0c10.04 12.36 17.95 21.43 23.71 27.2 5.77 5.76 14.84 13.67 27.2 23.71l-89.1 89.1a16 16 0 01-22.62 0l-28.29-28.29a16 16 0 010-22.63zM512 278c129.24 0 234 104.77 234 234S641.24 746 512 746 278 641.24 278 512s104.77-234 234-234m0 72c-89.47 0-162 72.53-162 162s72.53 162 162 162 162-72.53 162-162-72.53-162-162-162M206 476c-1.64 15.85-2.46 27.84-2.46 36 0 8.15.82 20.16 2.46 36H80a16 16 0 01-16-16v-40a16 16 0 0116-16zm738 0a16 16 0 0116 16v40a16 16 0 01-16 16H818c1.64-15.85 2.46-27.84 2.46-36 0-8.15-.82-20.16-2.46-36zM814.06 180.65l28.29 28.29a16 16 0 010 22.63l-89.1 89.09c-10.04-12.37-17.95-21.43-23.71-27.2-5.77-5.76-14.84-13.67-27.2-23.71l89.1-89.1a16 16 0 0122.62 0m-581.5 0l89.1 89.1c-12.37 10.04-21.43 17.95-27.2 23.71-5.76 5.77-13.67 14.84-23.71 27.2l-89.1-89.1a16 16 0 010-22.62l28.29-28.29a16 16 0 0122.62 0M532 64a16 16 0 0116 16v126c-15.85-1.64-27.84-2.46-36-2.46-8.15 0-20.16.82-36 2.46V80a16 16 0 0116-16z"></path></svg></span></span></button></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ROLL/zh-Hans/docs/Overview"><span title="概览" class="linkLabel_WmDU">概览</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="快速入门" class="categoryLinkLabel_W154">快速入门</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="安装指南" class="categoryLinkLabel_W154">安装指南</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/aliyun_serverless_devpod_quick_start"><span title="快速开始" class="categoryLinkLabel_W154">快速开始</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Debugging Guide/debug_guide"><span title="调试" class="categoryLinkLabel_W154">调试</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/FAQ/qa_issues"><span title="答疑" class="categoryLinkLabel_W154">答疑</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="使用指南" class="categoryLinkLabel_W154">使用指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="配置" class="categoryLinkLabel_W154">配置</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Pipeline/agent_pipeline_start"><span title="流水线" class="categoryLinkLabel_W154">流水线</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Algorithms/GRPO"><span title="算法" class="categoryLinkLabel_W154">算法</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Agentic/Tool_Use"><span title="Agentic" class="categoryLinkLabel_W154">Agentic</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/async_parallel_rollout"><span title="高级特性" class="categoryLinkLabel_W154">高级特性</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/async_parallel_rollout"><span title="Agentic 异步并行 Rollout" class="linkLabel_WmDU">Agentic 异步并行 Rollout</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/async_training"><span title="ROLL 异步训练功能使用指南" class="linkLabel_WmDU">ROLL 异步训练功能使用指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/checkpoint_and_resume"><span title="检查点保存与恢复指南" class="linkLabel_WmDU">检查点保存与恢复指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/dynamic_batching"><span title="ROLL Dynamic Batching" class="linkLabel_WmDU">ROLL Dynamic Batching</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/megatron_convert_2_hf"><span title="MCoreAdapter 模型转换为 Hugging Face 格式" class="linkLabel_WmDU">MCoreAdapter 模型转换为 Hugging Face 格式</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/offload_reload_control"><span title="GPU 时分复用控制指南" class="linkLabel_WmDU">GPU 时分复用控制指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/sequence_packing"><span title="ROLL SEQUENCE PACKING" class="linkLabel_WmDU">ROLL SEQUENCE PACKING</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Tracker &amp; Metrics/trackers_and_metrics"><span title="Tracker 和 Metrics" class="categoryLinkLabel_W154">Tracker 和 Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Hardware Support/ascend_usage"><span title="硬件支持" class="categoryLinkLabel_W154">硬件支持</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="开发" class="categoryLinkLabel_W154">开发</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="架构" class="categoryLinkLabel_W154">架构</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/support_new_models"><span title="开发者指南" class="categoryLinkLabel_W154">开发者指南</span></a></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/ROLL/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">使用指南</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">高级特性</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">ROLL Dynamic Batching</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>ROLL Dynamic Batching</h1></header>
<p>ROLL 框架支持对 Rollout Batch 做 <strong>Dynamic Batching</strong> 功能，尽量减少无效 token 计算，使得计算效率更高，本文档详细介绍如何使用这一功能。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="术语列表">术语列表<a href="#术语列表" class="hash-link" aria-label="术语列表的直接链接" title="术语列表的直接链接" translate="no">​</a></h2>
<ul>
<li class="">attention_mask: rollout batch中的数据，其中 <code>1</code> 表示实际需要被计算的token，<code>0</code> 表示 pad_token；</li>
<li class="">micro_batch (mbs): 模型前向处理时的微批次；</li>
<li class="">num_micro_batches: 每个mini-batch中micro_batch数量；</li>
<li class="">micro_batch_size: 每个微批次中序列数量；</li>
<li class="">micro_batch_seqlen: 每个微批次中序列长度；</li>
<li class="">dp_size, dp_rank, shard: 数据并行时的并行数量，以及在并行组中的编号，每个数据并行组中的训练数据；</li>
<li class="">vpp: Virtual Pipeline Model Parallel，Megatron-LM框架中支持的一种高效流水线并行技术；</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="简介">简介<a href="#简介" class="hash-link" aria-label="简介的直接链接" title="简介的直接链接" translate="no">​</a></h2>
<p>在RL训练场景中，每次rollout出来的数据具有十分显著的长尾效应，即序列长度不一致，尤其在Agentic Pipeline中，由于训练数据是多轮和Env相互产生的，导致这种长尾现象更为显著。</p>
<p>在训练时，通常会将一个rollout batch中的所有样本按照一个<code>max_len</code> pad到最长，这些pad_token也会参与计算，造成计算资源浪费；</p>
<p>为了解决这一问题，提高计算效率，Dynamic Batching技术核心思路是：</p>
<ul>
<li class="">对整个rollout batch中的样本在DP Rank维度上按照token数进行划分，使得计算资源尽量均衡；</li>
<li class="">改变样本中序列的顺序，使得临近的样本，长度尽量接近，能够去掉尽量多的pad token；</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="示例">示例<a href="#示例" class="hash-link" aria-label="示例的直接链接" title="示例的直接链接" translate="no">​</a></h2>
<p>下面通过一个例子，简要说明 ROLL 中 Dynamic Batching 流程</p>
<p>假设 <code>dp_size=2</code>, <code>num_seqs=8</code>,  <code>max_tokens_microbatch=10</code>, <code>sequence_length_round=2</code></p>
<p>原始输入 <code>attention_mask</code> 如下</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">attention_mask:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 0, 0, 0, 0, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]</span><br></span></code></pre></div></div>
<p>其对应的 <code>seq_lens</code> 如下:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">seq_lens:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[7, 6, 8, 5, 1, 3, 8, 6]</span><br></span></code></pre></div></div>
<p>可见序列之 间的实际 token 数量是不均衡的，会浪费大量 GPU 时间在处理 <code>pad_token</code> 上</p>
<p>为了计算效率，ROLL Dynamic Batching 基于下面的步骤来消除 <code>micro_batch</code> 中的 pad_token，从而达到资源利用的最大化。</p>
<ol>
<li class="">shard表示每个<code>dp_rank</code>中的训练数据，默认按照顺序切分，在Dynamic Batching中会基于序列实际长度排序并切分shard，使得 <code>dp_rank</code> 之间的tokens数均匀</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># seq_lens 排序后:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[1, 3, 5, 6, 6, 7, 8, 8]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># 切分成dp_size个shard</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  [1, 5, 6, 8]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard1:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  [3, 6, 7, 8]</span><br></span></code></pre></div></div>
<ol start="2">
<li class="">对于每个shard划分 <code>micro_batch</code>；</li>
</ol>
<p>划分时需要考虑如下两个参数：</p>
<ul>
<li class="">max_tokens_per_microbatch: 每个micro_batch中最大token数量，<code>micro_batch_size * micro_batch_seqlen</code> 不能超过这个值，如果超过需要再生成一个新的 <code>micro_batch</code>；</li>
<li class="">sequence_length_round: <code>micro_batch_seqlen</code> 需要能够被这个值整除；假设micro_batch中的序列长度为 <code>[200, 240]</code>，<code>sequence_length_round=64</code>，则这个micro_batch需要pad成<code>[256, 256]</code>；</li>
</ul>
<p>Dynamic Batching的划分shard流程就是找到小于max_tokens_per_microbatch的micro_batch中tokens数量最大的划分。且保证每个micro_batch的序列长度需要根据实际长度pad到 <code>sequence_length_round</code> 的倍数；</p>
<p>具体如下所示：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs0: # padding长度6 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 0, 0, 0, 0, 0 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     1, 1, 1, 1, 1, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs1: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs2: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 1]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard1:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs0: # padding长度6</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 0, 0, 0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">     1, 1, 1, 1, 1, 1]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs1: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs2: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 1]</span><br></span></code></pre></div></div>
<p>在这个随机mask矩阵中，原来token总数为 <code>attention_mask.size(0) * attention_mask.size(1) = 80</code>，经过 Dynamic Batching 之后的 token 数量为：56，remove掉了 <code>30%</code> 的 pad_token</p>
<ol start="3">
<li class="">支持Virtual Pipelie Model Parallel，优先拆分tokens数量多且micro_batch_size &gt; 1的micro_batch，使得micro_batch数量为pp_size整除倍(支持megatron)</li>
</ol>
<p>原来的这个例子中 <code>num_micro_batches</code> 不能够被 <code>pp_size</code> 整除，因此选择 <code>mbs0</code>，将其拆分成两个 mbs，如下所示：</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard0:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs0: # padding长度6 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 0, 0, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs1: # padding长度6 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs2: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs3: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 1]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">shard1:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs0: # padding长度6</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 0, 0, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs1: # padding长度6</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs2: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 0]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mbs3: # padding长度8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    [1, 1, 1, 1, 1, 1, 1, 1]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="参数配置">参数配置<a href="#参数配置" class="hash-link" aria-label="参数配置的直接链接" title="参数配置的直接链接" translate="no">​</a></h2>
<p>与 Dynamic Batching 相关的参数如下，分为 train 和 infer 两个部分</p>
<ul>
<li class="">Train<!-- -->
<ul>
<li class="">use_dynamic_batching_in_train: 是否在 <code>train_step</code> 时开启；</li>
<li class="">max_tokens_per_microbatch_in_train: 训练时每个 micro_batch 最大 token 数量；</li>
<li class="">sequence_length_round_in_train: 训练时每个 micro_batch 的序列长度需要能被这个参数整除，需要能够被 <code>tensor_model_parallel_size * context_parallel_size</code> 整除，一般取 128,64 即可；</li>
</ul>
</li>
<li class="">Infer<!-- -->
<ul>
<li class="">use_dynamic_batching_in_infer: 是否在 <code>compute_log_probs</code> 等不需要梯度更新的环节开启；</li>
<li class="">max_tokens_per_microbatch_in_infer: 与train中含义相同，根据显存消耗情况可以大一些；</li>
<li class="">sequence_length_round_in_infer: 与train中含义相同；</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="完整配置">完整配置<a href="#完整配置" class="hash-link" aria-label="完整配置的直接链接" title="完整配置的直接链接" translate="no">​</a></h2>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 同时开启 Dynamic Batching 和 Context Parallel 时推荐使用 flash_attn</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">system_envs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">NVTE_FLASH_ATTN</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;1&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">NVTE_FUSED_ATTN</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;0&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">NVTE_UNFUSED_ATTN</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;0&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">attn_implementation</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> fa2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">disable_gradient_checkpointing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">false</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">model_type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token null important">~</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">learning_rate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1.0e-6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">weight_decay</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">per_device_train_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">gradient_accumulation_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">warmup_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">lr_scheduler_type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> cosine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">data_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> qwen2_5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_train</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">pipeline_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">expert_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">use_distributed_optimizer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">infer_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">use_dynamic_batching_in_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">max_tokens_per_microbatch_in_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8192</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">sequence_length_round_in_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">use_dynamic_batching_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">max_tokens_per_microbatch_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">16384</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">sequence_length_round_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">disable_gradient_checkpointing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">generating_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">max_new_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)"># single-turn response length</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">top_p</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">top_k</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">num_beams</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">num_return_sequences</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">data_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> qwen2_5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">block_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">load_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> auto</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">reference</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">attn_implementation</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> fa2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">disable_gradient_checkpointing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">model_type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token null important">~</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">data_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> qwen2_5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_infer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token null important">~</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">8))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">infer_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">use_dynamic_batching_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">max_tokens_per_microbatch_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">16384</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">sequence_length_round_in_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/User Guides/Advanced Features/dynamic_batching.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最后<!-- -->于 <b><time datetime="2026-02-09T13:05:30.000Z" itemprop="dateModified">2026年2月9日</time></b> <!-- -->更新</span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/checkpoint_and_resume"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">检查点保存与恢复指南</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/megatron_convert_2_hf"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">MCoreAdapter 模型转换为 Hugging Face 格式</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#术语列表" class="table-of-contents__link toc-highlight">术语列表</a></li><li><a href="#简介" class="table-of-contents__link toc-highlight">简介</a></li><li><a href="#示例" class="table-of-contents__link toc-highlight">示例</a></li><li><a href="#参数配置" class="table-of-contents__link toc-highlight">参数配置</a></li><li><a href="#完整配置" class="table-of-contents__link toc-highlight">完整配置</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/single_node_quick_start">ROLL单机实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide">配置指南</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
</body>
</html>