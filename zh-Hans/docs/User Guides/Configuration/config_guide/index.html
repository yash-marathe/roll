<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-User Guides/Configuration/config_guide" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">ROLL 配置指南 | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ROLL 配置指南 | ROLL"><meta data-rh="true" name="description" content="ROLL 框架通过 YAML 配置文件来定义实验参数。本文档将详细介绍配置项的含义和使用方法。"><meta data-rh="true" property="og:description" content="ROLL 框架通过 YAML 配置文件来定义实验参数。本文档将详细介绍配置项的含义和使用方法。"><link data-rh="true" rel="icon" href="https://img.alicdn.com/imgextra/i4/O1CN01bo6EZl2192CAIjFwE_!!6000000006941-2-tps-465-367.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/User Guides/Configuration/config_guide" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"ROLL 配置指南","item":"https://alibaba.github.io/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D6R4GXHVFP"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D6R4GXHVFP",{anonymize_ip:!0})</script><link rel="stylesheet" href="/ROLL/zh-Hans/assets/css/styles.f65cd7c3.css">
<script src="/ROLL/zh-Hans/assets/js/runtime~main.922e8084.js" defer="defer"></script>
<script src="/ROLL/zh-Hans/assets/js/main.5f520f84.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"dark"),document.documentElement.setAttribute("data-theme-choice",t||"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav class="navbar navbar--fixed-top navbar_MONK"><div class="navbar__inner"><div class="logoWrap_HHlA navbar__items"><div class="logo_Ufb2"><div class="ant-image css-zmd3lp" style="width:40px;height:32px"><img alt="ROLL" class="ant-image-img css-zmd3lp" style="height:32px" src="https://img.alicdn.com/imgextra/i3/O1CN016Mlxas1MHNA3NEbZ0_!!6000000001409-2-tps-465-367.png" width="40" height="32"></div></div><div><div class="title_E_95">ROLL</div><div class="subTitle_M9Ik">像一名强化学习算法开发者一样</div></div></div><div class="navbar__items navbar__items--right"><a href="/ROLL/zh-Hans/" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">首页</a><a href="/ROLL/zh-Hans/#core" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">核心算法</a><a href="/ROLL/zh-Hans/#research" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">开源社区</a><a href="/ROLL/zh-Hans/docs/Overview" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3 primary_vbUC" tabindex="0" aria-disabled="false">文档</a><a href="https://github.com/alibaba/ROLL" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Github</span><span role="img" aria-label="export" class="anticon anticon-export"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="export" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 912H144c-17.7 0-32-14.3-32-32V144c0-17.7 14.3-32 32-32h360c4.4 0 8 3.6 8 8v56c0 4.4-3.6 8-8 8H184v656h656V520c0-4.4 3.6-8 8-8h56c4.4 0 8 3.6 8 8v360c0 17.7-14.3 32-32 32zM770.87 199.13l-52.2-52.2a8.01 8.01 0 014.7-13.6l179.4-21c5.1-.6 9.5 3.7 8.9 8.9l-21 179.4c-.8 6.6-8.9 9.4-13.6 4.7l-52.4-52.4-256.2 256.2a8.03 8.03 0 01-11.3 0l-42.4-42.4a8.03 8.03 0 010-11.3l256.1-256.3z"></path></svg></span></a><button type="button" class="ant-btn css-zmd3lp ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-dropdown-trigger language_XaW5"><span class="ant-btn-icon"><span role="img" aria-label="global" class="anticon anticon-global"><svg viewBox="64 64 896 896" focusable="false" data-icon="global" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M854.4 800.9c.2-.3.5-.6.7-.9C920.6 722.1 960 621.7 960 512s-39.4-210.1-104.8-288c-.2-.3-.5-.5-.7-.8-1.1-1.3-2.1-2.5-3.2-3.7-.4-.5-.8-.9-1.2-1.4l-4.1-4.7-.1-.1c-1.5-1.7-3.1-3.4-4.6-5.1l-.1-.1c-3.2-3.4-6.4-6.8-9.7-10.1l-.1-.1-4.8-4.8-.3-.3c-1.5-1.5-3-2.9-4.5-4.3-.5-.5-1-1-1.6-1.5-1-1-2-1.9-3-2.8-.3-.3-.7-.6-1-1C736.4 109.2 629.5 64 512 64s-224.4 45.2-304.3 119.2c-.3.3-.7.6-1 1-1 .9-2 1.9-3 2.9-.5.5-1 1-1.6 1.5-1.5 1.4-3 2.9-4.5 4.3l-.3.3-4.8 4.8-.1.1c-3.3 3.3-6.5 6.7-9.7 10.1l-.1.1c-1.6 1.7-3.1 3.4-4.6 5.1l-.1.1c-1.4 1.5-2.8 3.1-4.1 4.7-.4.5-.8.9-1.2 1.4-1.1 1.2-2.1 2.5-3.2 3.7-.2.3-.5.5-.7.8C103.4 301.9 64 402.3 64 512s39.4 210.1 104.8 288c.2.3.5.6.7.9l3.1 3.7c.4.5.8.9 1.2 1.4l4.1 4.7c0 .1.1.1.1.2 1.5 1.7 3 3.4 4.6 5l.1.1c3.2 3.4 6.4 6.8 9.6 10.1l.1.1c1.6 1.6 3.1 3.2 4.7 4.7l.3.3c3.3 3.3 6.7 6.5 10.1 9.6 80.1 74 187 119.2 304.5 119.2s224.4-45.2 304.3-119.2a300 300 0 0010-9.6l.3-.3c1.6-1.6 3.2-3.1 4.7-4.7l.1-.1c3.3-3.3 6.5-6.7 9.6-10.1l.1-.1c1.5-1.7 3.1-3.3 4.6-5 0-.1.1-.1.1-.2 1.4-1.5 2.8-3.1 4.1-4.7.4-.5.8-.9 1.2-1.4a99 99 0 003.3-3.7zm4.1-142.6c-13.8 32.6-32 62.8-54.2 90.2a444.07 444.07 0 00-81.5-55.9c11.6-46.9 18.8-98.4 20.7-152.6H887c-3 40.9-12.6 80.6-28.5 118.3zM887 484H743.5c-1.9-54.2-9.1-105.7-20.7-152.6 29.3-15.6 56.6-34.4 81.5-55.9A373.86 373.86 0 01887 484zM658.3 165.5c39.7 16.8 75.8 40 107.6 69.2a394.72 394.72 0 01-59.4 41.8c-15.7-45-35.8-84.1-59.2-115.4 3.7 1.4 7.4 2.9 11 4.4zm-90.6 700.6c-9.2 7.2-18.4 12.7-27.7 16.4V697a389.1 389.1 0 01115.7 26.2c-8.3 24.6-17.9 47.3-29 67.8-17.4 32.4-37.8 58.3-59 75.1zm59-633.1c11 20.6 20.7 43.3 29 67.8A389.1 389.1 0 01540 327V141.6c9.2 3.7 18.5 9.1 27.7 16.4 21.2 16.7 41.6 42.6 59 75zM540 640.9V540h147.5c-1.6 44.2-7.1 87.1-16.3 127.8l-.3 1.2A445.02 445.02 0 00540 640.9zm0-156.9V383.1c45.8-2.8 89.8-12.5 130.9-28.1l.3 1.2c9.2 40.7 14.7 83.5 16.3 127.8H540zm-56 56v100.9c-45.8 2.8-89.8 12.5-130.9 28.1l-.3-1.2c-9.2-40.7-14.7-83.5-16.3-127.8H484zm-147.5-56c1.6-44.2 7.1-87.1 16.3-127.8l.3-1.2c41.1 15.6 85 25.3 130.9 28.1V484H336.5zM484 697v185.4c-9.2-3.7-18.5-9.1-27.7-16.4-21.2-16.7-41.7-42.7-59.1-75.1-11-20.6-20.7-43.3-29-67.8 37.2-14.6 75.9-23.3 115.8-26.1zm0-370a389.1 389.1 0 01-115.7-26.2c8.3-24.6 17.9-47.3 29-67.8 17.4-32.4 37.8-58.4 59.1-75.1 9.2-7.2 18.4-12.7 27.7-16.4V327zM365.7 165.5c3.7-1.5 7.3-3 11-4.4-23.4 31.3-43.5 70.4-59.2 115.4-21-12-40.9-26-59.4-41.8 31.8-29.2 67.9-52.4 107.6-69.2zM165.5 365.7c13.8-32.6 32-62.8 54.2-90.2 24.9 21.5 52.2 40.3 81.5 55.9-11.6 46.9-18.8 98.4-20.7 152.6H137c3-40.9 12.6-80.6 28.5-118.3zM137 540h143.5c1.9 54.2 9.1 105.7 20.7 152.6a444.07 444.07 0 00-81.5 55.9A373.86 373.86 0 01137 540zm228.7 318.5c-39.7-16.8-75.8-40-107.6-69.2 18.5-15.8 38.4-29.7 59.4-41.8 15.7 45 35.8 84.1 59.2 115.4-3.7-1.4-7.4-2.9-11-4.4zm292.6 0c-3.7 1.5-7.3 3-11 4.4 23.4-31.3 43.5-70.4 59.2-115.4 21 12 40.9 26 59.4 41.8a373.81 373.81 0 01-107.6 69.2z"></path></svg></span></span><span>简体中文</span></button><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div><button type="button" class="ant-btn css-zmd3lp ant-btn-text ant-btn-color-default ant-btn-variant-text ant-btn-icon-only" style="margin-left:6px"><span class="ant-btn-icon"><span role="img" aria-label="sun" style="font-size:20px" class="anticon anticon-sun"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="sun" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M548 818v126a16 16 0 01-16 16h-40a16 16 0 01-16-16V818c15.85 1.64 27.84 2.46 36 2.46 8.15 0 20.16-.82 36-2.46m205.25-115.66l89.1 89.1a16 16 0 010 22.62l-28.29 28.29a16 16 0 01-22.62 0l-89.1-89.1c12.37-10.04 21.43-17.95 27.2-23.71 5.76-5.77 13.67-14.84 23.71-27.2m-482.5 0c10.04 12.36 17.95 21.43 23.71 27.2 5.77 5.76 14.84 13.67 27.2 23.71l-89.1 89.1a16 16 0 01-22.62 0l-28.29-28.29a16 16 0 010-22.63zM512 278c129.24 0 234 104.77 234 234S641.24 746 512 746 278 641.24 278 512s104.77-234 234-234m0 72c-89.47 0-162 72.53-162 162s72.53 162 162 162 162-72.53 162-162-72.53-162-162-162M206 476c-1.64 15.85-2.46 27.84-2.46 36 0 8.15.82 20.16 2.46 36H80a16 16 0 01-16-16v-40a16 16 0 0116-16zm738 0a16 16 0 0116 16v40a16 16 0 01-16 16H818c1.64-15.85 2.46-27.84 2.46-36 0-8.15-.82-20.16-2.46-36zM814.06 180.65l28.29 28.29a16 16 0 010 22.63l-89.1 89.09c-10.04-12.37-17.95-21.43-23.71-27.2-5.77-5.76-14.84-13.67-27.2-23.71l89.1-89.1a16 16 0 0122.62 0m-581.5 0l89.1 89.1c-12.37 10.04-21.43 17.95-27.2 23.71-5.76 5.77-13.67 14.84-23.71 27.2l-89.1-89.1a16 16 0 010-22.62l28.29-28.29a16 16 0 0122.62 0M532 64a16 16 0 0116 16v126c-15.85-1.64-27.84-2.46-36-2.46-8.15 0-20.16.82-36 2.46V80a16 16 0 0116-16z"></path></svg></span></span></button></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ROLL/zh-Hans/docs/Overview"><span title="概览" class="linkLabel_WmDU">概览</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="快速入门" class="categoryLinkLabel_W154">快速入门</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="安装指南" class="categoryLinkLabel_W154">安装指南</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/multi_nodes_quick_start"><span title="快速开始" class="categoryLinkLabel_W154">快速开始</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Debugging Guide/debug_guide"><span title="调试" class="categoryLinkLabel_W154">调试</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/FAQ/qa_issues"><span title="答疑" class="categoryLinkLabel_W154">答疑</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="使用指南" class="categoryLinkLabel_W154">使用指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="配置" class="categoryLinkLabel_W154">配置</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="ROLL 配置指南" class="linkLabel_WmDU">ROLL 配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_system"><span title="ROLL 配置系统详解" class="linkLabel_WmDU">ROLL 配置系统详解</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/deepspeed"><span title="DeepSpeed 训练后端配置指南" class="linkLabel_WmDU">DeepSpeed 训练后端配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/device_mapping"><span title="ROLL 资源配置" class="linkLabel_WmDU">ROLL 资源配置</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/fp8_rollout"><span title="FP8 量化配置指南" class="linkLabel_WmDU">FP8 量化配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/lora"><span title="LoRA 微调配置指南" class="linkLabel_WmDU">LoRA 微调配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/megatron"><span title="Megatron 推理和训练后端配置指南" class="linkLabel_WmDU">Megatron 推理和训练后端配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/offpolicy_setting"><span title="Off-Policy 算法配置指南" class="linkLabel_WmDU">Off-Policy 算法配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/sglang"><span title="SGLang 推理后端配置指南" class="linkLabel_WmDU">SGLang 推理后端配置指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/vllm"><span title="vLLM 推理后端配置指南" class="linkLabel_WmDU">vLLM 推理后端配置指南</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Pipeline/agent_pipeline_start"><span title="流水线" class="categoryLinkLabel_W154">流水线</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Algorithms/GRPO"><span title="算法" class="categoryLinkLabel_W154">算法</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Agentic/Tool_Use"><span title="Agentic" class="categoryLinkLabel_W154">Agentic</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/async_parallel_rollout"><span title="高级特性" class="categoryLinkLabel_W154">高级特性</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Tracker &amp; Metrics/trackers_and_metrics"><span title="Tracker 和 Metrics" class="categoryLinkLabel_W154">Tracker 和 Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Hardware Support/ascend_usage"><span title="硬件支持" class="categoryLinkLabel_W154">硬件支持</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="开发" class="categoryLinkLabel_W154">开发</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="架构" class="categoryLinkLabel_W154">架构</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/support_new_models"><span title="开发者指南" class="categoryLinkLabel_W154">开发者指南</span></a></div></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/ROLL/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">使用指南</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">配置</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">ROLL 配置指南</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>ROLL 配置指南</h1></header>
<p>ROLL 框架通过 YAML 配置文件来定义实验参数。本文档将详细介绍配置项的含义和使用方法。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="pipeline-配置">Pipeline 配置<a href="#pipeline-配置" class="hash-link" aria-label="Pipeline 配置的直接链接" title="Pipeline 配置的直接链接" translate="no">​</a></h2>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">exp_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;agentic_pipeline&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">seed</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">42</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">rpc_timeout</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">3600</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">logging_dir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> ./output/logs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">output_dir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> ./output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">render_save_dir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> /data/oss_bucket_0/yali/output/render</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">system_envs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">USE_MODELSCOPE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;1&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">track_with</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> tensorboard</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">tracker_kwargs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">log_dir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> /data/oss_bucket_0/yali/llm/tensorboard/roll_exp/agentic_sokoban</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">num_gpus_per_node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">max_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1024</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">save_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">10000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">logging_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">eval_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">resume_from_checkpoint</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">false</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">rollout_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">prompt_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">response_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4096</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">num_return_sequences_in_group</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="基本信息与通用配置">基本信息与通用配置<a href="#基本信息与通用配置" class="hash-link" aria-label="基本信息与通用配置的直接链接" title="基本信息与通用配置的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>exp_name</code>: 当前实验的名称，用于标识和组织输出文件、日志等。默认是从 Python 文件名派生。</li>
<li class=""><code>seed</code>: 用于初始化随机数生成器。设置固定的种子可以确保实验的可复现性。</li>
<li class=""><code>rpc_timeout</code>: 远程过程调用（RPC）的超时时长，单位为秒。用于 Ray Actor 之间通信。如果一个调用在此时间内没有响应，则会抛出超时错误。</li>
<li class=""><code>output_dir</code>: 模型预测结果和检查点（checkpoints）的输出目录。</li>
<li class=""><code>logging_dir</code>: 存储日志文件的目录。</li>
<li class=""><code>track_with</code>: 用于跟踪实验进度的工具类型。可选 wandb (Weights &amp; Biases), tensorboard (TensorBoard), swanlab 或 stdout (标准输出)。</li>
<li class=""><code>tracker_kwargs</code>: 传递给所选跟踪器类的额外关键字参数（字典）。例如，WandB 的 API 密钥、项目名称等。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="训练评估流程配置">训练/评估流程配置<a href="#训练评估流程配置" class="hash-link" aria-label="训练/评估流程配置的直接链接" title="训练/评估流程配置的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>max_steps</code>: 训练的最大步数。如果大于 0，则设置流水线执行的总步数。训练将在达到此步数时停止。</li>
<li class=""><code>save_steps</code>: 保存模型检查点的频率。每隔 X 个更新步数保存一次模型检查点。</li>
<li class=""><code>logging_steps</code>: 记录训练指标的频率。每隔 X 个更新步数记录一次训练信息（例如损失、指标等）。</li>
<li class=""><code>eval_steps</code>: 评估频率。每隔 X 个更新步数执行一次评估。</li>
<li class=""><code>resume_from_checkpoint</code>: 是否从检查点恢复训练。如果设置为 True，则从 output_dir 中最近的检查点恢复。</li>
<li class=""><code>checkpoint_config</code>: 检查点相关的配置信息，这个字段会被写入 worker_config。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="批处理大小与序列长度配置">批处理大小与序列长度配置<a href="#批处理大小与序列长度配置" class="hash-link" aria-label="批处理大小与序列长度配置的直接链接" title="批处理大小与序列长度配置的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>rollout_batch_size</code>: 在每次推理批次中，要进行 Rollout 的样本数量。</li>
<li class=""><code>val_batch_size</code>: 在每次验证批次中，要进行 Rollout 的样本数量。</li>
<li class=""><code>prompt_length</code>: 提示（输入）的最大长度（以 token 为单位）。如果实际提示更短，会填充到此长度；如果更长，可能会被截断。</li>
<li class=""><code>response_length</code>: LLM 生成的响应（输出）的最大长度（以 token 为单位）。如果 LLM 生成的响应更短，会填充；如果更长，会被截断。</li>
<li class=""><code>sequence_length</code>: 要填充的最大序列长度（以 token 为单位）。这通常指 LLM 模型的总上下文窗口大小，包括提示和生成的响应。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="分布式训练配置">分布式训练配置<a href="#分布式训练配置" class="hash-link" aria-label="分布式训练配置的直接链接" title="分布式训练配置的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>local_rank</code>: 分布式训练中的本地排名（在当前节点内的排名）。对于分布式训练，通常由系统自动设置；如果不是分布式训练，则设置为 -1。</li>
<li class=""><code>num_nodes</code>: 可用于分布式训练的节点（物理服务器）数量。如果设置为 1，则表示在单个节点上进行分布式训练。</li>
<li class=""><code>num_gpus_per_node</code>: 指定每个节点上可用的 GPU 数量。当节点数量大于 1 时，此参数应请求整个节点上的 GPU 总数。确保在多节点设置中 GPU 资源分配与请求一致。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="调度与请求管理">调度与请求管理<a href="#调度与请求管理" class="hash-link" aria-label="调度与请求管理的直接链接" title="调度与请求管理的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>generate_opt_level</code>: 控制 LLM 生成（推理）的优化级别。设置为 0 时，使用基础批次生成接口；设置为 1 时，使用调度器处理请求。</li>
<li class=""><code>is_num_return_sequences_expand</code>: 是否在提示（prompts）中复制 num_return_sequences 次。如果为 True，LLM 会为每个输入提示生成多个独立的响应，而不是只生成一个。</li>
<li class=""><code>max_running_requests</code>: 在 LLM 推理服务器上可以同时处理的最大请求数量。这限制了并行推理的并发度。</li>
<li class=""><code>is_use_additional_prompts</code>: 是否使用除常规批次大小之外的额外提示进行处理。</li>
<li class=""><code>max_additional_running_prompts</code>: 在 batch_size 之外，可以额外运行的提示数量。这可能用于处理一些特殊或低优先级的请求，而不会阻塞主批次。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="rlvr-pipeline-常用配置">RLVR Pipeline 常用配置<a href="#rlvr-pipeline-常用配置" class="hash-link" aria-label="RLVR Pipeline 常用配置的直接链接" title="RLVR Pipeline 常用配置的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>num_return_sequences_in_group</code>: 对于每个提示，LLM 要生成序列的数量。请注意，它的值会按比例扩大实际的训练全局批次样本量。换句话说，实际的训练全局批次大小等于 <code>num_return_sequences_in_group</code> * <code>rollout_batch_size</code>。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="ppo算法核心参数">PPO算法核心参数<a href="#ppo算法核心参数" class="hash-link" aria-label="PPO算法核心参数的直接链接" title="PPO算法核心参数的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>ppo_epochs</code>: 每个样本批次（即收集到一批经验数据后）进行优化的迭代次数。在一个 PPO 训练循环中，Agent 首先收集数据，然后利用这些数据进行多次梯度更新。</li>
<li class=""><code>max_grad_norm</code>: 梯度裁剪的最大范数。用于防止梯度爆炸。</li>
<li class=""><code>l2</code>: L2 正则化系数，用于惩罚大的权重值以防止过拟合。</li>
<li class=""><code>lambd</code>: 广义优势估计（GAE, Generalized Advantage Estimation）中的 lambda 参数。控制偏差-方差权衡。值接近 1 减少方差，值接近 0 减少偏差。</li>
<li class=""><code>gamma</code>: 强化学习中的折扣因子。用于折算未来奖励的重要性。值越接近 1，模型越重视长期奖励。</li>
<li class=""><code>kl_penalty</code>: KL 散度惩罚的计算方式。KL 散度用于衡量新旧策略之间的差异，防止策略更新过大。<!-- -->
<ul>
<li class="">&#x27;kl&#x27;: model_logp - ref_logp (新策略 log 概率减去参考策略 log 概率)。</li>
<li class="">&#x27;abs&#x27;: abs(kl) (KL 散度的绝对值)。</li>
<li class="">&#x27;mse&#x27;: mse(kl) (KL 散度的均方误差)。</li>
<li class="">&#x27;full&#x27;: 分布中所有 token 的实际 KL 散度。</li>
</ul>
</li>
<li class=""><code>init_kl_coef</code>: 初始的 KL 惩罚系数（用于自适应和线性控制）。这个系数乘以 KL 散度项，作为损失的一部分。</li>
<li class=""><code>kl_horizon</code>: 自适应 KL 控制的周期。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="ppo奖励优势处理">PPO奖励/优势处理<a href="#ppo奖励优势处理" class="hash-link" aria-label="PPO奖励/优势处理的直接链接" title="PPO奖励/优势处理的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>use_reward_scaling</code>: 是否对奖励进行缩放。</li>
<li class=""><code>add_len_reward</code>: 是否添加基于序列长度的奖励。</li>
<li class=""><code>reward_clip</code>: 对奖励进行裁剪的值，防止极端奖励影响训练。</li>
<li class=""><code>difficulty_loss_weight</code>: 是否使用难度损失权重。</li>
<li class=""><code>length_loss_weight</code>: 是否使用长度损失权重。</li>
<li class=""><code>use_reward_norm</code>: 是否使用奖励归一化。仅当 use_reward_scaling 为 True 时适用。</li>
<li class=""><code>whiten_rewards</code>: 在计算优势值之前，是否对奖励进行白化处理（使其均值为 0，方差为 1）。</li>
<li class=""><code>whiten_advantages</code>: 是否对优势值进行白化处理。有助于稳定训练。</li>
<li class=""><code>advantage_clip</code>: 优势值裁剪的范围。</li>
<li class=""><code>adv_estimator</code>: 优势值的估计方法。<!-- -->
<ul>
<li class="">&#x27;gae&#x27;: 广义优势估计（GAE）。</li>
<li class="">&#x27;reinforce&#x27;: REINFORCE 算法中的优势估计。</li>
<li class="">&#x27;grpo&#x27;: Grouped Relative Policy Optimization 中的优势估计。</li>
</ul>
</li>
<li class=""><code>norm_mean_type</code>: 奖励归一化的均值计算方式。<!-- -->
<ul>
<li class="">&#x27;batch&#x27;: 批次内的所有奖励的均值。</li>
<li class="">&#x27;group&#x27;: 提示组内部的均值。</li>
<li class="">&#x27;running&#x27;: 使用动态更新的统计量进行均值计算。</li>
<li class="">None: 归一化的时候不减去均值。</li>
</ul>
</li>
<li class=""><code>norm_std_type</code>: 奖励归一化的标准差计算方式。<!-- -->
<ul>
<li class="">&#x27;batch&#x27;: 批次内的所有奖励的标准差。</li>
<li class="">&#x27;group&#x27;: 提示组内部的标准差。</li>
<li class="">&#x27;running&#x27;: 使用动态更新的统计量进行标准差计算。</li>
<li class="">None: 归一化的时候不除以标准差。</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="ppo-损失函数组件">PPO 损失函数组 件<a href="#ppo-损失函数组件" class="hash-link" aria-label="PPO 损失函数组件的直接链接" title="PPO 损失函数组件的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>add_token_level_kl</code>: 是否添加 token 级别的 KL 散度惩罚。</li>
<li class=""><code>critic_warmup</code>: Critic 模型在正式训练开始前的预训练步数。</li>
<li class=""><code>use_kl_loss</code>: 是否使用 KL 散度损失。</li>
<li class=""><code>kl_loss_coef</code>: KL 散度损失项的系数。</li>
<li class=""><code>entropy_loss_coef</code>: 熵损失项的系数。增加熵可以鼓励策略探索。</li>
<li class=""><code>sft_loss_coef</code>: SFT (Supervised Fine-tuning) 损失的系数，用于正样本（例如，如果有监督微调的数据）。</li>
<li class=""><code>use_topr_loss</code>: 是否使用 TPRO (Trigonometric Policy Regularization with Offset) 损失。</li>
<li class=""><code>rl_loss_coef</code>: 强化学习损失项的系数。</li>
<li class=""><code>dual_clip_loss</code>: 是否使用双裁剪损失。PPO 损失函数的一种变体。</li>
<li class=""><code>loss_agg_mode</code>: 损失聚合的方式。<!-- -->
<ul>
<li class="">&#x27;token-mean&#x27;: Token 级别的均值。</li>
<li class="">&#x27;seq-mean-token-sum&#x27;: 序列级别的均值，token 级别的求和。</li>
<li class="">&#x27;seq-mean-token-mean&#x27;: 序列级别和 token 级别的均值。</li>
<li class="">&#x27;seq-mean-token-sum-norm&#x27;: 序列级别的均值，token 级别的归一化求和。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="agentic-pipeline-配置">Agentic Pipeline 配置<a href="#agentic-pipeline-配置" class="hash-link" aria-label="Agentic Pipeline 配置的直接链接" title="Agentic Pipeline 配置的直接链接" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="奖励归一化配置">奖励归一化配置<a href="#奖励归一化配置" class="hash-link" aria-label="奖励归一化配置的直接链接" title="奖励归一化配置的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>grouping</code>: 定义奖励归一化时的分组方式，可选 &#x27;state&#x27;、&#x27;batch&#x27;和&#x27;inductive&#x27;。</li>
<li class=""><code>method</code>: 定义具体的归一化方法，可选 &#x27;asym_clip&#x27;、&#x27;identity&#x27;和&#x27;mean_std&#x27;。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="环境管理器配置">环境管理器配置<a href="#环境管理器配置" class="hash-link" aria-label="环境管理器配置的直接链接" title="环境管理器配置的直接链接" translate="no">​</a></h4>
<ul>
<li class="">env_groups: 训练期间环境组的数量。每个环境组可能并行运行。</li>
<li class="">group_size: 在同一个组内，环境配置和环境种子（prompt）被确保是相同的。这对于控制实验变量和确保可复现性很重要。</li>
<li class="">tags: 环境的标签列表，用于标识和选择要使用的环境类型（例如 &quot;SimpleSokoban&quot;）。</li>
<li class="">n_groups: 如果未设置，所有环境名称将平均分配到组中。在同一个组中，环境配置和环境种子（prompt）在每次生成中都是相同的。</li>
<li class="">max_traj_per_env: 每个环境可以 Rollout 的最大轨迹数量。-1 表示没有限制。</li>
<li class="">format_penalty: 当 LLM 生成的响应不符合预期格式时所施加的惩罚值。这是一个负值，会降低不合格响应的奖励。</li>
<li class="">worker_cls: 环境管理器将使用的具体工作器类的路径。这个类实现了环境交互的逻辑。</li>
</ul>
<p>有关 RLVR/Agentic Pipeline配置和Reward设置的更多详细信息，还可以参阅 <a class="" href="/ROLL/zh-Hans/docs/User Guides/Pipeline/rlvr_pipeline_start">RLVR Pipeline Start</a> 和 <a class="" href="/ROLL/zh-Hans/docs/User Guides/Pipeline/agentic_pipeline_start">Agentic Pipeline Start</a></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="worker配置">Worker配置<a href="#worker配置" class="hash-link" aria-label="Worker配置的直接链接" title="Worker配置的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="actortrainactorinfercriticreference">ActorTrain/ActorInfer/Critic/Reference<a href="#actortrainactorinfercriticreference" class="hash-link" aria-label="ActorTrain/ActorInfer/Critic/Reference的直接链接" title="ActorTrain/ActorInfer/Critic/Reference的直接链接" translate="no">​</a></h3>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">disable_gradient_checkpointing</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">learning_rate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1.0e-6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">weight_decay</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">per_device_train_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">gradient_accumulation_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">32</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">warmup_steps</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">20</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">data_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> native</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">file_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> xxx/train.json</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> instruction</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_train  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 训练策略：deepspeed_train 或 megatron_train</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">pipeline_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">expert_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">infer_batch_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用的设备 ID 列表</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">generating_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">max_new_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">response_length</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.99</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 推理策略：vllm, sglang 或 hf_infer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.6</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">block_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">16</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">max_model_len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">num_gpus_per_worker</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 每个 worker 分配的 GPU 数 量</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">reference</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> megatron_infer</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_model_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">16))</span><br></span></code></pre></div></div>
<ul>
<li class=""><code>world_size</code>: 参与这个特定角色集群的总数量。例如，如果有多个 actor_train 实例，这就是它们的总数。</li>
<li class=""><code>device_mapping</code>: 当 worker 进行训练时要使用的设备 ID 列表。 配置所有使用 GPU 的 worker，包括<code>actor_train</code>、<code>actor_infer</code>、<code>critic</code> 和 <code>reference</code>。例如 list(range(0,16)) 表示使用 ID 为 0 到 15 的 GPU。</li>
<li class=""><code>num_gpus_per_worker</code>: 分配给每个 worker 的 GPU 数量。 仅适用于<code>actor_infer</code>。如果一个 actor_infer 需要多个 GPU（例如用于模型并行），则设置此参数。</li>
<li class=""><code>model_update_frequency</code>: 模型更新的频率。例如，每多少步或每多少个事件触发一次模型更新。</li>
<li class=""><code>infer_batch_size</code>: 用于推理或计算 logprobs 时的批次大小。 这通常是单个推理请求的内部批次大小。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="模型参数-model_args">模型参数 (<strong>model_args</strong>)<a href="#模型参数-model_args" class="hash-link" aria-label="模型参数-model_args的直接链接" title="模型参数-model_args的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>model_args.dtype</code>: 设置模型的数据类型，可以是 fp32 (单精度浮点数), bf16 (BFloat16),   或 fp16 (半精度浮点数)。如果不设置，则使用配置的 torch_dtype。选择合适的数据类型可以平衡计算速度、内存消耗和精度。</li>
<li class=""><code>model_args.disable_gradient_checkpointing</code>: 禁用梯度检查点。仅当 <code>actor_train</code> 的 <code>strategy_name</code> 为 <code>deepspeed_train</code> 时适用。梯度检查点是一种内存优化技术，通过在反向传播时重新计算部分激活值来减少显存占用。禁用它会增加内存消耗但可能略微加速计算。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="数据参数-data_args">数据参数 (<strong>data_args</strong>)<a href="#数据参数-data_args" class="hash-link" aria-label="数据参数-data_args的直接链接" title="数据参数-data_args的直接链接" translate="no">​</a></h3>
<p>如何配置<code>actor_train</code>下的 data_args：</p>
<ul>
<li class=""><code>data_args.template</code>: 用于在训练和推理期间构建提示的聊天模板。设置为<code>native</code>时，将使用分词器（tokenizer）的默认聊天模板<code>tokenizer.apply_chat_template</code>来构建提示。</li>
<li class=""><code>data_args.file_name</code>: 训练数据的文件路径。支持的格式包括 JSON、JSONL 和 CSV。</li>
<li class=""><code>data_args.prompt</code>: 在数据文件中用作提示的列名。</li>
<li class=""><code>data_args.messages</code>: 在数据文件中用作消息的列名（与 prompt 冲突，两者只能选其一）。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="生成参数-generating_args">生成参数 (<strong>generating_args</strong>)<a href="#生成参数-generating_args" class="hash-link" aria-label="生成参数-generating_args的直接链接" title="生成参数-generating_args的直接链接" translate="no">​</a></h3>
<p>如何配置<code>actor_infer</code>下的 generating_args：</p>
<ul>
<li class=""><code>generating_args.max_new_tokens</code>: 生成文本的最大长度（以 token  为单位）。这限制了 LLM 每次推理调用可以输出多少新内容。</li>
<li class=""><code>generating_args.temperature</code>: 用于采样的温度值。较高的温度会使生成结果更随机、更有创造性；较低的温度会使结果更确定、更保守。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="策略参数-strategy_args">策略参数 (<strong>strategy_args</strong>)<a href="#策略参数-strategy_args" class="hash-link" aria-label="策略参数-strategy_args的直接链接" title="策略参数-strategy_args的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><code>strategy_args.strategy_name</code>: 训练/推理策略的名称。<!-- -->
<ul>
<li class="">用于训练的策略有：<code>deepspeed_train</code>（使用 DeepSpeed）或 <code>megatron_train</code>（使用 Megatron-LM）。</li>
<li class="">用于推理的策略有：<code>vllm</code>、<code>sglang</code> 或 <code>hf_infer</code>（使用 Hugging Face 的默认推理）。</li>
</ul>
</li>
<li class=""><code>strategy_args.strategy_config</code>: 训练/推理策略的详细配置，它将作为参数传递给 <code>strategy_name</code>对应的构造函数。例如，<code>strategy_config.tensor_model_parallel_size</code> 用于 <code>megatron_train</code> 策略，<code>strategy_config.gpu_memory_utilization</code> 用于 <code>vllm</code> 策略。</li>
</ul>
<p>以下列出了常用的策略配置：</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="megatron-策略配置">Megatron 策略配置<a href="#megatron-策略配置" class="hash-link" aria-label="Megatron 策略配置的直接链接" title="Megatron 策略配置的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>tensor_model_parallel_size</code>: 张量模型并行度。将模型的层内（例如矩阵乘法）的计算和内存分割到多个 GPU 上。</li>
<li class=""><code>pipeline_model_parallel_size</code>: 流水线模型并行度。将模型的不同层或层组分配到不同的 GPU 上  ，形成一个流水线，以并行处理不同批次的数据。</li>
<li class=""><code>expert_model_parallel_size</code>: : 专家模型并行度。在 Mixture-of-Experts (MoE) 模型中，将不同的专家（expert）分配到不同的 GPU 上。</li>
<li class=""><code>context_parallel_size</code>: 上下文并行度。 一种用于处理超长序列的并行策略，将序列分割后并行处理。</li>
<li class=""><code>virtual_pipeline_model_parallel_size</code>: 流水线中的虚拟流水线数量。用于改善流水线并行的效率和负载均衡。</li>
<li class=""><code>sequence_parallel</code>: 启用序列并行优化。针对 Transformer 模型中的序列处理进行优化，减少通信开销。</li>
<li class=""><code>recompute_granularity</code>: 激活值重计算粒度。用于内存优化，在反向传播时重新计算激活值以节省显存。<!-- -->
<ul>
<li class="">full: 整个 Transformer 层都会被重新计算。</li>
<li class="">selective: 仅重新计算 Transformer 层中的核心注意力部分。</li>
</ul>
</li>
<li class=""><code>moe_layer_recompute</code>: 内存优化，对 MoE 层进行检查点以节省激活内存。</li>
<li class=""><code>moe_token_dispatcher_type</code>: 使用的 token 调度器类型，选项有 &#x27;allgather&#x27; 和 &#x27;alltoall&#x27;。</li>
<li class=""><code>moe_grouped_gemm</code>: 为 MoE 专家启用分组 GEMM (通用矩阵乘法)。</li>
<li class=""><code>moe_shared_expert_overlap</code>: 启用共享专家计算与调度器通信之间的重叠。</li>
<li class=""><code>overlap_grad_reduce</code>: 如果为 true，在分布式优化器中，将梯度 All-reduce 过程与反向传播计算重叠。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="vllm-策略配置">VLLM 策略配置<a href="#vllm-策略配置" class="hash-link" aria-label="VLLM 策略配置的直接链接" title="VLLM 策略配置的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>gpu_memory_utilization</code>: 用于模 型执行器的 GPU 内存占比。 例如 0.6 表示使用 60% 的 GPU 内存。</li>
<li class=""><code>block_size</code>: token 块大小，用于连续的 token 块。影响 VLLM 内部的内存管理效率。</li>
<li class=""><code>max_model_len</code>: 模型上下文长度。如果未指定，将从模型配置中自动推导。</li>
<li class=""><code>load_format</code>: 加载模型权重的格式。由于模型会在开始时进行&quot;更新&quot;，此值可以设置为 dummy。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="sglang-策略配置">SGLang 策略配置<a href="#sglang-策略配置" class="hash-link" aria-label="SGLang 策略配置的直接链接" title="SGLang 策略配置的直接链接" translate="no">​</a></h4>
<ul>
<li class=""><code>mem_fraction_static</code>: 用于模型权重和 KV 缓存等静态内存的 GPU 内存占比。 如果 KV 缓存构建失败，请增加此值；如果 CUDA 内存不足，请减小此值。</li>
<li class=""><code>load_format</code>: 加载模型权重的格式。（同 VLLM，可设为 dummy）</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="deepspeed-策略配置">DeepSpeed 策略配置<a href="#deepspeed-策略配置" class="hash-link" aria-label="DeepSpeed 策略配置的直接链接" title="DeepSpeed 策略配置的直接链接" translate="no">​</a></h4>
<p>在<code>./examples/config/</code> 中有 DeepSpeed 配置文件，可以在默认列表中重写以进行策略配置。
例如，要使用 deepspeed_zero2 策略，请将以下内容添加到您的配置中：</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">defaults</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/envs@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero2@_here_   </span><span class="token comment" style="color:rgb(98, 114, 164)"># 引入 deepspeed_zero2 策略配置</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero3@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> ../config/deepspeed_zero3_cpuoffload@_here_</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> deepspeed_train</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> $</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">deepspeed_zero2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="训练参数-training_args">训练参数 (<strong>training_args</strong>)<a href="#训练参数-training_args" class="hash-link" aria-label="训练参数-training_args的直接链接" title="训练参数-training_args的直接链接" translate="no">​</a></h3>
<p>用于配置训练参数，例如<code>learning_rate</code>(学习率)、<code>weight_decay</code>(权重衰减)、<code>warmup_steps</code>(预热步数) 等。</p>
<ul>
<li class=""><code>training_args.per_device_train_batch_size</code>: 在每个设备上进行训练时使用的批次大小。</li>
<li class=""><code>training_args.gradient_accumulation_steps</code>: 梯度累积的步数。</li>
</ul>
<p>在 DeepSpeed 训练中，全局训练批次大小是<code>per_device_train_batch_size</code> * <code>gradient_accumulation_steps</code> * world_size (即<code>actor_train</code>/<code>critic</code>的<code>device_mapping</code>长度)。</p>
<p>在 Megatron 训练中，全局训练批次大小是<code>per_device_train_batch_size</code> * <code>gradient_accumulation_steps</code> * world_size / <code>tensor_model_parallel_size</code> / <code>pipeline_model_parallel_size</code> / <code>context_parallel_size</code> (不需要除以<code>expert_model_parallel_size</code>)。</p>
<p>如果你想在每次 Rollout 中执行一次优化步骤，则应设置<code>gradient_accumulation_steps</code>为 <code>rollout_batch_size</code> * <code>num_return_sequences_in_group</code> * <code>tensor_model_parallel_size</code> * <code>pipeline_model_parallel_size</code> * <code>context_parallel_size</code>/ <code>per_device_train_batch_size</code> / world_size.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/User Guides/Configuration/config_guide.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最后<!-- -->于 <b><time datetime="2025-11-27T06:09:53.000Z" itemprop="dateModified">2025年11月27日</time></b> <!-- -->更新</span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/zh-Hans/docs/Getting Started/FAQ/qa_issues"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">常见问题解答 (Q&amp;A)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_system"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">ROLL 配置系统详解</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#pipeline-配置" class="table-of-contents__link toc-highlight">Pipeline 配置</a><ul><li><a href="#基本信息与通用配置" class="table-of-contents__link toc-highlight">基本信息与通用配  置</a></li><li><a href="#训练评估流程配置" class="table-of-contents__link toc-highlight">训练/评估流程配置</a></li><li><a href="#批处理大小与序列长度配置" class="table-of-contents__link toc-highlight">批处理大小与序列长度配置</a></li><li><a href="#分布式训练配置" class="table-of-contents__link toc-highlight">分布式训练配置</a></li><li><a href="#调度与请求管理" class="table-of-contents__link toc-highlight">调度与请求管理</a></li><li><a href="#rlvr-pipeline-常用配置" class="table-of-contents__link toc-highlight">RLVR Pipeline 常用配置</a></li><li><a href="#agentic-pipeline-配置" class="table-of-contents__link toc-highlight">Agentic Pipeline 配置</a></li></ul></li><li><a href="#worker配置" class="table-of-contents__link toc-highlight">Worker配置</a><ul><li><a href="#actortrainactorinfercriticreference" class="table-of-contents__link toc-highlight">ActorTrain/ActorInfer/Critic/Reference</a></li><li><a href="#模型参数-model_args" class="table-of-contents__link toc-highlight">模型参数 (<strong>model_args</strong>)</a></li><li><a href="#数据参数-data_args" class="table-of-contents__link toc-highlight">数据参数 (<strong>data_args</strong>)</a></li><li><a href="#生成参数-generating_args" class="table-of-contents__link toc-highlight">生成参数 (<strong>generating_args</strong>)</a></li><li><a href="#策略参数-strategy_args" class="table-of-contents__link toc-highlight">策略参数 (<strong>strategy_args</strong>)</a></li><li><a href="#训练参数-training_args" class="table-of-contents__link toc-highlight">训练参数 (<strong>training_args</strong>)</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/single_node_quick_start">ROLL单机实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide">配置指南</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
</body>
</html>