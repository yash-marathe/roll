<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Development/Developer Guide/llm_as_judge_optimization" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">LLM as Judge 在 Agentic 环境中的优化实现 | ROLL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://alibaba.github.io/ROLL/zh-Hans/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://alibaba.github.io/ROLL/zh-Hans/docs/Development/Developer Guide/llm_as_judge_optimization"><meta data-rh="true" property="og:locale" content="zh_Hans"><meta data-rh="true" property="og:locale:alternate" content="en"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LLM as Judge 在 Agentic 环境中的优化实现 | ROLL"><meta data-rh="true" name="description" content="本文档介绍 ROLL 框架中 LLM as Judge 在 Agentic 环境中的优化实现方案，包括系统架构、调用链路、配置方法和最佳实践。"><meta data-rh="true" property="og:description" content="本文档介绍 ROLL 框架中 LLM as Judge 在 Agentic 环境中的优化实现方案，包括系统架构、调用链路、配置方法和最佳实践。"><link data-rh="true" rel="icon" href="https://img.alicdn.com/imgextra/i4/O1CN01bo6EZl2192CAIjFwE_!!6000000006941-2-tps-465-367.png"><link data-rh="true" rel="canonical" href="https://alibaba.github.io/ROLL/zh-Hans/docs/Development/Developer Guide/llm_as_judge_optimization"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/Development/Developer Guide/llm_as_judge_optimization" hreflang="en"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/zh-Hans/docs/Development/Developer Guide/llm_as_judge_optimization" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://alibaba.github.io/ROLL/docs/Development/Developer Guide/llm_as_judge_optimization" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"LLM as Judge 在 Agentic 环境中的优化实现","item":"https://alibaba.github.io/ROLL/zh-Hans/docs/Development/Developer Guide/llm_as_judge_optimization"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-D6R4GXHVFP"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D6R4GXHVFP",{anonymize_ip:!0})</script><link rel="stylesheet" href="/ROLL/zh-Hans/assets/css/styles.4016bf18.css">
<script src="/ROLL/zh-Hans/assets/js/runtime~main.138e3150.js" defer="defer"></script>
<script src="/ROLL/zh-Hans/assets/js/main.b037e3bf.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"dark"),document.documentElement.setAttribute("data-theme-choice",t||"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="跳到主要内容"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">跳到主要内容</a></div><nav class="navbar navbar--fixed-top navbar_MONK"><div class="navbar__inner"><div class="logoWrap_HHlA navbar__items"><div class="logo_Ufb2"><div class="ant-image css-plsjn" style="width:40px;height:32px"><img alt="ROLL" class="ant-image-img css-plsjn" style="height:32px" src="https://img.alicdn.com/imgextra/i3/O1CN016Mlxas1MHNA3NEbZ0_!!6000000001409-2-tps-465-367.png" width="40" height="32"></div></div><div><div class="title_E_95">ROLL</div><div class="subTitle_M9Ik">像一名强化学习算法开发者一样</div></div></div><div class="navbar__items navbar__items--right"><a href="/ROLL/zh-Hans/" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">首页</a><a href="/ROLL/zh-Hans/#core" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">核心算法</a><a href="/ROLL/zh-Hans/#research" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false">开源社区</a><a href="/ROLL/zh-Hans/docs/Overview" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3 primary_vbUC" tabindex="0" aria-disabled="false">文档</a><a href="https://github.com/alibaba/ROLL" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text btn_xSL3" tabindex="0" aria-disabled="false"><span>Github</span><span role="img" aria-label="export" class="anticon anticon-export"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="export" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M880 912H144c-17.7 0-32-14.3-32-32V144c0-17.7 14.3-32 32-32h360c4.4 0 8 3.6 8 8v56c0 4.4-3.6 8-8 8H184v656h656V520c0-4.4 3.6-8 8-8h56c4.4 0 8 3.6 8 8v360c0 17.7-14.3 32-32 32zM770.87 199.13l-52.2-52.2a8.01 8.01 0 014.7-13.6l179.4-21c5.1-.6 9.5 3.7 8.9 8.9l-21 179.4c-.8 6.6-8.9 9.4-13.6 4.7l-52.4-52.4-256.2 256.2a8.03 8.03 0 01-11.3 0l-42.4-42.4a8.03 8.03 0 010-11.3l256.1-256.3z"></path></svg></span></a><button type="button" class="ant-btn css-plsjn ant-btn-default ant-btn-color-default ant-btn-variant-outlined ant-dropdown-trigger language_XaW5"><span class="ant-btn-icon"><span role="img" aria-label="global" class="anticon anticon-global"><svg viewBox="64 64 896 896" focusable="false" data-icon="global" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M854.4 800.9c.2-.3.5-.6.7-.9C920.6 722.1 960 621.7 960 512s-39.4-210.1-104.8-288c-.2-.3-.5-.5-.7-.8-1.1-1.3-2.1-2.5-3.2-3.7-.4-.5-.8-.9-1.2-1.4l-4.1-4.7-.1-.1c-1.5-1.7-3.1-3.4-4.6-5.1l-.1-.1c-3.2-3.4-6.4-6.8-9.7-10.1l-.1-.1-4.8-4.8-.3-.3c-1.5-1.5-3-2.9-4.5-4.3-.5-.5-1-1-1.6-1.5-1-1-2-1.9-3-2.8-.3-.3-.7-.6-1-1C736.4 109.2 629.5 64 512 64s-224.4 45.2-304.3 119.2c-.3.3-.7.6-1 1-1 .9-2 1.9-3 2.9-.5.5-1 1-1.6 1.5-1.5 1.4-3 2.9-4.5 4.3l-.3.3-4.8 4.8-.1.1c-3.3 3.3-6.5 6.7-9.7 10.1l-.1.1c-1.6 1.7-3.1 3.4-4.6 5.1l-.1.1c-1.4 1.5-2.8 3.1-4.1 4.7-.4.5-.8.9-1.2 1.4-1.1 1.2-2.1 2.5-3.2 3.7-.2.3-.5.5-.7.8C103.4 301.9 64 402.3 64 512s39.4 210.1 104.8 288c.2.3.5.6.7.9l3.1 3.7c.4.5.8.9 1.2 1.4l4.1 4.7c0 .1.1.1.1.2 1.5 1.7 3 3.4 4.6 5l.1.1c3.2 3.4 6.4 6.8 9.6 10.1l.1.1c1.6 1.6 3.1 3.2 4.7 4.7l.3.3c3.3 3.3 6.7 6.5 10.1 9.6 80.1 74 187 119.2 304.5 119.2s224.4-45.2 304.3-119.2a300 300 0 0010-9.6l.3-.3c1.6-1.6 3.2-3.1 4.7-4.7l.1-.1c3.3-3.3 6.5-6.7 9.6-10.1l.1-.1c1.5-1.7 3.1-3.3 4.6-5 0-.1.1-.1.1-.2 1.4-1.5 2.8-3.1 4.1-4.7.4-.5.8-.9 1.2-1.4a99 99 0 003.3-3.7zm4.1-142.6c-13.8 32.6-32 62.8-54.2 90.2a444.07 444.07 0 00-81.5-55.9c11.6-46.9 18.8-98.4 20.7-152.6H887c-3 40.9-12.6 80.6-28.5 118.3zM887 484H743.5c-1.9-54.2-9.1-105.7-20.7-152.6 29.3-15.6 56.6-34.4 81.5-55.9A373.86 373.86 0 01887 484zM658.3 165.5c39.7 16.8 75.8 40 107.6 69.2a394.72 394.72 0 01-59.4 41.8c-15.7-45-35.8-84.1-59.2-115.4 3.7 1.4 7.4 2.9 11 4.4zm-90.6 700.6c-9.2 7.2-18.4 12.7-27.7 16.4V697a389.1 389.1 0 01115.7 26.2c-8.3 24.6-17.9 47.3-29 67.8-17.4 32.4-37.8 58.3-59 75.1zm59-633.1c11 20.6 20.7 43.3 29 67.8A389.1 389.1 0 01540 327V141.6c9.2 3.7 18.5 9.1 27.7 16.4 21.2 16.7 41.6 42.6 59 75zM540 640.9V540h147.5c-1.6 44.2-7.1 87.1-16.3 127.8l-.3 1.2A445.02 445.02 0 00540 640.9zm0-156.9V383.1c45.8-2.8 89.8-12.5 130.9-28.1l.3 1.2c9.2 40.7 14.7 83.5 16.3 127.8H540zm-56 56v100.9c-45.8 2.8-89.8 12.5-130.9 28.1l-.3-1.2c-9.2-40.7-14.7-83.5-16.3-127.8H484zm-147.5-56c1.6-44.2 7.1-87.1 16.3-127.8l.3-1.2c41.1 15.6 85 25.3 130.9 28.1V484H336.5zM484 697v185.4c-9.2-3.7-18.5-9.1-27.7-16.4-21.2-16.7-41.7-42.7-59.1-75.1-11-20.6-20.7-43.3-29-67.8 37.2-14.6 75.9-23.3 115.8-26.1zm0-370a389.1 389.1 0 01-115.7-26.2c8.3-24.6 17.9-47.3 29-67.8 17.4-32.4 37.8-58.4 59.1-75.1 9.2-7.2 18.4-12.7 27.7-16.4V327zM365.7 165.5c3.7-1.5 7.3-3 11-4.4-23.4 31.3-43.5 70.4-59.2 115.4-21-12-40.9-26-59.4-41.8 31.8-29.2 67.9-52.4 107.6-69.2zM165.5 365.7c13.8-32.6 32-62.8 54.2-90.2 24.9 21.5 52.2 40.3 81.5 55.9-11.6 46.9-18.8 98.4-20.7 152.6H137c3-40.9 12.6-80.6 28.5-118.3zM137 540h143.5c1.9 54.2 9.1 105.7 20.7 152.6a444.07 444.07 0 00-81.5 55.9A373.86 373.86 0 01137 540zm228.7 318.5c-39.7-16.8-75.8-40-107.6-69.2 18.5-15.8 38.4-29.7 59.4-41.8 15.7 45 35.8 84.1 59.2 115.4-3.7-1.4-7.4-2.9-11-4.4zm292.6 0c-3.7 1.5-7.3 3-11 4.4 23.4-31.3 43.5-70.4 59.2-115.4 21 12 40.9 26 59.4 41.8a373.81 373.81 0 01-107.6 69.2z"></path></svg></span></span><span>简体中文</span></button><div class="navbar__search searchBarContainer_NW3z" dir="ltr"><input placeholder="搜索" aria-label="Search" class="navbar__search-input searchInput_YFbd" value=""><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div><button type="button" class="ant-btn css-plsjn ant-btn-text ant-btn-color-default ant-btn-variant-text ant-btn-icon-only" style="margin-left:6px"><span class="ant-btn-icon"><span role="img" aria-label="sun" style="font-size:20px" class="anticon anticon-sun"><svg fill-rule="evenodd" viewBox="64 64 896 896" focusable="false" data-icon="sun" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M548 818v126a16 16 0 01-16 16h-40a16 16 0 01-16-16V818c15.85 1.64 27.84 2.46 36 2.46 8.15 0 20.16-.82 36-2.46m205.25-115.66l89.1 89.1a16 16 0 010 22.62l-28.29 28.29a16 16 0 01-22.62 0l-89.1-89.1c12.37-10.04 21.43-17.95 27.2-23.71 5.76-5.77 13.67-14.84 23.71-27.2m-482.5 0c10.04 12.36 17.95 21.43 23.71 27.2 5.77 5.76 14.84 13.67 27.2 23.71l-89.1 89.1a16 16 0 01-22.62 0l-28.29-28.29a16 16 0 010-22.63zM512 278c129.24 0 234 104.77 234 234S641.24 746 512 746 278 641.24 278 512s104.77-234 234-234m0 72c-89.47 0-162 72.53-162 162s72.53 162 162 162 162-72.53 162-162-72.53-162-162-162M206 476c-1.64 15.85-2.46 27.84-2.46 36 0 8.15.82 20.16 2.46 36H80a16 16 0 01-16-16v-40a16 16 0 0116-16zm738 0a16 16 0 0116 16v40a16 16 0 01-16 16H818c1.64-15.85 2.46-27.84 2.46-36 0-8.15-.82-20.16-2.46-36zM814.06 180.65l28.29 28.29a16 16 0 010 22.63l-89.1 89.09c-10.04-12.37-17.95-21.43-23.71-27.2-5.77-5.76-14.84-13.67-27.2-23.71l89.1-89.1a16 16 0 0122.62 0m-581.5 0l89.1 89.1c-12.37 10.04-21.43 17.95-27.2 23.71-5.76 5.77-13.67 14.84-23.71 27.2l-89.1-89.1a16 16 0 010-22.62l28.29-28.29a16 16 0 0122.62 0M532 64a16 16 0 0116 16v126c-15.85-1.64-27.84-2.46-36-2.46-8.15 0-20.16.82-36 2.46V80a16 16 0 0116-16z"></path></svg></span></span></button></div></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="回到顶部" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="文档侧边栏" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ROLL/zh-Hans/docs/Overview"><span title="概览" class="linkLabel_WmDU">概览</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="快速入门" class="categoryLinkLabel_W154">快速入门</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Installation/image_address"><span title="安装指南" class="categoryLinkLabel_W154">安装指南</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/aliyun_serverless_devpod_quick_start"><span title="快速开始" class="categoryLinkLabel_W154">快速开始</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/Debugging Guide/debug_guide"><span title="调试" class="categoryLinkLabel_W154">调试</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Getting Started/FAQ/qa_issues"><span title="答疑" class="categoryLinkLabel_W154">答疑</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="使用指南" class="categoryLinkLabel_W154">使用指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide"><span title="配置" class="categoryLinkLabel_W154">配置</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Pipeline/agent_pipeline_start"><span title="流水线" class="categoryLinkLabel_W154">流水线</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Algorithms/GRPO"><span title="算法" class="categoryLinkLabel_W154">算法</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Agentic/Tool_Use"><span title="Agentic" class="categoryLinkLabel_W154">Agentic</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Advanced Features/async_parallel_rollout"><span title="高级特性" class="categoryLinkLabel_W154">高级特性</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Tracker &amp; Metrics/trackers_and_metrics"><span title="Tracker 和 Metrics" class="categoryLinkLabel_W154">Tracker 和 Metrics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/User Guides/Hardware Support/ascend_usage"><span title="硬件支持" class="categoryLinkLabel_W154">硬件支持</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="开发" class="categoryLinkLabel_W154">开发</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Architecture/AgenticPipeline"><span title="架构" class="categoryLinkLabel_W154">架构</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/support_new_models"><span title="开发者指南" class="categoryLinkLabel_W154">开发者指南</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/support_new_models"><span title="如何支持新模型" class="linkLabel_WmDU">如何支持新模型</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/rollout_mock_usage"><span title="Rollout Dump Mock 使用指南" class="linkLabel_WmDU">Rollout Dump Mock 使用指南</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/custom_loss_func"><span title="Guide to Implementing Custom loss_func" class="linkLabel_WmDU">Guide to Implementing Custom loss_func</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/customer_env"><span title="自定义Env" class="linkLabel_WmDU">自定义Env</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/llm_as_judge_optimization"><span title="LLM as Judge 在 Agentic 环境中的优化实现" class="linkLabel_WmDU">LLM as Judge 在 Agentic 环境中的优化实现</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ROLL/zh-Hans/docs/Development/Developer Guide/prompt_intro"><span title="Prompt生成指南" class="linkLabel_WmDU">Prompt生成指南</span></a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="页面路径"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="主页面" class="breadcrumbs__link" href="/ROLL/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">开发</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">开发者指南</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">LLM as Judge 在 Agentic 环境中的优化实现</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">本页总览</button></div><div class="theme-doc-markdown markdown"><header><h1>LLM as Judge 在 Agentic 环境中的优化实现</h1></header>
<p>本文档介绍 ROLL 框架中 LLM as Judge 在 Agentic 环境中的优化实现方案，包括系统架构、调用链路、配置方法和最佳实践。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="概览">概览<a href="#概览" class="hash-link" aria-label="概览的直接链接" title="概览的直接链接" translate="no">​</a></h2>
<p>LLM as Judge 是一种使用大语言模型作为评判器来评估智能体响应质量的方法。在 Agentic 训练场景中，大规模环境实例并发执行 rollout 时，使用 LLM as Judge 计算 reward 会产生大量并发 LLM 请求，这对外部 LLM 服务的稳定性和吞吐量提出了巨大挑战。</p>
<p>为解决这一问题，ROLL 框架通过<strong>独立的 Reward Cluster</strong> 和<strong>高效的调度机制</strong>，实现了可扩展的本地化并行评估系统，避免了对外部服务的依赖，确保了训练过程的稳定性和可控性。</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>文档说明</div><div class="admonitionContent_BuS1"><p>本文档以 <strong>DeepEyes 环境</strong>的 LLM as Judge 实现为例进行说明。对于其他需要使用 LLM as Judge 的环境，可以参考 <code>env_manager</code> 和 <code>env</code> 内的调用方式自定义实现。</p></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="核心优势">核心优势<a href="#核心优势" class="hash-link" aria-label="核心优势的直接链接" title="核心优势的直接链接" translate="no">​</a></h3>
<ul>
<li class=""><strong>独立资源管理</strong>：Reward 模型与 Policy 模型分离，可独立分配 GPU 资源，避免资源竞争</li>
<li class=""><strong>本地化部署</strong>：通过本地 Reward Cluster 避免外部 API 依赖，保证服务稳定性和数据安全</li>
<li class=""><strong>高并发支持</strong>：通过 RequestScheduler 实现多环境并行的高效 reward 评估，支持环境并发扩展</li>
<li class=""><strong>统一接口设计</strong>：提供 <code>generate_by_proxy</code> 统一工具函数，简化 LLM 调用逻辑，支持文本和多模态</li>
<li class=""><strong>灵活配置</strong>：支持多种推理后端（vLLM、SGLang）和自定义生成参数</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="应用场景">应用场景<a href="#应用场景" class="hash-link" aria-label="应用场景的直接链接" title="应用场景的直接链接" translate="no">​</a></h3>
<p>典型的 Agentic 训练场景：</p>
<ul>
<li class=""><strong>环境规模</strong>：256个环境组，每组 4 个环境，共 1024个并发环境实例</li>
<li class=""><strong>Rollout 频率</strong>：每个环境完成 episode 后调用 LLM Judge</li>
<li class=""><strong>并发压力</strong>：在 rollout 高峰期可能有 500+ 个环境同时请求 reward 评估</li>
<li class=""><strong>稳定性要求</strong>：训练过程不能因为外部 API 限流或超时而中断</li>
</ul>
<p>通过本文档介绍的优化实现，可以有效应对上述挑战。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="系统架构">系统架构<a href="#系统架构" class="hash-link" aria-label="系统架构的直接链接" title="系统架构的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="整体架构">整体架构<a href="#整体架构" class="hash-link" aria-label="整体架构的直接链接" title="整体架构的直接链接" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">AgenticPipeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ├── Reward Cluster (可选，独立GPU资源)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │   ├── InferWorker (默认)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │   └── 支持 vLLM/SGLang 后端</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ├── Reward Scheduler (Ray Named Actor)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │   ├── 请求路由与负载均衡</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │   ├── 并发控制</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │   └── 请求追踪与清理</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    │</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    └── Environment Manager</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ├── llm_proxy: 用于 policy 推理</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ├── reward_proxy: 用于 LLM as Judge</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        └── env实例</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            └── 在 obtain_outcome_reward 中调用 reward_proxy</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="关键组件">关键组件<a href="#关键组件" class="hash-link" aria-label="关键组件的直接链接" title="关键组件的直接链接" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-reward-cluster">1. Reward Cluster<a href="#1-reward-cluster" class="hash-link" aria-label="1. Reward Cluster的直接链接" title="1. Reward Cluster的直接链接" translate="no">​</a></h4>
<p><strong>位置</strong>: <code>roll/pipeline/agentic/agentic_pipeline.py:88-98</code></p>
<p>Reward Cluster 是可选组件，仅在配置了 <code>device_mapping</code> 时创建：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">is</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">not</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">and</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">&gt;</span><span class="token plain"> </span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward </span><span class="token operator">=</span><span class="token plain"> Cluster</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        name</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        worker_cls</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">worker_cls</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 默认 InferWorker</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        resource_manager</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">resource_manager</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        worker_config</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p><strong>Worker Class 默认配置</strong>: <code>roll/pipeline/agentic/agentic_config.py:287</code></p>
<ul>
<li class="">默认使用 <code>InferWorker</code> 作为推理引擎，复用ActorInfer Worker实现</li>
<li class="">支持 vLLM、SGLang等多种后端</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-reward-scheduler-ray-named-actor">2. Reward Scheduler (Ray Named Actor)<a href="#2-reward-scheduler-ray-named-actor" class="hash-link" aria-label="2. Reward Scheduler (Ray Named Actor)的直接链接" title="2. Reward Scheduler (Ray Named Actor)的直接链接" translate="no">​</a></h4>
<p><strong>位置</strong>: <code>roll/pipeline/agentic/agentic_pipeline.py:112-125</code></p>
<p>Reward Scheduler 作为 Ray Named Actor 创建，供所有环境管理器共享访问：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward_scheduler </span><span class="token operator">=</span><span class="token plain"> RequestScheduler</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">options</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name</span><span class="token operator">=</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;RewardScheduler-</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">self</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">pipeline_config</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">reward</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">name</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    get_if_exists</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    namespace</span><span class="token operator">=</span><span class="token plain">RAY_NAMESPACE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    scheduling_strategy</span><span class="token operator">=</span><span class="token plain">NodeAffinitySchedulingStrategy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">remote</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    infer_cluster</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    pipeline_config</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    resource_manager</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">resource_manager</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p><strong>核心功能</strong>:</p>
<ul>
<li class=""><strong>智能路由</strong>: 使用最少负载路由算法分配请求到不同的 DP rank</li>
<li class=""><strong>粘性路由</strong>: 同一环境的请求固定路由到同一 worker（利于 KV cache）</li>
<li class=""><strong>请求追踪</strong>: 维护 <code>request_id</code> 到 worker 的映射关系</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-reward-proxy">3. Reward Proxy<a href="#3-reward-proxy" class="hash-link" aria-label="3. Reward Proxy的直接链接" title="3. Reward Proxy的直接链接" translate="no">​</a></h4>
<p><strong>位置</strong>: <code>roll/pipeline/agentic/env_manager/vl_traj_env_manager.py:85-109</code></p>
<p>环境管理器通过 Ray 获取 Reward Scheduler 并创建 Reward Proxy：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># 从 Ray 获取 reward scheduler (Named Actor)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward_scheduler </span><span class="token operator">=</span><span class="token plain"> ray</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_actor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        name</span><span class="token operator">=</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;RewardScheduler-</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">pipeline_config</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">reward</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">name</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        namespace</span><span class="token operator">=</span><span class="token plain">RAY_NAMESPACE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 创建 reward proxy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward_proxy </span><span class="token operator">=</span><span class="token plain"> create_llm_proxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        generate_scheduler</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward_scheduler</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        llm_proxy_config</span><span class="token operator">=</span><span class="token plain">pipeline_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">llm_proxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        tokenizer</span><span class="token operator">=</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reward_tokenizer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        env</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p><strong>Proxy 工厂函数</strong>: <code>roll/pipeline/agentic/llm_proxy/__init__.py:11</code></p>
<ul>
<li class="">支持多种 proxy 类型：<code>policy</code>、<code>openai</code>、<code>random</code></li>
<li class="">通过注册机制实现可扩展性</li>
<li class="">训练验证过policy设置功能正常，基于外部部署的大模型服务可使用openai proxy，注意对并发的挑战</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="4-统一工具函数-generate_by_proxy">4. 统一工具函数 <code>generate_by_proxy</code><a href="#4-统一工具函数-generate_by_proxy" class="hash-link" aria-label="4-统一工具函数-generate_by_proxy的直接链接" title="4-统一工具函数-generate_by_proxy的直接链接" translate="no">​</a></h4>
<p><strong>位置</strong>: <code>roll/pipeline/agentic/llm_proxy/proxy_utils.py:18-170</code></p>
<p>这是env调用的核心组件，提供统一的 LLM 调用接口：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">generate_by_proxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> List</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">Dict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token builtin" style="color:rgb(189, 147, 249)">str</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Any</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tokenizer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> PreTrainedTokenizer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    proxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> BaseLLMProxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    enable_thinking</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">bool</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    generation_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">Dict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token builtin" style="color:rgb(189, 147, 249)">str</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Any</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    collator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">Any</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    mm_data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">Dict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token builtin" style="color:rgb(189, 147, 249)">str</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Any</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    src_rank</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token builtin" style="color:rgb(189, 147, 249)">int</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">-</span><span class="token operator">&gt;</span><span class="token plain"> Optional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token builtin" style="color:rgb(189, 147, 249)">str</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><br></span></code></pre></div></div>
<p><strong>核心特性</strong>:</p>
<ul>
<li class=""><strong>统一接口</strong>: 无论文本还是多模态，都使用相同的调用方式</li>
<li class=""><strong>自动格式化</strong>: 使用 <code>tokenizer.apply_chat_template</code> 格式化消息</li>
<li class=""><strong>多模态支持</strong>: 通过 <code>collator</code> 参数支持图像/视频输入</li>
<li class=""><strong>thinking 机制</strong>: 支持 DeepSeek、Qwen 等模型的思考链</li>
<li class=""><strong>路由控制</strong>: 通过 <code>src_rank</code> 参数实现粘性路由</li>
<li class=""><strong>错误处理</strong>: 返回 <code>None</code> 表示推理失败，由调用方处理</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="调用链路">调用链路<a href="#调用链路" class="hash-link" aria-label="调用链路的直接链接" title="调用链路的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="完整调用流程">完整调用流程<a href="#完整调用流程" class="hash-link" aria-label="完整调用流程的直接链接" title="完整调用流程的直接链接" translate="no"> ​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">1. DeepEyesEnv.step() (env/deepeyes/env.py:182-197)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   当 done=True 时触发 obtain_outcome_reward</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2. DeepEyesEnv.obtain_outcome_reward() (env/deepeyes/env.py:199-254)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   构建 judge prompt，调用 reward model</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">3. generate_by_proxy() (llm_proxy/proxy_utils.py:18)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   统一的 LLM 调用工具函数</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">4. reward_proxy.generate() (llm_proxy/policy_proxy.py:15)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   通过 Ray 调用 scheduler</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5. reward_scheduler.generate_one_request() (scheduler/generate_scheduler.py:1296)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   请求路由与负载均衡</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">6. infer_cluster.workers[dp_rank].generate_request()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   实际的模型推理</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   ↓</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">7. 返回 LLM 判断结果</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="配置说明">配置说明<a href="#配置说明" class="hash-link" aria-label="配置说明的直接链接" title="配置说明的直接链接" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="完整配置示例">完整配置示例<a href="#完整配置示例" class="hash-link" aria-label="完整配置示例的直接链接" title="完整配置示例的直接链接" translate="no">​</a></h3>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Reward 配置 (LLM as Judge for AgenticPipeline)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;reward&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">worker_cls</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;roll.pipeline.base_worker.InferWorker&quot;</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 默认值，可省略</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">model_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">model_name_or_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Qwen/Qwen2.5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">72B</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">Instruct</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">dtype</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> bf16</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">generating_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">max_new_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2048</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.2</span><span class="token plain">      </span><span class="token comment" style="color:rgb(98, 114, 164)"># 较低温度提高判断稳定性</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">top_p</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.95</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">top_k</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">20</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm   </span><span class="token comment" style="color:rgb(98, 114, 164)"># 或 sglang</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">tensor_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">load_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> auto</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 关键：必须非空才会创建 reward cluster</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> 16))  </span><span class="token comment" style="color:rgb(98, 114, 164)"># GPUs 8-15</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">llm_proxy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">proxy_type</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> policy  </span><span class="token comment" style="color:rgb(98, 114, 164)"># 使用 policy proxy</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="配置关键点">配置关键点<a href="#配置关键点" class="hash-link" aria-label="配置关键点的直接链接" title="配置关键点的直接链接" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-device_mapping必须配置">1. device_mapping（必须配置）<a href="#1-device_mapping必须配置" class="hash-link" aria-label="1. device_mapping（必须配置）的直接链接" title="1. device_mapping（必须配置）的直接链接" translate="no">​</a></h4>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># 推荐配置：Policy 和 Reward 使用独立 GPU</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">actor_infer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> 8))   </span><span class="token comment" style="color:rgb(98, 114, 164)"># GPUs 0-7</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">reward</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">device_mapping</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> list(range(8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> 16))  </span><span class="token comment" style="color:rgb(98, 114, 164)"># GPUs 8-15，独立资源</span><br></span></code></pre></div></div>
<ul>
<li class=""><strong>空或 None</strong>: 不创建 reward cluster，环境无法使用 LLM as Judge</li>
<li class=""><strong>非空</strong>: 创建独立的 reward cluster，支持 LLM as Judge</li>
<li class=""><strong>独立部署</strong>: 与 actor_infer 使用不同的 GPU 资源，Policy 推理和 Reward 评估并行执行，actor_infer与reward必须得独立部署</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-strategy_name推理后端选择">2. strategy_name（推理后端选择）<a href="#2-strategy_name推理后端选择" class="hash-link" aria-label="2. strategy_name（推理后端选择）的直接链接" title="2. strategy_name（推理后端选择）的直接链接" translate="no">​</a></h4>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">strategy_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> vllm   </span><span class="token comment" style="color:rgb(98, 114, 164)"># 或 sglang</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">strategy_config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">gpu_memory_utilization</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">tensor_parallel_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">load_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> auto	</span><span class="token comment" style="color:rgb(98, 114, 164)"># 必须配置auto, vllm/sglang strategy里默认使用dummy load，会随机初始  化参数</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-generating_args生成参数">3. generating_args（生成参数）<a href="#3-generating_args生成参数" class="hash-link" aria-label="3. generating_args（生成参数）的直接链接" title="3. generating_args（生成参数）的直接链接" translate="no">​</a></h4>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">generating_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">max_new_tokens</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">2048</span><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># 根据 judge 输出长度调整</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.2</span><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># 较低温度提高稳定性</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">top_p</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.95</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">top_k</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">20</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="总结">总结<a href="#总结" class="hash-link" aria-label="总结的直接链接" title="总结的直接链接" translate="no">​</a></h2>
<p>LLM as Judge 在 Agentic 环境中的优化实现通过以下关键设计实现高效可扩展：</p>
<ol>
<li class=""><strong>独立 Reward Cluster</strong>: 资源隔离，避免与 Policy 推理竞争</li>
<li class=""><strong>Ray Named Actor</strong>: Reward Scheduler 作为共享服务，供所有环境访问</li>
<li class=""><strong>统一工具函数</strong>: <code>generate_by_proxy</code> 简化调用，支持文本和多模态</li>
<li class=""><strong>智能路由</strong>: 粘性路由和负载均衡，提高缓存利用率</li>
</ol>
<p>通过合理配置和使用这些组件，可以构建高效、可靠的 LLM as Judge 评估系统。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/Development/Developer Guide/llm_as_judge_optimization.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>编辑此页</a></div><div class="col lastUpdated_JAkA"><span class="theme-last-updated">最后<!-- -->于 <b><time datetime="2026-02-09T13:05:30.000Z" itemprop="dateModified">2026年2月9日</time></b> <!-- -->更新</span></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="文件选项卡"><a class="pagination-nav__link pagination-nav__link--prev" href="/ROLL/zh-Hans/docs/Development/Developer Guide/customer_env"><div class="pagination-nav__sublabel">上一页</div><div class="pagination-nav__label">自定义Env</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ROLL/zh-Hans/docs/Development/Developer Guide/prompt_intro"><div class="pagination-nav__sublabel">下一页</div><div class="pagination-nav__label">Prompt生成指南</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#概览" class="table-of-contents__link toc-highlight">概览</a><ul><li><a href="#核心优势" class="table-of-contents__link toc-highlight">核心优势</a></li><li><a href="#应用场景" class="table-of-contents__link toc-highlight">应用场景</a></li></ul></li><li><a href="#系统架构" class="table-of-contents__link toc-highlight">系统架构</a><ul><li><a href="#整体架构" class="table-of-contents__link toc-highlight">整体架构</a></li><li><a href="#关键组件" class="table-of-contents__link toc-highlight">关键组件</a></li></ul></li><li><a href="#调用链路" class="table-of-contents__link toc-highlight">调用链路</a><ul><li><a href="#完整调用流程" class="table-of-contents__link toc-highlight">完整调用流程</a></li></ul></li><li><a href="#配置说明" class="table-of-contents__link toc-highlight">配置说明</a><ul><li><a href="#完整配置示例" class="table-of-contents__link toc-highlight">完整配置示例</a></li><li><a href="#配置关键点" class="table-of-contents__link toc-highlight">配置关键点</a></li></ul></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Examples</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/Getting Started/Quick Start/single_node_quick_start">ROLL单机实践手册</a></li><li class="footer__item"><a class="footer__link-item" href="/ROLL/zh-Hans/docs/User Guides/Configuration/config_guide">配置指南</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/alibaba/ROLL" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Alibaba.</div></div></div></footer></div>
</body>
</html>