"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[6275],{5419:(e,i,r)=>{r.r(i),r.d(i,{assets:()=>d,contentTitle:()=>h,default:()=>b,frontMatter:()=>o,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"UserGuide/start","title":"start","description":"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80","source":"@site/i18n/zh-Hans/docusaurus-plugin-content-docs/current/UserGuide/start.mdx","sourceDirName":"UserGuide","slug":"/UserGuide/start","permalink":"/ROLL/zh-Hans/docs/UserGuide/start","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/UserGuide/start.mdx","tags":[],"version":"current","lastUpdatedAt":1763115283000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"VLM RLVR \u6d41\u6c34\u7ebf","permalink":"/ROLL/zh-Hans/docs/UserGuide/pipeline/vl_rlvr_pipeline_start"},"next":{"title":"tracker\u548cmetrics","permalink":"/ROLL/zh-Hans/docs/UserGuide/trackers_and_metrics"}}');var t=r(4848),a=r(8453),n=(r(6540),r(5068));function l({item:e,subLabel:i}){return"link"===e.type?(0,t.jsx)("div",{children:(0,t.jsx)("a",{href:e.href,children:e.label})}):"category"===e.type?(0,t.jsxs)("div",{children:[e.label!==i&&(0,t.jsx)("h4",{style:{marginTop:8},children:e.label}),(0,t.jsx)("div",{children:e.items.sort(e=>"link"===e.type?-1:1).map(e=>(0,t.jsx)(l,{item:e,subLabel:i}))})]}):(0,t.jsx)("div",{})}const c=function({folder_label:e}){const i=(0,n.$S)();return i?.label!==e?null:(0,t.jsx)("div",{children:i.items.sort(e=>"link"===e.type?-1:1).filter(e=>"link"!==e.type||"start"!==e.label).map(i=>(0,t.jsx)(l,{item:i,subLabel:e}))})},o={},h="ROLL: Reinforcement Learning Optimization for Large-Scale Learning",d={},u=[{value:"\ud83d\ude80 \u5feb\u901f\u5165\u95e8",id:"-\u5feb\u901f\u5165\u95e8",level:2},{value:"\u5feb\u901f\u5f00\u59cb",id:"\u5feb\u901f\u5f00\u59cb",level:3},{value:"\u4f7f\u7528\u6307\u5357",id:"\u4f7f\u7528\u6307\u5357",level:3}];function g(e){const i={a:"a",br:"br",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)("div",{align:"center",children:[(0,t.jsx)("img",{src:"https://img.alicdn.com/imgextra/i2/O1CN01R6uYoU1VrrET7d1G6_!!6000000002707-0-tps-1292-407.jpg",width:"40%",alt:"ROLL Logo"}),(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"roll-reinforcement-learning-optimization-for-large-scale-learning",children:"ROLL: Reinforcement Learning Optimization for Large-Scale Learning"})}),(0,t.jsx)("h4",{children:"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80"}),(0,t.jsxs)("p",{children:[(0,t.jsx)("a",{href:"https://github.com/alibaba/ROLL/blob/main/LICENSE",children:(0,t.jsx)("img",{src:"https://img.shields.io/badge/license-Apache%202.0-blue.svg",alt:"License"})}),(0,t.jsx)("a",{href:"https://github.com/alibaba/ROLL/issues",children:(0,t.jsx)("img",{src:"https://img.shields.io/github/issues/alibaba/ROLL",alt:"GitHub issues"})}),(0,t.jsx)("a",{href:"https://github.com/alibaba/ROLL/stargazers",children:(0,t.jsx)("img",{src:"https://img.shields.io/github/stars/alibaba/ROLL?style=social",alt:"Repo stars"})}),(0,t.jsx)("a",{href:"https://arxiv.org/abs/2506.06122",children:(0,t.jsx)("img",{src:"https://img.shields.io/static/v1?label=arXiv&message=Paper&color=red"})}),(0,t.jsx)("a",{href:"https://img.alicdn.com/imgextra/i4/O1CN01MICK0T28fHMzy5P84_!!6000000007959-2-tps-756-850.png",target:"_blank",children:(0,t.jsx)("img",{src:"https://img.shields.io/badge/WeChat-green?logo=wechat",alt:"WeChat QR"})})]})]}),"\n",(0,t.jsx)(i.p,{children:"ROLL is an efficient and user-friendly RL library designed for Large Language Models (LLMs) utilizing Large Scale GPU resources. It significantly enhances LLM performance in key areas such as human preference alignment, complex reasoning, and multi-turn agentic interaction scenarios."}),"\n",(0,t.jsx)(i.p,{children:"Leveraging a multi-role distributed architecture with Ray for flexible resource allocation and heterogeneous task scheduling, ROLL integrates cutting-edge technologies like Megatron-Core, SGLang and vLLM to accelerate model training and inference."}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"[08/11/2025]"})," \ud83c\udf89 Our Paper released, see ",(0,t.jsx)(i.a,{href:"https://arxiv.org/abs/2508.08221",children:"Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}),".\n",(0,t.jsx)(i.strong,{children:"[06/09/2025]"})," \ud83c\udf89 ROLL tech report is now available! Access the report ",(0,t.jsx)(i.a,{href:"https://arxiv.org/abs/2506.06122",children:"here"}),"."]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"-\u5feb\u901f\u5165\u95e8",children:"\ud83d\ude80 \u5feb\u901f\u5165\u95e8"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/",children:"\u6587\u6863"})}),"\n",(0,t.jsx)(i.h3,{id:"\u5feb\u901f\u5f00\u59cb",children:"\u5feb\u901f\u5f00\u59cb"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/QuickStart/installation",children:"\u5b89\u88c5\u6307\u5357"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/QuickStart/config_system",children:"\u914d\u7f6e\u7cfb\u7edf\u8be6\u89e3"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/QuickStart/debug_guide",children:"\u8c03\u8bd5\u6307\u5357"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/UserGuide/trackers_and_metrics",children:"Trackers\u548cMetrics"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/UserGuide/checkpoint_and_resume",children:"\u68c0\u67e5\u70b9\u4fdd\u5b58\u4e0e\u6062\u590d\u6307\u5357"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/UserGuide/megatron_convert_2_hf",children:"\u6a21\u578b\u8f6c\u6362\u4e3a Hugging Face \u683c\u5f0f"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/QuickStart/single_node_quick_start",children:"\u5feb\u901f\u4e0a\u624b\uff1a\u5355\u673a\u7248\u90e8\u7f72\u6307\u5357"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/zh-Hans/QuickStart/multi_node_quick_start",children:"\u5feb\u901f\u4e0a\u624b\uff1a\u591a\u8282\u70b9\u90e8\u7f72\u6307\u5357"}),(0,t.jsx)(i.br,{}),"\n",(0,t.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/zh-Hans/docs/QuickStart/qa_issues",children:"\u5e38\u89c1\u95ee\u9898\u89e3\u7b54 (Q&A)"})]}),"\n",(0,t.jsx)(i.h3,{id:"\u4f7f\u7528\u6307\u5357",children:"\u4f7f\u7528\u6307\u5357"}),"\n",(0,t.jsx)(c,{folder_label:"\u4f7f\u7528\u6307\u5357"}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)("div",{align:"center",children:(0,t.jsx)(i.p,{children:"We welcome contributions from the community! \ud83e\udd1d"})})]})}function b(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(g,{...e})}):g(e)}},8453:(e,i,r)=>{r.d(i,{R:()=>n,x:()=>l});var s=r(6540);const t={},a=s.createContext(t);function n(e){const i=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:n(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);