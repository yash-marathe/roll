"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[2436],{6629:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"Getting Started/Quick Start/single_node_quick_start","title":"Quick Start: Single-Node Deployment Guide","description":"Environment Preparation","source":"@site/docs/Getting Started/Quick Start/single_node_quick_start.md","sourceDirName":"Getting Started/Quick Start","slug":"/Getting Started/Quick Start/single_node_quick_start","permalink":"/ROLL/docs/Getting Started/Quick Start/single_node_quick_start","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/Getting Started/Quick Start/single_node_quick_start.md","tags":[],"version":"current","lastUpdatedAt":1764225914000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Quick Start: Multi-Node Deployment Guide","permalink":"/ROLL/docs/Getting Started/Quick Start/multi_nodes_quick_start"},"next":{"title":"ROLL Debugging Guide","permalink":"/ROLL/docs/Getting Started/Debugging Guide/debug_guide"}}');var r=t(74848),a=t(28453);const o={},s="Quick Start: Single-Node Deployment Guide",l={},c=[{value:"Environment Preparation",id:"environment-preparation",level:2},{value:"Environment Configuration",id:"environment-configuration",level:2},{value:"Pipeline Execution",id:"pipeline-execution",level:2},{value:"Reference: Single V100 GPU Memory Configuration Key Points",id:"reference-single-v100-gpu-memory-configuration-key-points",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"quick-start-single-node-deployment-guide",children:"Quick Start: Single-Node Deployment Guide"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-preparation",children:"Environment Preparation"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Purchase a machine equipped with GPU and install GPU drivers synchronously"}),"\n",(0,r.jsx)(n.li,{children:"Connect to the GPU instance remotely and enter the machine terminal"}),"\n",(0,r.jsx)(n.li,{children:"Run the following command to install the Docker environment and NVIDIA container toolkit"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"curl -fsSL https://github.com/alibaba/ROLL/blob/main/scripts/install_docker_nvidia_container_toolkit.sh | sudo bash\n"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Choose your desired Docker image from the ",(0,r.jsx)(n.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/image_address",children:"image addresses"}),". The following example uses ",(0,r.jsx)(n.em,{children:"torch2.6.0 + vLLM0.8.4"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# 1. Start a Docker container with GPU support, expose container ports, and keep the container running\nsudo docker run -dit \\\n  --gpus all \\\n  -p 9001:22 \\\n  --ipc=host \\\n  --shm-size=10gb \\\n  roll-registry.cn-hangzhou.cr.aliyuncs.com/roll/pytorch:nvcr-24.05-py3-torch260-vllm084 \\\n  /bin/bash\n\n# 2. Enter the Docker container\n#    You can use the `sudo docker ps` command to find the running container ID or name.\nsudo docker exec -it <container_id> /bin/bash\n\n# 3. Verify that GPUs are visible\nnvidia-smi\n\n# 4. Clone the project code\ngit clone https://github.com/alibaba/ROLL.git\n\n# 5. Install project dependencies (choose the requirements file corresponding to your image)\ncd ROLL\npip install -r requirements_torch260_vllm.txt -i https://mirrors.aliyun.com/pypi/simple/\n"})}),"\n",(0,r.jsx)(n.h2,{id:"pipeline-execution",children:"Pipeline Execution"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bash examples/agentic_demo/run_agentic_pipeline_frozen_lake_single_node_demo.sh\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Example log screenshots during pipeline execution:\n",(0,r.jsx)(n.img,{src:"https://img.alicdn.com/imgextra/i2/O1CN015wRcUb1EkfZQEjpEI_!!6000000000390-2-tps-2868-650.png",alt:"log_pipeline_start"})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://img.alicdn.com/imgextra/i2/O1CN01Iaiv7H1HYi4hu8Fat_!!6000000000770-2-tps-2876-904.png",alt:"log_pipeline_in_training"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:"https://img.alicdn.com/imgextra/i1/O1CN016YSeUs1F5jmtyFA5V_!!6000000000436-2-tps-1904-206.png",alt:"log_pipeline_complete"})}),"\n",(0,r.jsx)(n.h2,{id:"reference-single-v100-gpu-memory-configuration-key-points",children:"Reference: Single V100 GPU Memory Configuration Key Points"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Reduce the expected number of GPUs from 8 to the 1 V100 you actually have\nnum_gpus_per_node: 1 \n# Training processes now only map to GPU 0\nactor_train.device_mapping: list(range(0,1))\n# Inference processes now only map to GPU 0\nactor_infer.device_mapping: list(range(0,1))\n# Reference model processes now only map to GPU 0\nreference.device_mapping: list(range(0,1))\n\n# Significantly reduce the batch size during Rollout/Validation stages to prevent out-of-memory errors when a single GPU processes large batches\nrollout_batch_size: 16\nval_batch_size: 16\n\n# V100 has better native support for FP16 than BF16 (unlike A100/H100). Switching to FP16 can improve compatibility and stability while saving GPU memory.\nactor_train.model_args.dtype: fp16\nactor_infer.model_args.dtype: fp16\nreference.model_args.dtype: fp16\n\n# Switch the large model training framework from DeepSpeed to Megatron-LM, where parameters can be sent in batches for faster execution\nstrategy_name: megatron_train\nstrategy_config:\n  tensor_model_parallel_size: 1\n  pipeline_model_parallel_size: 1\n  expert_model_parallel_size: 1\n  use_distributed_optimizer: true\n  recompute_granularity: full\n\n# In Megatron training, the global training batch size is per_device_train_batch_size * gradient_accumulation_steps * world_size\nactor_train.training_args.per_device_train_batch_size: 1\nactor_train.training_args.gradient_accumulation_steps: 16  \n\n# Reduce the maximum number of actions per trajectory to make each Rollout trajectory shorter, reducing the length of LLM-generated content\nmax_actions_per_traj: 10    \n\n# Reduce the number of parallel training environment groups and validation environment groups to accommodate single GPU resources\ntrain_env_manager.env_groups: 1\ntrain_env_manager.n_groups: 1\nval_env_manager.env_groups: 2\nval_env_manager.n_groups: [1, 1]\nval_env_manager.tags: [SimpleSokoban, FrozenLake]\n\n# Reduce the total number of training steps to run a complete training process faster for quick debugging\nmax_steps: 100\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(96540);const r={},a=i.createContext(r);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);