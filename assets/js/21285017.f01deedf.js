"use strict";(self.webpackChunkdocs_roll=self.webpackChunkdocs_roll||[]).push([[4961],{2373:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>p,toc:()=>d});var t=i(8168),r=(i(6540),i(5680));const a={},o="DeepSpeed Training Backend Configuration Guide",p={unversionedId:"English/UserGuide/backend/deepspeed",id:"English/UserGuide/backend/deepspeed",title:"DeepSpeed Training Backend Configuration Guide",description:"DeepSpeed is Microsoft's efficient deep learning optimization library that provides memory optimization, distributed training, and performance optimization features. This document will provide detailed instructions on how to configure and use the DeepSpeed training backend in the ROLL framework.",source:"@site/docs/English/UserGuide/backend/deepspeed.md",sourceDirName:"English/UserGuide/backend",slug:"/English/UserGuide/backend/deepspeed",permalink:"/ROLL/docs/English/UserGuide/backend/deepspeed",draft:!1,editUrl:"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/English/UserGuide/backend/deepspeed.md",tags:[],version:"current",lastUpdatedAt:1756200599,formattedLastUpdatedAt:"Aug 26, 2025",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Agentic Asynchronous Training Feature Usage Guide",permalink:"/ROLL/docs/English/UserGuide/async_training_agentic"},next:{title:"LoRA Fine-tuning Configuration Guide",permalink:"/ROLL/docs/English/UserGuide/backend/lora"}},l={},d=[{value:"DeepSpeed Introduction",id:"deepspeed-introduction",level:2},{value:"Configuring DeepSpeed Strategy",id:"configuring-deepspeed-strategy",level:2},{value:"Configuration Example",id:"configuration-example",level:3},{value:"Configuration Parameter Details",id:"configuration-parameter-details",level:3},{value:"DeepSpeed Configuration Files",id:"deepspeed-configuration-files",level:2},{value:"Using Predefined Configurations",id:"using-predefined-configurations",level:3},{value:"Integration with Other Components",id:"integration-with-other-components",level:2},{value:"Notes",id:"notes",level:2}],s={toc:d},g="wrapper";function c({components:e,...n}){return(0,r.yg)(g,(0,t.A)({},s,n,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"deepspeed-training-backend-configuration-guide"},"DeepSpeed Training Backend Configuration Guide"),(0,r.yg)("p",null,"DeepSpeed is Microsoft's efficient deep learning optimization library that provides memory optimization, distributed training, and performance optimization features. This document will provide detailed instructions on how to configure and use the DeepSpeed training backend in the ROLL framework."),(0,r.yg)("h2",{id:"deepspeed-introduction"},"DeepSpeed Introduction"),(0,r.yg)("p",null,"DeepSpeed provides multiple optimization techniques, including:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"ZeRO Optimization"),": Reduces memory usage by partitioning optimizer states, gradients, and parameters"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Memory-Efficient Training"),": Supports training of large-scale models"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"High-Performance Communication"),": Optimizes communication efficiency in distributed training"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Flexible Configuration"),": Supports configuration of multiple optimization levels")),(0,r.yg)("h2",{id:"configuring-deepspeed-strategy"},"Configuring DeepSpeed Strategy"),(0,r.yg)("p",null,"In the ROLL framework, DeepSpeed training strategy can be configured by setting ",(0,r.yg)("inlineCode",{parentName:"p"},"strategy_args")," in the YAML configuration file."),(0,r.yg)("h3",{id:"configuration-example"},"Configuration Example"),(0,r.yg)("p",null,"The following is a typical DeepSpeed configuration example (from ",(0,r.yg)("inlineCode",{parentName:"p"},"examples/qwen2.5-7B-rlvr_megatron/rlvl_lora_zero3.yaml"),"):"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"defaults:\n  - ../config/deepspeed_zero@_here_\n  - ../config/deepspeed_zero2@_here_\n  - ../config/deepspeed_zero3@_here_\n  - ../config/deepspeed_zero3_cpuoffload@_here_\n\nactor_train:\n  model_args:\n    attn_implementation: fa2\n    disable_gradient_checkpointing: true\n    dtype: bf16\n    model_type: ~\n  training_args:\n    learning_rate: 1.0e-5\n    weight_decay: 0\n    per_device_train_batch_size: 1\n    gradient_accumulation_steps: 32\n    warmup_steps: 20\n    num_train_epochs: 50\n  strategy_args:\n    strategy_name: deepspeed_train\n    strategy_config: ${deepspeed_zero3}\n  device_mapping: list(range(0,16))\n  infer_batch_size: 4\n")),(0,r.yg)("h3",{id:"configuration-parameter-details"},"Configuration Parameter Details"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"strategy_name"),": Set to ",(0,r.yg)("inlineCode",{parentName:"p"},"deepspeed_train")," to use the DeepSpeed training backend")),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"strategy_config"),": DeepSpeed-specific configuration parameters"),(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},"Can reference predefined configuration files, such as ",(0,r.yg)("inlineCode",{parentName:"li"},"${deepspeed_zero3}")),(0,r.yg)("li",{parentName:"ul"},"Multiple DeepSpeed configuration files are available in the ",(0,r.yg)("inlineCode",{parentName:"li"},"./examples/config/")," directory:",(0,r.yg)("ul",{parentName:"li"},(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_zero.yaml"),": Basic ZeRO configuration"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_zero2.yaml"),": ZeRO-2 configuration"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_zero3.yaml"),": ZeRO-3 configuration"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_zero3_cpuoffload.yaml"),": ZeRO-3 configuration with CPU offloading"))))),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"defaults section"),": Import predefined DeepSpeed configurations"),(0,r.yg)("pre",{parentName:"li"},(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"defaults:\n  - ../config/deepspeed_zero@_here_\n  - ../config/deepspeed_zero2@_here_\n  - ../config/deepspeed_zero3@_here_\n  - ../config/deepspeed_zero3_cpuoffload@_here_\n"))),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("p",{parentName:"li"},(0,r.yg)("strong",{parentName:"p"},"device_mapping"),": Specify the list of GPU device IDs to use"))),(0,r.yg)("h2",{id:"deepspeed-configuration-files"},"DeepSpeed Configuration Files"),(0,r.yg)("p",null,"Multiple predefined DeepSpeed configuration files are provided in the ",(0,r.yg)("inlineCode",{parentName:"p"},"./examples/config/")," directory:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"deepspeed_zero.yaml"),": Basic ZeRO configuration"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"deepspeed_zero2.yaml"),": ZeRO-2 configuration with optimizer state partitioning"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"deepspeed_zero3.yaml"),": ZeRO-3 configuration with optimizer state, gradient, and parameter partitioning"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"deepspeed_zero3_cpuoffload.yaml"),": ZeRO-3 configuration with CPU offloading")),(0,r.yg)("h3",{id:"using-predefined-configurations"},"Using Predefined Configurations"),(0,r.yg)("p",null,"To use predefined DeepSpeed configurations, you can reference them in the YAML file like this:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"defaults:\n  - ../config/deepspeed_zero3@_here_\n\nactor_train:\n  strategy_args:\n    strategy_name: deepspeed_train\n    strategy_config: ${deepspeed_zero3}\n")),(0,r.yg)("h2",{id:"integration-with-other-components"},"Integration with Other Components"),(0,r.yg)("p",null,"In the configuration example, we can see:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("inlineCode",{parentName:"li"},"actor_train")," uses DeepSpeed for training"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("inlineCode",{parentName:"li"},"actor_infer")," may use other inference backends (such as vLLM)"),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("inlineCode",{parentName:"li"},"reference")," uses the Hugging Face inference backend"),(0,r.yg)("li",{parentName:"ol"},"Reward models use different inference backends")),(0,r.yg)("p",null,"This design allows different components to choose the most suitable backend according to their needs."),(0,r.yg)("h2",{id:"notes"},"Notes"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"DeepSpeed requires specific versions of dependency libraries, please ensure compatible versions are installed"),(0,r.yg)("li",{parentName:"ol"},"Different ZeRO levels have different memory and performance characteristics, choose according to specific needs"),(0,r.yg)("li",{parentName:"ol"},"When using LoRA fine-tuning, pay attention to compatibility with DeepSpeed")))}c.isMDXComponent=!0},5680:(e,n,i)=>{i.d(n,{xA:()=>s,yg:()=>m});var t=i(6540);function r(e,n,i){return n in e?Object.defineProperty(e,n,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[n]=i,e}function a(e,n){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),i.push.apply(i,t)}return i}function o(e){for(var n=1;n<arguments.length;n++){var i=null!=arguments[n]?arguments[n]:{};n%2?a(Object(i),!0).forEach(function(n){r(e,n,i[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):a(Object(i)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(i,n))})}return e}function p(e,n){if(null==e)return{};var i,t,r=function(e,n){if(null==e)return{};var i,t,r={},a=Object.keys(e);for(t=0;t<a.length;t++)i=a[t],n.indexOf(i)>=0||(r[i]=e[i]);return r}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(t=0;t<a.length;t++)i=a[t],n.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(r[i]=e[i])}return r}var l=t.createContext({}),d=function(e){var n=t.useContext(l),i=n;return e&&(i="function"==typeof e?e(n):o(o({},n),e)),i},s=function(e){var n=d(e.components);return t.createElement(l.Provider,{value:n},e.children)},g="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef(function(e,n){var i=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),g=d(i),u=r,m=g["".concat(l,".").concat(u)]||g[u]||c[u]||a;return i?t.createElement(m,o(o({ref:n},s),{},{components:i})):t.createElement(m,o({ref:n},s))});function m(e,n){var i=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var a=i.length,o=new Array(a);o[0]=u;var p={};for(var l in n)hasOwnProperty.call(n,l)&&(p[l]=n[l]);p.originalType=e,p[g]="string"==typeof e?e:r,o[1]=p;for(var d=2;d<a;d++)o[d]=i[d];return t.createElement.apply(null,o)}return t.createElement.apply(null,i)}u.displayName="MDXCreateElement"}}]);