"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[8582],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>s});var a=t(96540);const o={},i=a.createContext(o);function r(e){const n=a.useContext(i);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(i.Provider,{value:n},e.children)}},91552:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"User Guides/Agentic/agentic_engineer_practice","title":"Agentic Engineering Practice Documentation","description":"This document introduces the development practices of the Agentic component in the ROLL framework, including environment manager development protocols, GlobalDataset usage, validation mode configuration, and trajectory synthesis functionality.","source":"@site/docs/User Guides/Agentic/agentic_engineer_practice.md","sourceDirName":"User Guides/Agentic","slug":"/User Guides/Agentic/agentic_engineer_practice","permalink":"/ROLL/docs/User Guides/Agentic/agentic_engineer_practice","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/User Guides/Agentic/agentic_engineer_practice.md","tags":[],"version":"current","lastUpdatedAt":1764581625000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","permalink":"/ROLL/docs/User Guides/Agentic/agentic_StarPO"},"next":{"title":"Agentic Asynchronous Parallel Rollout","permalink":"/ROLL/docs/User Guides/Advanced Features/async_parallel_rollout"}}');var o=t(74848),i=t(28453);const r={},s="Agentic Engineering Practice Documentation",l={},d=[{value:"1. EnvManager Development Protocol",id:"1-envmanager-development-protocol",level:2},{value:"1.1 Core Loop Mechanism",id:"11-core-loop-mechanism",level:3},{value:"1.2 EnvManager Development Constraints",id:"12-envmanager-development-constraints",level:3},{value:"2. GlobalDataset Usage",id:"2-globaldataset-usage",level:2},{value:"2.1 Design Purpose",id:"21-design-purpose",level:3},{value:"2.2 Class Definition and Location",id:"22-class-definition-and-location",level:3},{value:"2.3 Two Working Modes",id:"23-two-working-modes",level:3},{value:"Sample Mode",id:"sample-mode",level:4},{value:"Traversal Mode",id:"traversal-mode",level:4},{value:"2.4 Core Features",id:"24-core-features",level:3},{value:"2.5 Usage Example",id:"25-usage-example",level:3},{value:"3. Validation Dataset Traversal Configuration During Training",id:"3-validation-dataset-traversal-configuration-during-training",level:2},{value:"3.1 Configuration Principles",id:"31-configuration-principles",level:3},{value:"3.2 MathEnv Implementation Reference",id:"32-mathenv-implementation-reference",level:3},{value:"3.3 YAML Configuration Example",id:"33-yaml-configuration-example",level:3},{value:"3.4 Random Sampling Evaluation Scenarios",id:"34-random-sampling-evaluation-scenarios",level:3},{value:"4. Trajectory Synthesis Dataset Traversal Configuration",id:"4-trajectory-synthesis-dataset-traversal-configuration",level:2},{value:"4.1 AgenticRolloutPipeline Implementation",id:"41-agenticrolloutpipeline-implementation",level:3},{value:"4.2 Startup Method",id:"42-startup-method",level:3},{value:"4.3 Core Configuration Reference",id:"43-core-configuration-reference",level:3},{value:"4.4 Trajectory Dump Configuration",id:"44-trajectory-dump-configuration",level:3},{value:"4.5 Important Notes",id:"45-important-notes",level:3},{value:"5. Trajectory Filtering",id:"5-trajectory-filtering",level:2},{value:"5.1 Usage Method",id:"51-usage-method",level:3},{value:"5.2 Custom Filtering Logic",id:"52-custom-filtering-logic",level:3},{value:"6. Frequently Asked Questions",id:"6-frequently-asked-questions",level:2},{value:"Q1: How to handle dataset traversal completion?",id:"q1-how-to-handle-dataset-traversal-completion",level:3},{value:"Q2: How to ensure experiment reproducibility?",id:"q2-how-to-ensure-experiment-reproducibility",level:3},{value:"Q3: How to handle large-scale trajectory data storage?",id:"q3-how-to-handle-large-scale-trajectory-data-storage",level:3},{value:"Q4: How to debug the trajectory generation process?",id:"q4-how-to-debug-the-trajectory-generation-process",level:3}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"agentic-engineering-practice-documentation",children:"Agentic Engineering Practice Documentation"})}),"\n",(0,o.jsx)(n.p,{children:"This document introduces the development practices of the Agentic component in the ROLL framework, including environment manager development protocols, GlobalDataset usage, validation mode configuration, and trajectory synthesis functionality."}),"\n",(0,o.jsx)(n.h2,{id:"1-envmanager-development-protocol",children:"1. EnvManager Development Protocol"}),"\n",(0,o.jsx)(n.p,{children:"EnvManager is the core component of the Agentic framework, responsible for environment management and trajectory generation. Developing new EnvManagers requires following the following protocol:"}),"\n",(0,o.jsx)(n.h3,{id:"11-core-loop-mechanism",children:"1.1 Core Loop Mechanism"}),"\n",(0,o.jsxs)(n.p,{children:["EnvManager must implement the ",(0,o.jsx)(n.code,{children:"run_rollout_loop"})," method, which follows the following protocol:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def run_rollout_loop(self, data: DataProto):\n    """\n    1. Each time run_rollout_loop is called, it continuously executes episodes \n       until receiving a command that data collection is complete\n    2. Need to reset seed to ensure consistency across all groups\n    3. episode_id is obtained from the scheduler\n\n    Seed update logic:\n       group_seed = base_seed + group_id\n       episode_seed = group_seed + episode_id\n\n    trajectory_id: f"{group_id}_{episode_id}_{episode_seed}"\n    """\n    \n    # Minimal call example\n    while self.running:\n        # Get episode_id from scheduler\n        self.episode_id = ray.get(self.output_queue.get_episode_id.remote(self.env_config["group_id"]))\n        if self.episode_id is None:\n            break\n        \n        # Reset environment\n        rollout_cache = self.reset()\n        \n        while rollout_cache is not None and not rollout_cache.terminated and not rollout_cache.truncated:\n            # Make decision\n            lm_output = self.make_decision(rollout_cache)\n            # Execute environment step\n            rollout_cache = self.step(lm_output)\n        \n        # Submit trajectory\n        rollout = self.formulate_rollouts(rollout_cache)\n        ray.get(self.output_queue.put.remote(self.env_config[\'group_id\'], self.episode_id, start_step, rollout))\n'})}),"\n",(0,o.jsx)(n.h3,{id:"12-envmanager-development-constraints",children:"1.2 EnvManager Development Constraints"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"While loop infinite loop"}),": EnvManager continuously executes episodes through a while loop"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Exit only when dataset traversal is complete"}),": When dataset traversal is complete, the ",(0,o.jsx)(n.code,{children:"reset()"})," method returns None, triggering loop exit"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Each episode must have corresponding trajectory put"}),": Each completed episode must submit trajectory data through ",(0,o.jsx)(n.code,{children:"output_queue.put"})]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"2-globaldataset-usage",children:"2. GlobalDataset Usage"}),"\n",(0,o.jsx)(n.h3,{id:"21-design-purpose",children:"2.1 Design Purpose"}),"\n",(0,o.jsx)(n.p,{children:"To avoid memory access/memory bottlenecks caused by each env reading data independently, the framework provides the GlobalDataset component at the framework level to implement unified management and distribution of datasets."}),"\n",(0,o.jsx)(n.h3,{id:"22-class-definition-and-location",children:"2.2 Class Definition and Location"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'# Location: roll.datasets.global_dataset.GlobalDataset\n@ray.remote\nclass GlobalDataset:\n    def __init__(self, dataset_name, split: str = "train", mode="sample", dataset_kwargs: Dict = None):\n        # mode: "sample" or "traversal"\n'})}),"\n",(0,o.jsx)(n.h3,{id:"23-two-working-modes",children:"2.3 Two Working Modes"}),"\n",(0,o.jsx)(n.h4,{id:"sample-mode",children:"Sample Mode"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose"}),": Random sampling of datasets in training mode"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Features"}),": Randomly select data items each time"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Configuration"}),": ",(0,o.jsx)(n.code,{children:'mode="sample"'})]}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"traversal-mode",children:"Traversal Mode"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Purpose"}),": Need to traverse the entire dataset in validation mode"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Features"}),": Traverse dataset sequentially, ensuring each data item is accessed"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Configuration"}),": ",(0,o.jsx)(n.code,{children:'mode="traversal"'})]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"24-core-features",children:"2.4 Core Features"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Deterministic sampling"}),": The ",(0,o.jsx)(n.code,{children:"get_data_item"})," method ensures the same seed returns the same data"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"State management"}),": Internally maintains index state, supporting dataset reset and traversal"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"25-usage-example",children:"2.5 Usage Example"}),"\n",(0,o.jsx)(n.p,{children:"Refer to the implementation of MathEnv, SWEEnv, TerminalBenchEnv:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class MathEnv(GEMMathEnv):\n    def __init__(self, dataset_name: str = "", mode: str = "train", **kwargs):\n        # Convert train/val mode to sample/traversal\n        global_dataset_mode = "sample" if self.mode == "train" else "traversal"\n        \n        self.dataset = GlobalDataset.options(\n            name=f"{self.mode}_{dataset_name}",\n            get_if_exists=True,\n            namespace=RAY_NAMESPACE\n        ).remote(\n            dataset_name=dataset_name,\n            split=split,\n            mode=global_dataset_mode\n        )\n        \n        # Create and register dataset_manager, this is necessary for implementing multiple val\n        self.dataset_manager = GlobalDatasetManager.options(\n            name=f"{self.mode}_dataset_manager",\n            get_if_exists=True,\n            namespace=RAY_NAMESPACE\n        ).remote()\n        ray.get(self.dataset_manager.register.remote(\n            dataset_name=dataset_name, \n            dataset_ref=self.dataset\n        ))\n'})}),"\n",(0,o.jsx)(n.h2,{id:"3-validation-dataset-traversal-configuration-during-training",children:"3. Validation Dataset Traversal Configuration During Training"}),"\n",(0,o.jsx)(n.h3,{id:"31-configuration-principles",children:"3.1 Configuration Principles"}),"\n",(0,o.jsx)(n.p,{children:"For scenarios that require dataset traversal (such as math/code/swe validation scenarios), special configuration is required:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Set mode parameter when defining env"}),": In val mode, need to set ",(0,o.jsx)(n.code,{children:"mode=val"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Set val_batch_size=-1"}),": This allows traversal of the entire val dataset"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Exit when env.reset returns None"}),": When dataset traversal is complete, env.reset will return None"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"32-mathenv-implementation-reference",children:"3.2 MathEnv Implementation Reference"}),"\n",(0,o.jsxs)(n.p,{children:["Location: ",(0,o.jsx)(n.code,{children:"roll.pipeline.agentic.env.gem.math_env.MathEnv"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class MathEnv(GEMMathEnv):\n    def __init__(self, mode: str = "train", **kwargs):\n        # Convert mode\n        global_dataset_mode = "sample" if self.mode == "train" else "traversal"\n        self.dataset = GlobalDataset.remote(\n            dataset_name=dataset_name,\n            split=split,\n            mode=global_dataset_mode\n        )\n    \n    def reset(self, seed: Optional[None] = None) -> Tuple[str, dict[str, Any]]:\n        data = ray.get(self.dataset.get_data_item.remote(seed=seed))\n        if data is None:\n            return None, None  # Dataset traversal complete\n        # Process data...\n'})}),"\n",(0,o.jsx)(n.h3,{id:"33-yaml-configuration-example",children:"3.3 YAML Configuration Example"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'rollout_batch_size: 128\nval_batch_size: -1  # Traverse entire dataset\n\ndeep_math:\n    env_type: "roll_math"\n    env_config:\n      mode: val  # Set to validation mode\n      dataset_name: data/math_deepmath_deal.jsonl\n      split: train\n      question_key: prompt\n      answer_key: ground_truth\n'})}),"\n",(0,o.jsx)(n.h3,{id:"34-random-sampling-evaluation-scenarios",children:"3.4 Random Sampling Evaluation Scenarios"}),"\n",(0,o.jsx)(n.p,{children:"For random sampling evaluation scenarios such as games, simply configure in the conventional way, ensuring the same seed returns the same data. Random sampling is the default implementation, no special configuration required."}),"\n",(0,o.jsx)(n.h2,{id:"4-trajectory-synthesis-dataset-traversal-configuration",children:"4. Trajectory Synthesis Dataset Traversal Configuration"}),"\n",(0,o.jsx)(n.h3,{id:"41-agenticrolloutpipeline-implementation",children:"4.1 AgenticRolloutPipeline Implementation"}),"\n",(0,o.jsxs)(n.p,{children:["Location: ",(0,o.jsx)(n.code,{children:"roll/pipeline/agentic/agentic_rollout_pipeline.py"})]}),"\n",(0,o.jsx)(n.h3,{id:"42-startup-method",children:"4.2 Startup Method"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-shell",children:"python examples/start_agentic_rollout_pipeline.py --config_path $CONFIG_PATH --config_name $CONFIG_NAME\n"})}),"\n",(0,o.jsx)(n.h3,{id:"43-core-configuration-reference",children:"4.3 Core Configuration Reference"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'# Trajectory storage directory\nrollout_dump_dir: /data/oss_bucket_0/lixing/log/swe/${model_name}/rollout_trajectories\n\n# Support ODPS storage\n# rollout_dump_dir: odps://odps_project/tables/table_name/ds=${model_name}\n\n# Environment manager configuration\ntrain_env_manager:\n  max_env_num_per_worker: 16\n  num_env_groups: 32\n  group_size: 1  # Support multiple trajectories for the same prompt rollout\n  tags: [SWEEnvVal]\n  num_groups_partition: [32]\n\n# Custom environment configuration\ncustom_envs:\n  SWEEnvVal:\n    env_type: "swe_env"\n    env_config:\n      mode: val  # Validation mode\n'})}),"\n",(0,o.jsx)(n.h3,{id:"44-trajectory-dump-configuration",children:"4.4 Trajectory Dump Configuration"}),"\n",(0,o.jsxs)(n.p,{children:["In the ",(0,o.jsx)(n.code,{children:"formulate_rollouts"})," method of EnvManager, need to register dump fields and types:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'def formulate_rollouts(self, rollout_cache: RolloutCache):\n    # Prepare data\n    save = {\n        "task_idx": task_idx,\n        "episode_score": episode_score,\n        "traj_messages": traj_messages,\n        "metrics": metrics,\n        # ... other fields\n    }\n    \n    # Register dump fields\n    lm_input.non_tensor_batch["model_name"] = np.array(\n        [os.path.basename(self.pipeline_config.base_dir)], dtype=object\n    )\n    lm_input.non_tensor_batch["save_content"] = np.array([json.dumps(save)], dtype=object)\n    lm_input.non_tensor_batch["step"] = np.array([self.current_step], dtype=object)\n    lm_input.non_tensor_batch["task_idx"] = np.array([task_idx], dtype=object)\n    lm_input.non_tensor_batch["stop_reason"] = np.array([stop_reason], dtype=object)\n    lm_input.non_tensor_batch["mode"] = np.array([self.mode], dtype=object)\n    lm_input.non_tensor_batch["episode_score"] = np.array([episode_score], dtype=object)\n    \n    # Configure database field types\n    colummns_config = [\n        ["task_idx", "bigint"],\n        ["model_name", "string"],\n        ["stop_reason", "string"],\n        ["episode_score", "double"],\n        ["mode", "string"],\n        ["save_content", "string"],\n    ]\n    lm_input.meta_info["COLUMMNS_CONFIG"] = colummns_config\n    \n    return lm_input\n'})}),"\n",(0,o.jsx)(n.h3,{id:"45-important-notes",children:"4.5 Important Notes"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"Keys in columns_config will be removed from data_proto after dump"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"save_content field contains complete trajectory information, stored in JSON format"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"Support local file system and ODPS table storage"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"Each trajectory has a unique trajectory_id for tracking"})}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"5-trajectory-filtering",children:"5. Trajectory Filtering"}),"\n",(0,o.jsx)(n.h3,{id:"51-usage-method",children:"5.1 Usage Method"}),"\n",(0,o.jsxs)(n.p,{children:["The trajectory filtering function is implemented by configuring the filter class through ",(0,o.jsx)(n.code,{children:"roll.pipeline.agentic.agentic_config.EnvManagerConfig.group_filter_cls"}),". ",(0,o.jsx)(n.code,{children:"roll.pipeline.agentic.agentic_pipeline.GroupFilter"})," is the default implementation."]}),"\n",(0,o.jsx)(n.h3,{id:"52-custom-filtering-logic",children:"5.2 Custom Filtering Logic"}),"\n",(0,o.jsx)(n.p,{children:"Custom complex trajectory filtering logic can be implemented, for example:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class GroupFilter:\n    def __init__(self, config: AgenticConfig, env_manager_config: EnvManagerConfig, mode: str):\n        pass\n\n    def filter(self, group_id: int, episode_id: int, group: list[DataProto]):\n        for data in group:\n            if data.meta_info["drop_flag"]:\n                return True\n'})}),"\n",(0,o.jsx)(n.p,{children:"Through custom filter functions, flexible filtering strategies can be implemented based on various trajectory attributes (such as score, length, stop reason, etc.)."}),"\n",(0,o.jsx)(n.h2,{id:"6-frequently-asked-questions",children:"6. Frequently Asked Questions"}),"\n",(0,o.jsx)(n.h3,{id:"q1-how-to-handle-dataset-traversal-completion",children:"Q1: How to handle dataset traversal completion?"}),"\n",(0,o.jsxs)(n.p,{children:["A: Check the ",(0,o.jsx)(n.code,{children:"get_data_item"})," return value in the ",(0,o.jsx)(n.code,{children:"reset"})," method. If it returns None, it means dataset traversal is complete, and you should return None to exit the loop."]}),"\n",(0,o.jsx)(n.h3,{id:"q2-how-to-ensure-experiment-reproducibility",children:"Q2: How to ensure experiment reproducibility?"}),"\n",(0,o.jsxs)(n.p,{children:["A: Through a unified seed management mechanism, ensure the same seed returns the same data. The ",(0,o.jsx)(n.code,{children:"get_data_item"})," method of GlobalDataset guarantees this."]}),"\n",(0,o.jsx)(n.h3,{id:"q3-how-to-handle-large-scale-trajectory-data-storage",children:"Q3: How to handle large-scale trajectory data storage?"}),"\n",(0,o.jsxs)(n.p,{children:["A: You can use ODPS table storage by configuring ",(0,o.jsx)(n.code,{children:"rollout_dump_dir"})," as an ",(0,o.jsx)(n.code,{children:"odps://"})," format URL. For example:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"rollout_dump_dir: odps://odps_project/tables/table_name/ds=${model_name}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"q4-how-to-debug-the-trajectory-generation-process",children:"Q4: How to debug the trajectory generation process?"}),"\n",(0,o.jsx)(n.p,{children:"A: You can debug the trajectory generation process by configuring log levels and adding custom logs. Trajectory data will be completely saved in JSON format for easy analysis."}),"\n",(0,o.jsxs)(n.p,{children:["For multi-round interaction local debugging, refer to the documentation: ",(0,o.jsx)(n.a,{href:"/ROLL/docs/Getting%20Started/Debugging%20Guide/debug_guide",children:"Debug Guide"})]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);