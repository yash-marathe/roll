"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[6942],{28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>l});var r=t(96540);const s={},o=r.createContext(s);function i(e){const n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(o.Provider,{value:n},e.children)}},81461:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"Development/Developer Guide/support_new_models","title":"How to Add Support for a New Model","description":"To integrate a new model into ROLL, you must supply:","source":"@site/docs/Development/Developer Guide/support_new_models.md","sourceDirName":"Development/Developer Guide","slug":"/Development/Developer Guide/support_new_models","permalink":"/ROLL/docs/Development/Developer Guide/support_new_models","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/Development/Developer Guide/support_new_models.md","tags":[],"version":"current","lastUpdatedAt":1764223793000,"sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"RLVR Pipeline","permalink":"/ROLL/docs/Development/Architecture/RLVRPipeline"},"next":{"title":"Customer Env","permalink":"/ROLL/docs/Development/Developer Guide/customer_env"}}');var s=t(74848),o=t(28453);const i={sidebar_position:3},l="How to Add Support for a New Model",d={},a=[{value:"1. Inference Strategies",id:"1-inference-strategies",level:2},{value:"1.1 <code>vllm</code>",id:"11-vllm",level:3},{value:"1.2 <code>sglang</code>",id:"12-sglang",level:3},{value:"2. Training Strategies",id:"2-training-strategies",level:2},{value:"2.1 <code>DeepSpeed</code>",id:"21-deepspeed",level:3},{value:"2.2 <code>Megatron</code>",id:"22-megatron",level:3},{value:"1. For Standard Transformer Models",id:"1-for-standard-transformer-models",level:4},{value:"Registering a New Template",id:"registering-a-new-template",level:5},{value:"2. For Models with Custom Components",id:"2-for-models-with-custom-components",level:4}];function c(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"how-to-add-support-for-a-new-model",children:"How to Add Support for a New Model"})}),"\n",(0,s.jsxs)(n.p,{children:["To integrate a new model into ",(0,s.jsx)(n.strong,{children:"ROLL"}),", you must supply:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["at least one ",(0,s.jsx)(n.strong,{children:"inference"})," implementation, and"]}),"\n",(0,s.jsxs)(n.li,{children:["at least one ",(0,s.jsx)(n.strong,{children:"training"})," implementation."]}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Phase"}),(0,s.jsx)(n.th,{children:"Pick \u2265 1 backend"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Inference"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"vllm"}),", ",(0,s.jsx)(n.code,{children:"sglang"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Training"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"DeepSpeed"}),", ",(0,s.jsx)(n.code,{children:"Megatron"})]})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"1-inference-strategies",children:"1. Inference Strategies"}),"\n",(0,s.jsxs)(n.h3,{id:"11-vllm",children:["1.1 ",(0,s.jsx)(n.code,{children:"vllm"})]}),"\n",(0,s.jsxs)(n.p,{children:["Follow the official guide:",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.a,{href:"https://docs.vllm.ai/en/latest/contributing/model/registration.html#out-of-tree-models",children:"https://docs.vllm.ai/en/latest/contributing/model/registration.html#out-of-tree-models"})]}),"\n",(0,s.jsxs)(n.h3,{id:"12-sglang",children:["1.2 ",(0,s.jsx)(n.code,{children:"sglang"})]}),"\n",(0,s.jsxs)(n.p,{children:["Follow the official guide:",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.a,{href:"https://docs.sglang.ai/supported_models/support_new_models.html",children:"https://docs.sglang.ai/supported_models/support_new_models.html"})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"2-training-strategies",children:"2. Training Strategies"}),"\n",(0,s.jsxs)(n.h3,{id:"21-deepspeed",children:["2.1 ",(0,s.jsx)(n.code,{children:"DeepSpeed"})]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Ensure your model can be loaded by","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"transformers.AutoModelForCausalLM.from_pretrained(...)\n"})}),"\n","If not, add the model implementation directly to the ROLL repository."]}),"\n",(0,s.jsxs)(n.li,{children:["Make the model inherit from ",(0,s.jsx)(n.code,{children:"transformers.PreTrainedModel"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Make the model can be loaded in ",(0,s.jsx)(n.code,{children:"roll/models/model_providers.py"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Once these steps are complete, you can:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["train with the ",(0,s.jsx)(n.code,{children:"deepspeed_train"})," strategy for ",(0,s.jsx)(n.code,{children:"actor_train"})," worker, and"]}),"\n",(0,s.jsxs)(n.li,{children:["with ",(0,s.jsx)(n.code,{children:"hf_infer"})," or ",(0,s.jsx)(n.code,{children:"deepspeed_infer"})," strategy for the ",(0,s.jsx)(n.code,{children:"reference"})," worker."]}),"\n"]}),"\n",(0,s.jsxs)(n.h3,{id:"22-megatron",children:["2.2 ",(0,s.jsx)(n.code,{children:"Megatron"})]}),"\n",(0,s.jsxs)(n.p,{children:["To integrate a Hugging Face model with the ",(0,s.jsx)(n.code,{children:"Megatron"})," training strategy, you need to provide a conversion template. This template defines how to map the model's configuration and weights from the Hugging Face format to the Megatron-Core format."]}),"\n",(0,s.jsx)(n.h4,{id:"1-for-standard-transformer-models",children:"1. For Standard Transformer Models"}),"\n",(0,s.jsxs)(n.p,{children:["If your model has a standard Transformer architecture compatible with ",(0,s.jsx)(n.code,{children:"mcore.GPTModel"}),", you only need to register a new conversion template. All templates are located in ",(0,s.jsx)(n.code,{children:"mcore_adapter/src/mcore_adapter/models/converter/template.py"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["To add a new template, you'll call the ",(0,s.jsx)(n.code,{children:"register_template"})," function at the end of this file. Here\u2019s a detailed guide on how to construct the arguments for this function."]}),"\n",(0,s.jsx)(n.h5,{id:"registering-a-new-template",children:"Registering a New Template"}),"\n",(0,s.jsxs)(n.p,{children:["The core of the integration is the ",(0,s.jsx)(n.code,{children:"register_template"})," function. Let's break down its main parameters:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"register_template(\n    hf_model_type,\n    config_hf_to_mca,\n    weight_converters,\n    hf_layer_prefix,\n    constant_mca_config={},\n    hf_invalid_keys=[],\n    ...\n)\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["a. ",(0,s.jsx)(n.code,{children:"hf_model_type"})," (str):"]}),"\nThis is the most crucial parameter. It must exactly match the ",(0,s.jsx)(n.code,{children:"model_type"})," field in the model's Hugging Face ",(0,s.jsx)(n.code,{children:"config.json"})," file. The converter uses this string to look up the correct template."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["b. ",(0,s.jsx)(n.code,{children:"hf_layer_prefix"})," (str):"]}),"\nThis specifies the prefix for the transformer layers in the Hugging Face model's state dictionary. For most models, this will be something like ",(0,s.jsx)(n.code,{children:'"model.layers."'}),"."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["c. ",(0,s.jsx)(n.code,{children:"config_hf_to_mca"})," (Dict[str, str]):"]}),"\nThis dictionary maps configuration parameter names from the Hugging Face ",(0,s.jsx)(n.code,{children:"config.json"})," to their corresponding names in the Megatron-Core ",(0,s.jsx)(n.code,{children:"TransformerConfig"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["d. ",(0,s.jsx)(n.code,{children:"weight_converters"})," (List[ConverOp]):"]}),"\nThis is a list of converter operations that define how to transform weights from the HF format to the MCA format. Each operation is an instance of a ",(0,s.jsx)(n.code,{children:"ConverOp"})," subclass."]}),"\n",(0,s.jsx)(n.p,{children:"Common converter operations include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"RenameConverOp"})}),": Used for weights that only need to be renamed.","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Renames 'lm_head.weight' in HF to 'output_layer.weight' in MCA\nRenameConverOp(hf_names=\"lm_head.weight\", mca_names=\"output_layer.weight\")\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"StackConverOp"})}),": Stacks multiple HF tensors into a single MCA tensor. This is commonly used for the gate and up projections in SwiGLU layers.","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Stacks two HF weights into one MCA weight for the first feed-forward layer\nStackConverOp(\n    hf_names=[".mlp.gate_proj.weight", ".mlp.up_proj.weight"], \n    mca_names=".mlp.linear_fc1.weight", \n    dim=0\n)\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"QKVConverOp"})}),": Fuses the separate Query, Key, and Value weight tensors from HF into a single, interleaved QKV tensor required by Megatron-Core.","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Fuses Q, K, and V weights into a single QKV weight\nQKVConverOp(\n    hf_names=[".self_attn.q_proj.weight", ".self_attn.k_proj.weight", ".self_attn.v_proj.weight"],\n    mca_names=".self_attention.linear_qkv.weight",\n)\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsxs)(n.strong,{children:["e. ",(0,s.jsx)(n.code,{children:"constant_mca_config"})," (Dict[str, Any]):"]}),"\nThis dictionary defines Megatron-Core configuration values that are constant for the model and are not available in the HF config."]}),"\n",(0,s.jsx)(n.h4,{id:"2-for-models-with-custom-components",children:"2. For Models with Custom Components"}),"\n",(0,s.jsxs)(n.p,{children:["If the model includes unique components not found in a standard ",(0,s.jsx)(n.code,{children:"mcore.GPTModel"})," (e.g., Vision Transformer blocks in a multimodal model like Qwen2-VL), you will need to:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Implement a new model class that inherits from ",(0,s.jsx)(n.code,{children:"mcore.GPTModel"})," and adds the custom logic. You can use the implementations for ",(0,s.jsx)(n.code,{children:"qwen2-vl"})," and ",(0,s.jsx)(n.code,{children:"qwen2.5-vl"})," in the repository as a reference."]}),"\n",(0,s.jsxs)(n.li,{children:["Register a template for the parts of the model that are standard, as described above. The template can also handle renaming for the custom parts (e.g., ",(0,s.jsx)(n.code,{children:'RenameConverOp(hf_names="visual.{}", mca_names="vision_model.{}")'}),")."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"After completing these steps, you can:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["train with the ",(0,s.jsx)(n.code,{children:"megatron_train"})," strategy for the ",(0,s.jsx)(n.code,{children:"actor_train"})," worker, and"]}),"\n",(0,s.jsxs)(n.li,{children:["use the ",(0,s.jsx)(n.code,{children:"megatron_infer"})," strategy for the ",(0,s.jsx)(n.code,{children:"reference"})," worker."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);