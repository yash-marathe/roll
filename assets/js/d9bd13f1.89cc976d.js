"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[8635],{60283(e,n,s){s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>d,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"User Guides/Configuration/fsdp2","title":"FSDP2 Training and Inference Backend Configuration Guide","description":"FSDP2 (Fully Sharded Data Parallel 2 is PyTorch\'s latest distributed training framework that provides efficient parameter sharding with DTensor. This document will provide detailed instructions on how to configure and use the FSDP2 backend in the ROLL framework.","source":"@site/docs/User Guides/Configuration/fsdp2.md","sourceDirName":"User Guides/Configuration","slug":"/User Guides/Configuration/fsdp2","permalink":"/ROLL/docs/User Guides/Configuration/fsdp2","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/User Guides/Configuration/fsdp2.md","tags":[],"version":"current","lastUpdatedAt":1770642330000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"FP8 Quantization Configuration Guide","permalink":"/ROLL/docs/User Guides/Configuration/fp8_rollout"},"next":{"title":"LoRA Fine-tuning Configuration Guide","permalink":"/ROLL/docs/User Guides/Configuration/lora"}}');var r=s(74848),l=s(28453);const a={},d="FSDP2 Training and Inference Backend Configuration Guide",t={},o=[{value:"FSDP2 with ROLL",id:"fsdp2-with-roll",level:2},{value:"Configuring FSDP2 Strategy",id:"configuring-fsdp2-strategy",level:2},{value:"Training Configuration Example",id:"training-configuration-example",level:3},{value:"Inference Configuration Example",id:"inference-configuration-example",level:3},{value:"FSDP2 + Context Parallel Configuration Example",id:"fsdp2--context-parallel-configuration-example",level:3},{value:"Configuration Parameter Details",id:"configuration-parameter-details",level:3},{value:"Device Mesh Configuration",id:"device-mesh-configuration",level:2},{value:"Pure FSDP2 Mode",id:"pure-fsdp2-mode",level:3},{value:"HSDP Mode",id:"hsdp-mode",level:3},{value:"FSDP2 + Context Parallel (Ulysses)",id:"fsdp2--context-parallel-ulysses",level:3},{value:"Model-Specific Configurations",id:"model-specific-configurations",level:2},{value:"Text Models (Qwen2.5, Qwen3, LLaMA)",id:"text-models-qwen25-qwen3-llama",level:3},{value:"Vision-Language Models (Qwen2.5-VL, Qwen3-VL)",id:"vision-language-models-qwen25-vl-qwen3-vl",level:3},{value:"MoE Models (Qwen3-MoE)",id:"moe-models-qwen3-moe",level:3},{value:"Notes",id:"notes",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"fsdp2-training-and-inference-backend-configuration-guide",children:"FSDP2 Training and Inference Backend Configuration Guide"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://docs.pytorch.org/tutorials/intermediate/FSDP_tutorial.html",children:"FSDP2 (Fully Sharded Data Parallel 2"})," is PyTorch's latest distributed training framework that provides efficient parameter sharding with ",(0,r.jsx)(n.a,{href:"https://docs.pytorch.org/docs/stable/distributed.tensor.html",children:"DTensor"}),". This document will provide detailed instructions on how to configure and use the FSDP2 backend in the ROLL framework."]}),"\n",(0,r.jsx)(n.h2,{id:"fsdp2-with-roll",children:"FSDP2 with ROLL"}),"\n",(0,r.jsx)(n.p,{children:"ROLL support the following FSDP2 features:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"FSDP2 Sharding"}),": Shards model parameters, gradients, and optimizer with FSDP2 ",(0,r.jsx)(n.a,{href:"https://docs.pytorch.org/docs/main/distributed.fsdp.fully_shard.html",children:"fully_shard"}),". Also support checkpoint management with ",(0,r.jsx)(n.a,{href:"https://docs.pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html",children:"DCP"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Context Parallelism"}),": Supports integration with Context Parallel (Ulysses)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Support"}),": Supports text models, Vision-Language (VL) models, and MoE (Mixture of Experts) models."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"configuring-fsdp2-strategy",children:"Configuring FSDP2 Strategy"}),"\n",(0,r.jsxs)(n.p,{children:["In the ROLL framework, FSDP2 training and inference strategies can be configured by setting ",(0,r.jsx)(n.code,{children:"strategy_args"})," in the YAML configuration file."]}),"\n",(0,r.jsx)(n.h3,{id:"training-configuration-example",children:"Training Configuration Example"}),"\n",(0,r.jsxs)(n.p,{children:["The following is a typical FSDP2 training configuration example (from ",(0,r.jsx)(n.code,{children:"examples_lixing/qwen3-8B-rlvr_fsdp2/rlvr_config.yaml"}),"):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"actor_train:\n  model_args:\n    disable_gradient_checkpointing: false\n    dtype: bf16\n    model_type: ~\n  training_args:\n    learning_rate: 1.0e-6\n    weight_decay: 0\n    per_device_train_batch_size: 1\n    gradient_accumulation_steps: 32\n    warmup_steps: 20\n    num_train_epochs: 50\n  strategy_args:\n    strategy_name: fsdp2_train\n    strategy_config:\n      fsdp_size: 16\n      param_dtype: bf16\n      reduce_dtype: float32\n      reshard_after_forward: true\n      offload_policy: false\n  device_mapping: list(range(0,16))\n  infer_batch_size: 4\n"})}),"\n",(0,r.jsx)(n.h3,{id:"inference-configuration-example",children:"Inference Configuration Example"}),"\n",(0,r.jsx)(n.p,{children:"The following is a typical FSDP2 inference configuration example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"reference:\n  model_args:\n    disable_gradient_checkpointing: true\n    dtype: bf16\n    model_type: ~\n  strategy_args:\n    strategy_name: fsdp2_infer\n    strategy_config:\n      fsdp_size: 4\n      param_dtype: bf16\n      reduce_dtype: float32\n      reshard_after_forward: true\n      offload_policy: false\n  device_mapping: list(range(0,8))\n  infer_batch_size: 1\n"})}),"\n",(0,r.jsx)(n.h3,{id:"fsdp2--context-parallel-configuration-example",children:"FSDP2 + Context Parallel Configuration Example"}),"\n",(0,r.jsxs)(n.p,{children:["The following is a configuration example combining FSDP2 with Context Parallel (Ulysses) (from ",(0,r.jsx)(n.code,{children:"examples_lixing/qwen3-4b-vl_fsdp2_lct/vl_fsdp2_lct_cp2.yaml"}),"):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"actor_train:\n  model_args:\n    disable_gradient_checkpointing: false\n    dtype: bf16\n    model_type: ~\n    ulysses_size: 2  # Context parallel size\n  training_args:\n    learning_rate: 1.0e-6\n    weight_decay: 1.0e-2\n    per_device_train_batch_size: 1\n    gradient_accumulation_steps: 256\n    warmup_steps: 0\n    num_train_epochs: 50\n  strategy_args:\n    strategy_name: fsdp2_train\n    strategy_config:\n      fsdp_size: 4  # FSDP sharding size\n      param_dtype: bf16\n      reduce_dtype: float32\n      reshard_after_forward: true\n      offload_policy: false\n  device_mapping: list(range(0,8))\n  infer_batch_size: 1\n"})}),"\n",(0,r.jsx)(n.p,{children:"In this example:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Total GPUs: 8"}),"\n",(0,r.jsx)(n.li,{children:"Context Parallel (Ulysses) size: 2"}),"\n",(0,r.jsx)(n.li,{children:"FSDP size: 4"}),"\n",(0,r.jsx)(n.li,{children:"Device mesh shape: (2, 4) [ddp, fsdp]"}),"\n",(0,r.jsx)(n.li,{children:"2 replicas, each with 4-way parameter sharding"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"configuration-parameter-details",children:"Configuration Parameter Details"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"strategy_name"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"fsdp2_train"})," for training"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"fsdp2_infer"})," for inference"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"strategy_config"}),": FSDP2-specific configuration parameters"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"fsdp_size"}),": Number of FSDP shards"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["If ",(0,r.jsx)(n.code,{children:"fsdp_size >= world_size"})," or ",(0,r.jsx)(n.code,{children:"fsdp_size <= 1"}),": pure FSDP2 mode"]}),"\n",(0,r.jsxs)(n.li,{children:["If ",(0,r.jsx)(n.code,{children:"fsdp_size < world_size"}),": HSDP mode with DDP replicas"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"param_dtype"}),": Parameter data type (e.g., ",(0,r.jsx)(n.code,{children:"bf16"}),", ",(0,r.jsx)(n.code,{children:"fp16"}),", ",(0,r.jsx)(n.code,{children:"float32"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"reduce_dtype"}),": Data type for gradient reduction (e.g., ",(0,r.jsx)(n.code,{children:"float32"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"reshard_after_forward"}),": Whether to reshard parameters after forward pass"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"true"}),": Reshard after forward"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"false"}),": Keep parameters gathered"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"offload_policy"}),": Whether to enable CPU offloading"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"true"}),": Offload parameters to CPU when not in use (saves GPU memory)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"false"}),": Keep all parameters on GPU (faster but uses more memory)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"wrap_policy"}),": Module wrapping policy"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"transformer_layer_cls_to_wrap"}),": List of transformer layer class names to wrap (e.g., ",(0,r.jsx)(n.code,{children:'["Qwen3DecoderLayer"]'}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"wrap_embeddings"}),": Whether to wrap embedding layers (default: ",(0,r.jsx)(n.code,{children:"false"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"wrap_lm_output"}),": Whether to wrap LM head (default: ",(0,r.jsx)(n.code,{children:"false"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"moe_experts"}),": List of MoE expert block class names to wrap (for MoE models, we may want to wrap each experts seperately to avoid OOM during param. gather, but need dummy expert forward to avoid hang, see ",(0,r.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:s(72762).A+"",children:"example"}),")"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["if not sef the ",(0,r.jsx)(n.code,{children:"wrap_policy"}),", by default will use the _no_splite_modules for transofmers models."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"apply_expert_patch"}),": Whether to apply MoE expert patch (for MoE models)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"true"}),": Apply patch to prevent deadlocks when different ranks activate different experts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"false"}),": Don't apply patch (may cause deadlocks in MoE models)"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"apply_tiled_mlp"}),": Whether to apply TiledMLP optimization"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"true"}),": Use tiled MLP computation to reduce memory usage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"false"}),": Use standard MLP computation"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"tiled_num_shards"}),": Number of shards for TiledMLP (default: 4)"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"async_save_ckpt"}),": Whether to save checkpoints asynchronously (default: ",(0,r.jsx)(n.code,{children:"true"}),")"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ulysses_size"}),": Context parallel size (set in ",(0,r.jsx)(n.code,{children:"model_args"}),")"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Splits sequence dimension across multiple GPUs"}),"\n",(0,r.jsx)(n.li,{children:"Compatible with FSDP2 for hybrid parallelism"}),"\n",(0,r.jsx)(n.li,{children:"Useful for long-context training"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"device_mapping"}),": Specify the list of GPU device IDs to use"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"infer_batch_size"}),": Batch size during inference"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"device-mesh-configuration",children:"Device Mesh Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["FSDP2 supports different device mesh configurations based on ",(0,r.jsx)(n.code,{children:"fsdp_size"})," and ",(0,r.jsx)(n.code,{children:"ulysses_size"}),":"]}),"\n",(0,r.jsx)(n.h3,{id:"pure-fsdp2-mode",children:"Pure FSDP2 Mode"}),"\n",(0,r.jsxs)(n.p,{children:["When ",(0,r.jsx)(n.code,{children:"fsdp_size >= world_size"})," or ",(0,r.jsx)(n.code,{children:"fsdp_size <= 1"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Example: 16 GPUs, fsdp_size=16\nstrategy_config:\n  fsdp_size: 16\n# Device mesh: (16,) [fsdp]\n# All 16 GPUs shard parameters\n"})}),"\n",(0,r.jsx)(n.h3,{id:"hsdp-mode",children:"HSDP Mode"}),"\n",(0,r.jsxs)(n.p,{children:["When ",(0,r.jsx)(n.code,{children:"fsdp_size < world_size"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Example: 16 GPUs, fsdp_size=8\nstrategy_config:\n  fsdp_size: 8\n# ddp_size = 16 // 8 = 2\n# Device mesh: (2, 8) [ddp, fsdp]\n# 2 replicas, each with 8-way parameter sharding\n"})}),"\n",(0,r.jsx)(n.h3,{id:"fsdp2--context-parallel-ulysses",children:"FSDP2 + Context Parallel (Ulysses)"}),"\n",(0,r.jsxs)(n.p,{children:["When both ",(0,r.jsx)(n.code,{children:"ulysses_size"})," and ",(0,r.jsx)(n.code,{children:"fsdp_size"})," are configured:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Example: 8 GPUs, ulysses_size=2, fsdp_size=4\nmodel_args:\n  ulysses_size: 2\nstrategy_config:\n  fsdp_size: 4\n# ddp_size = 8 // 4 = 2\n# Device mesh: (2, 4) [ddp, fsdp]\n# 2 replicas, each with 4-way parameter sharding\n# Ulysses: 2-way context parallel (sequence dimension split)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"model-specific-configurations",children:"Model-Specific Configurations"}),"\n",(0,r.jsx)(n.h3,{id:"text-models-qwen25-qwen3-llama",children:"Text Models (Qwen2.5, Qwen3, LLaMA)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'strategy_config:\n  fsdp_size: 16\n  param_dtype: bf16\n  reduce_dtype: float32\n  wrap_policy:\n    transformer_layer_cls_to_wrap: ["Qwen3DecoderLayer"]\n'})}),"\n",(0,r.jsx)(n.h3,{id:"vision-language-models-qwen25-vl-qwen3-vl",children:"Vision-Language Models (Qwen2.5-VL, Qwen3-VL)"}),"\n",(0,r.jsx)(n.p,{children:"VL models require special handling for the vision tower:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"actor_train:\n  model_args:\n    freeze_module_prefix: vision_model  # Freeze vision tower\n    ulysses_size: 2  # Optional: context parallel\n  strategy_args:\n    strategy_name: fsdp2_train\n    strategy_config:\n      fsdp_size: 4\n      param_dtype: bf16\n      reduce_dtype: float32\n      # Vision tower blocks automatically have cast_forward_inputs disabled\n"})}),"\n",(0,r.jsx)(n.h3,{id:"moe-models-qwen3-moe",children:"MoE Models (Qwen3-MoE)"}),"\n",(0,r.jsx)(n.p,{children:"MoE models require the expert patch to prevent deadlocks:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'strategy_config:\n  fsdp_size: 16\n  param_dtype: bf16\n  reduce_dtype: float32\n  apply_expert_patch: true  # Critical for MoE models if wrap each expert separately\n  wrap_policy:\n    moe_experts: ["Qwen3MoeMLP"]\n'})}),"\n",(0,r.jsx)(n.h2,{id:"notes",children:"Notes"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"PyTorch Version"}),": FSDP2 requires PyTorch >= 2.4"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"MoE Models"}),": Always enable ",(0,r.jsx)(n.code,{children:"apply_expert_patch: true"})," for MoE models to prevent deadlocks if wrap experts seperately"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VL Models"}),": Vision tower blocks automatically handle precision issues"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Memory vs Performance"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"offload_policy: true"})," saves memory but is slower"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"reshard_after_forward: true"})," saves memory but may be slower"]}),"\n",(0,r.jsx)(n.li,{children:"Balance based on your hardware and requirements"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},72762(e,n,s){s.d(n,{A:()=>i});const i=s.p+"assets/files/qwen3_moe_patch-83fd6b6c7a691229bf71364630c23b5f.py"},28453(e,n,s){s.d(n,{R:()=>a,x:()=>d});var i=s(96540);const r={},l=i.createContext(r);function a(e){const n=i.useContext(l);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);