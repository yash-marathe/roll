"use strict";(self.webpackChunkdocs_roll=self.webpackChunkdocs_roll||[]).push([[5378],{5680:(e,n,i)=>{i.d(n,{xA:()=>p,yg:()=>m});var a=i(6540);function r(e,n,i){return n in e?Object.defineProperty(e,n,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[n]=i,e}function t(e,n){var i=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter(function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable})),i.push.apply(i,a)}return i}function o(e){for(var n=1;n<arguments.length;n++){var i=null!=arguments[n]?arguments[n]:{};n%2?t(Object(i),!0).forEach(function(n){r(e,n,i[n])}):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(i)):t(Object(i)).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(i,n))})}return e}function l(e,n){if(null==e)return{};var i,a,r=function(e,n){if(null==e)return{};var i,a,r={},t=Object.keys(e);for(a=0;a<t.length;a++)i=t[a],n.indexOf(i)>=0||(r[i]=e[i]);return r}(e,n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);for(a=0;a<t.length;a++)i=t[a],n.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(e,i)&&(r[i]=e[i])}return r}var s=a.createContext({}),g=function(e){var n=a.useContext(s),i=n;return e&&(i="function"==typeof e?e(n):o(o({},n),e)),i},p=function(e){var n=g(e.components);return a.createElement(s.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef(function(e,n){var i=e.components,r=e.mdxType,t=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=g(i),u=r,m=c["".concat(s,".").concat(u)]||c[u]||d[u]||t;return i?a.createElement(m,o(o({ref:n},p),{},{components:i})):a.createElement(m,o({ref:n},p))});function m(e,n){var i=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var t=i.length,o=new Array(t);o[0]=u;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[c]="string"==typeof e?e:r,o[1]=l;for(var g=2;g<t;g++)o[g]=i[g];return a.createElement.apply(null,o)}return a.createElement.apply(null,i)}u.displayName="MDXCreateElement"},6961:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>t,metadata:()=>l,toc:()=>g});var a=i(8168),r=(i(6540),i(5680));const t={},o="ROLL Configuration System Detailed Explanation",l={unversionedId:"English/QuickStart/config_system",id:"English/QuickStart/config_system",title:"ROLL Configuration System Detailed Explanation",description:"The ROLL framework adopts a structured configuration system that defines experimental parameters through YAML files. This document will provide a detailed introduction to ROLL's configuration design, helping new users understand the framework's configuration structure and extension methods.",source:"@site/docs/English/QuickStart/config_system.md",sourceDirName:"English/QuickStart",slug:"/English/QuickStart/config_system",permalink:"/ROLL/docs/English/QuickStart/config_system",draft:!1,editUrl:"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/English/QuickStart/config_system.md",tags:[],version:"current",lastUpdatedAt:1755682791,formattedLastUpdatedAt:"Aug 20, 2025",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Configuration Guide",permalink:"/ROLL/docs/English/QuickStart/config_guide"},next:{title:"ROLL Debugging Guide",permalink:"/ROLL/docs/English/QuickStart/debug_guide"}},s={},g=[{value:"Configuration System Architecture",id:"configuration-system-architecture",level:2},{value:"1. BaseConfig - Base Configuration Class",id:"1-baseconfig---base-configuration-class",level:3},{value:"2. WorkerConfig - Worker Node Configuration Class",id:"2-workerconfig---worker-node-configuration-class",level:3},{value:"3. PipelineConfig - Pipeline Configuration Class",id:"3-pipelineconfig---pipeline-configuration-class",level:3},{value:"4. Strategy - Strategy Configuration",id:"4-strategy---strategy-configuration",level:3},{value:"5. Arguments Classes",id:"5-arguments-classes",level:3},{value:"Configuration Class UML Diagram",id:"configuration-class-uml-diagram",level:2},{value:"Mapping between YAML Configuration and PipelineConfig",id:"mapping-between-yaml-configuration-and-pipelineconfig",level:2},{value:"Configuration Validation Mechanism",id:"configuration-validation-mechanism",level:2},{value:"Global Environment Variables/Worker-Specific Environment Variables Configuration Entry",id:"global-environment-variablesworker-specific-environment-variables-configuration-entry",level:2},{value:"Configuration Method",id:"configuration-method",level:3},{value:"Global Environment Variable Configuration",id:"global-environment-variable-configuration",level:4},{value:"Worker-Specific Environment Variable Configuration",id:"worker-specific-environment-variable-configuration",level:4},{value:"Priority Rules",id:"priority-rules",level:3},{value:"Configuration Example Analysis",id:"configuration-example-analysis",level:2}],p={toc:g},c="wrapper";function d({components:e,...n}){return(0,r.yg)(c,(0,a.A)({},p,n,{components:e,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"roll-configuration-system-detailed-explanation"},"ROLL Configuration System Detailed Explanation"),(0,r.yg)("p",null,"The ROLL framework adopts a structured configuration system that defines experimental parameters through YAML files. This document will provide a detailed introduction to ROLL's configuration design, helping new users understand the framework's configuration structure and extension methods."),(0,r.yg)("h2",{id:"configuration-system-architecture"},"Configuration System Architecture"),(0,r.yg)("p",null,"ROLL's configuration system is primarily composed of the following core components:"),(0,r.yg)("h3",{id:"1-baseconfig---base-configuration-class"},"1. BaseConfig - Base Configuration Class"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"BaseConfig")," is the base class for all configurations, defining basic experimental parameters such as:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Experiment name (",(0,r.yg)("inlineCode",{parentName:"li"},"exp_name"),")"),(0,r.yg)("li",{parentName:"ul"},"Random seed (",(0,r.yg)("inlineCode",{parentName:"li"},"seed"),")"),(0,r.yg)("li",{parentName:"ul"},"Output directory (",(0,r.yg)("inlineCode",{parentName:"li"},"output_dir"),")"),(0,r.yg)("li",{parentName:"ul"},"Log directory (",(0,r.yg)("inlineCode",{parentName:"li"},"logging_dir"),")"),(0,r.yg)("li",{parentName:"ul"},"Tracker configuration (",(0,r.yg)("inlineCode",{parentName:"li"},"track_with"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"tracker_kwargs"),")"),(0,r.yg)("li",{parentName:"ul"},"Training step control (",(0,r.yg)("inlineCode",{parentName:"li"},"max_steps"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"save_steps"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"logging_steps"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"eval_steps"),")"),(0,r.yg)("li",{parentName:"ul"},"Batch size (",(0,r.yg)("inlineCode",{parentName:"li"},"rollout_batch_size"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"val_batch_size"),")"),(0,r.yg)("li",{parentName:"ul"},"Sequence length settings (",(0,r.yg)("inlineCode",{parentName:"li"},"prompt_length"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"response_length"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"sequence_length"),")")),(0,r.yg)("h3",{id:"2-workerconfig---worker-node-configuration-class"},"2. WorkerConfig - Worker Node Configuration Class"),(0,r.yg)("p",null,(0,r.yg)("inlineCode",{parentName:"p"},"WorkerConfig")," defines the configuration for each worker node (such as training/inference roles), including:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Model parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"model_args"),")"),(0,r.yg)("li",{parentName:"ul"},"Training parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"training_args"),")"),(0,r.yg)("li",{parentName:"ul"},"Data parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"data_args"),")"),(0,r.yg)("li",{parentName:"ul"},"Generation parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"generating_args"),")"),(0,r.yg)("li",{parentName:"ul"},"Strategy parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"strategy_args"),")"),(0,r.yg)("li",{parentName:"ul"},"Device mapping (",(0,r.yg)("inlineCode",{parentName:"li"},"device_mapping"),")"),(0,r.yg)("li",{parentName:"ul"},"Number of worker nodes (",(0,r.yg)("inlineCode",{parentName:"li"},"world_size"),")")),(0,r.yg)("h3",{id:"3-pipelineconfig---pipeline-configuration-class"},"3. PipelineConfig - Pipeline Configuration Class"),(0,r.yg)("p",null,"In RLVR scenarios, ",(0,r.yg)("inlineCode",{parentName:"p"},"RLVRConfig")," inherits from ",(0,r.yg)("inlineCode",{parentName:"p"},"BaseConfig")," and serves as the configuration class for specific tasks (other PipelineConfigs include AgenticConfig, DPOConfig, DistillConfig). It includes:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Role configurations (",(0,r.yg)("inlineCode",{parentName:"li"},"actor_train"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"actor_infer"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"reference"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"critic"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"rewards"),", etc.)"),(0,r.yg)("li",{parentName:"ul"},"RL algorithm-related parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"ppo_epochs"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"adv_estimator"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"reward_clip"),", etc.)"),(0,r.yg)("li",{parentName:"ul"},"Data processing parameters (",(0,r.yg)("inlineCode",{parentName:"li"},"max_len_mask"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"difficulty_mask"),", etc.)")),(0,r.yg)("h3",{id:"4-strategy---strategy-configuration"},"4. Strategy - Strategy Configuration"),(0,r.yg)("p",null,"Strategy configuration defines the training/inference strategy used by each worker node, including:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"Strategy name (such as ",(0,r.yg)("inlineCode",{parentName:"li"},"megatron_train"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"vllm"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"sglang"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"deepspeed_train"),", etc.)"),(0,r.yg)("li",{parentName:"ul"},"Strategy-specific parameters (such as tensor parallel size, pipeline parallel size, etc.)")),(0,r.yg)("h3",{id:"5-arguments-classes"},"5. Arguments Classes"),(0,r.yg)("p",null,"ROLL uses multiple argument classes to organize configurations:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"ModelArguments"),": Model-related parameters"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"TrainingArguments"),": Training-related parameters"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"GeneratingArguments"),": Generation-related parameters"),(0,r.yg)("li",{parentName:"ul"},(0,r.yg)("inlineCode",{parentName:"li"},"DataArguments"),": Data-related parameters")),(0,r.yg)("h2",{id:"configuration-class-uml-diagram"},"Configuration Class UML Diagram"),(0,r.yg)("p",null,"To better understand ROLL's configuration system, the UML diagram of RLVRConfig is shown below:"),(0,r.yg)("ul",null,(0,r.yg)("li",{parentName:"ul"},"BaseConfig provides the most basic configuration keys, and specific application PipelineConfigs inherit from BaseConfig"),(0,r.yg)("li",{parentName:"ul"},"In PipelineConfig, multiple WorkerConfigs can be defined according to application needs. WorkerConfigs are independent and can be freely assigned independent resources and training/inference backends"),(0,r.yg)("li",{parentName:"ul"},"In WorkerConfig, ModelArguments, TrainingArguments, GeneratingArguments, DataArguments, and backend StrategyArguments held by the role are defined as needed"),(0,r.yg)("li",{parentName:"ul"},"WorkerConfig can be extended as needed to construct new application configurations")),(0,r.yg)("p",null,(0,r.yg)("img",{alt:"RLVRConfig Diagram",src:i(8313).A,width:"3034",height:"1742"})),(0,r.yg)("h2",{id:"mapping-between-yaml-configuration-and-pipelineconfig"},"Mapping between YAML Configuration and PipelineConfig"),(0,r.yg)("p",null,"In ROLL, there is a direct mapping relationship between YAML configuration files and Python configuration classes:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Top-level fields in the YAML file correspond to the attributes of ",(0,r.yg)("inlineCode",{parentName:"li"},"PipelineConfig"),"->",(0,r.yg)("inlineCode",{parentName:"li"},"BaseConfig")),(0,r.yg)("li",{parentName:"ol"},"Role configurations (such as ",(0,r.yg)("inlineCode",{parentName:"li"},"actor_train"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"actor_infer"),") correspond to ",(0,r.yg)("inlineCode",{parentName:"li"},"WorkerConfig")," instances, which correspond to the configuration of attribute classes in ",(0,r.yg)("inlineCode",{parentName:"li"},"PipelineConfig")),(0,r.yg)("li",{parentName:"ol"},"Sub-fields under each role (such as ",(0,r.yg)("inlineCode",{parentName:"li"},"model_args"),", ",(0,r.yg)("inlineCode",{parentName:"li"},"training_args"),") correspond to the corresponding parameter class instances")),(0,r.yg)("p",null,"For example, in the YAML file:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"actor_train:\n  model_args:\n    disable_gradient_checkpointing: false\n    dtype: bf16\n  training_args:\n    learning_rate: 1.0e-6\n    per_device_train_batch_size: 1\n")),(0,r.yg)("p",null,"Mapping to Python code:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-python"},'config.actor_train.model_args.disable_gradient_checkpointing = False\nconfig.actor_train.model_args.dtype = "bf16"\nconfig.actor_train.training_args.learning_rate = 1.0e-6\nconfig.actor_train.training_args.per_device_train_batch_size = 1\n')),(0,r.yg)("h2",{id:"configuration-validation-mechanism"},"Configuration Validation Mechanism"),(0,r.yg)("p",null,"ROLL's configuration system has strict validation mechanisms:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Configuration items in YAML must be explicitly defined in the corresponding Config class to be used"),(0,r.yg)("li",{parentName:"ol"},"Configuration item validation is implemented through data class type annotations and metadata"),(0,r.yg)("li",{parentName:"ol"},"Additional logical validation is performed in the ",(0,r.yg)("inlineCode",{parentName:"li"},"__post_init__")," method")),(0,r.yg)("p",null,"This design prevents configuration item confusion and ensures configuration consistency and correctness."),(0,r.yg)("h2",{id:"global-environment-variablesworker-specific-environment-variables-configuration-entry"},"Global Environment Variables/Worker-Specific Environment Variables Configuration Entry"),(0,r.yg)("p",null,"In the ROLL framework, environment variable settings are divided into two levels:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Global Environment Variables"),": Configured on ",(0,r.yg)("inlineCode",{parentName:"li"},"pipeline_config")," with ",(0,r.yg)("inlineCode",{parentName:"li"},"system_envs"),", taking effect for all roles in the entire pipeline."),(0,r.yg)("li",{parentName:"ol"},(0,r.yg)("strong",{parentName:"li"},"Worker-Specific Environment Variables"),": Configured in ",(0,r.yg)("inlineCode",{parentName:"li"},"system_envs")," within ",(0,r.yg)("inlineCode",{parentName:"li"},"worker_config"),", taking effect only when the Worker's Ray Actor is created.")),(0,r.yg)("h3",{id:"configuration-method"},"Configuration Method"),(0,r.yg)("h4",{id:"global-environment-variable-configuration"},"Global Environment Variable Configuration"),(0,r.yg)("p",null,"Set the ",(0,r.yg)("inlineCode",{parentName:"p"},"system_envs")," field at the top level of the YAML configuration file:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'exp_name: "example-exp"\n# Other basic configurations...\n\n# Global environment variable settings\nsystem_envs:\n  NVTE_TORCH_COMPILE: \'0\'\n  RAY_PROFILING: "1"\n\n# Role configurations\nactor_train:\n  # ...\n')),(0,r.yg)("h4",{id:"worker-specific-environment-variable-configuration"},"Worker-Specific Environment Variable Configuration"),(0,r.yg)("p",null,"Set the ",(0,r.yg)("inlineCode",{parentName:"p"},"system_envs")," field in specific role configurations:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},"actor_train:\n  model_args:\n    # ...\n  training_args:\n    # ...\n  # Environment variables effective only for actor_train role\n  system_envs:\n    NVTE_TORCH_COMPILE: '0'\n\nactor_infer:\n  model_args:\n    # ...\n  generating_args:\n    # ...\n  # Environment variables effective only for actor_infer role\n  system_envs:\n    NVTE_TORCH_COMPILE: '0'\n")),(0,r.yg)("h3",{id:"priority-rules"},"Priority Rules"),(0,r.yg)("p",null,"When global environment variables and role-specific environment variables conflict, role-specific environment variables have higher priority and will override global settings."),(0,r.yg)("p",null,"Through this hierarchical environment variable configuration method, the ROLL framework provides independent and flexible environment variable configuration capabilities to meet different Worker requirements."),(0,r.yg)("h2",{id:"configuration-example-analysis"},"Configuration Example Analysis"),(0,r.yg)("p",null,"The following is a detailed analysis of the ",(0,r.yg)("inlineCode",{parentName:"p"},"example_grpo.yaml")," configuration file:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-yaml"},'# Basic configuration\nexp_name: "qwen2.5-7B-rlvr-config"  # Experiment name\nseed: 42  # Random seed\nlogging_dir: ./output/logs  # Log directory\noutput_dir: ./output  # Output directory\n\n# Checkpoint saving configuration\ncheckpoint_config:\n  type: file_system\n  output_dir: /data/cpfs_0/rl_examples/models/${exp_name}\n\n# Tracker configuration\ntrack_with: tensorboard  # Using tensorboard for tracking\ntracker_kwargs:\n  log_dir: /data/oss_bucket_0/rl_examples/llm/tensorboard/roll_exp/rlvr  # Log directory\n\n# GRPO algorithm-related configuration\nrollout_batch_size: 64  # Rollout batch size\nadv_estimator: "grpo"  # Advantage estimator using GRPO\nnum_return_sequences_in_group: 8  # Number of sequences returned per group\n\n# Sequence length configuration\nprompt_length: 2048  # Prompt length\nresponse_length: 4096  # Response length\n\n# Training parameters\nppo_epochs: 1  # PPO optimization rounds\nuse_kl_loss: true  # Use KL divergence loss\nkl_loss_coef: 0.001  # KL loss coefficient\nloss_agg_mode: "seq-mean-token-sum"  # Loss aggregation mode\n\n# Advantage calculation related\nwhiten_advantages: true  # Whiten advantage values\nadvantage_clip: 2.0  # Advantage value clipping\ndual_clip_loss: true  # Use dual clipping loss\n\n# Reward processing\nreward_clip: 10  # Reward value clipping\n\n# Model configuration\npretrain: Qwen/Qwen2.5-7B  # Pretrained model path\nreward_pretrain: Qwen/Qwen2.5-7B  # Reward model path\n\n# Role configurations\nactor_train:  # Training role\n  model_args:\n    disable_gradient_checkpointing: false  # Enable gradient checkpointing\n    dtype: bf16  # Data type\n  training_args:\n    learning_rate: 1.0e-6  # Learning rate\n    per_device_train_batch_size: 1  # Training batch size per device\n    gradient_accumulation_steps: 32  # Gradient accumulation steps\n  strategy_args:\n    strategy_name: megatron_train  # Using Megatron training strategy\n    strategy_config:\n      tensor_model_parallel_size: 1  # Tensor parallel size\n      pipeline_model_parallel_size: 1  # Pipeline parallel size\n  device_mapping: list(range(0,16))  # Device mapping\n\nactor_infer:  # Inference role\n  model_args:\n    disable_gradient_checkpointing: true  # Disable gradient checkpointing\n    dtype: bf16  # Data type\n  generating_args:\n    max_new_tokens: ${response_length}  # Maximum new tokens\n    temperature: 0.99  # Temperature parameter\n  strategy_args:\n    strategy_name: vllm  # Using vLLM inference strategy\n    strategy_config:\n      gpu_memory_utilization: 0.8  # GPU memory utilization\n  device_mapping: list(range(0,12))  # Device mapping\n\n# Reward model configuration\nrewards:\n  math_rule:  # Math rule reward\n    worker_cls: roll.pipeline.rlvr.rewards.math_rule_reward_worker.MathRuleRewardWorker  # Worker class\n    model_args:\n      model_name_or_path: ${reward_pretrain}  # Model path\n    tag_included: [deepmath_103k, aime]  # Included tags\n    world_size: 8  # Number of worker nodes\n')),(0,r.yg)("p",null,"Through the above analysis, users can better understand the structure and usage methods of the ROLL configuration system."))}d.isMDXComponent=!0},8313:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/roll_config_diagram-70e35358b4cbce585fd341b8530146ad.png"}}]);