"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[3704],{8453:(e,i,t)=>{t.d(i,{R:()=>n,x:()=>l});var r=t(6540);const s={},a=r.createContext(s);function n(e){const i=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:n(e.components),r.createElement(a.Provider,{value:i},e.children)}},9213:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>h,contentTitle:()=>d,default:()=>b,frontMatter:()=>o,metadata:()=>r,toc:()=>u});const r=JSON.parse('{"id":"UserGuide/start","title":"start","description":"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80","source":"@site/docs/UserGuide/start.mdx","sourceDirName":"UserGuide","slug":"/UserGuide/start","permalink":"/ROLL/docs/UserGuide/start","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/UserGuide/start.mdx","tags":[],"version":"current","lastUpdatedAt":1763115283000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"RLVR Pipeline for VLM","permalink":"/ROLL/docs/UserGuide/pipeline/vl_rlvr_pipeline_start"},"next":{"title":"Trackers and Metrics","permalink":"/ROLL/docs/UserGuide/trackers_and_metrics"}}');var s=t(4848),a=t(8453),n=(t(6540),t(5068));function l({item:e,subLabel:i}){return"link"===e.type?(0,s.jsx)("div",{children:(0,s.jsx)("a",{href:e.href,children:e.label})}):"category"===e.type?(0,s.jsxs)("div",{children:[e.label!==i&&(0,s.jsx)("h4",{style:{marginTop:8},children:e.label}),(0,s.jsx)("div",{children:e.items.sort(e=>"link"===e.type?-1:1).map(e=>(0,s.jsx)(l,{item:e,subLabel:i}))})]}):(0,s.jsx)("div",{})}const c=function({folder_label:e}){const i=(0,n.$S)();return i?.label!==e?null:(0,s.jsx)("div",{children:i.items.sort(e=>"link"===e.type?-1:1).filter(e=>"link"!==e.type||"start"!==e.label).map(i=>(0,s.jsx)(l,{item:i,subLabel:e}))})},o={},d="ROLL: Reinforcement Learning Optimization for Large-Scale Learning",h={},u=[{value:"\ud83d\ude80 Get Started",id:"-get-started",level:2},{value:"Quick Start",id:"quick-start",level:3},{value:"UserGuide",id:"userguide",level:3}];function g(e){const i={a:"a",br:"br",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{align:"center",children:[(0,s.jsx)("img",{src:"https://img.alicdn.com/imgextra/i2/O1CN01R6uYoU1VrrET7d1G6_!!6000000002707-0-tps-1292-407.jpg",width:"40%",alt:"ROLL Logo"}),(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"roll-reinforcement-learning-optimization-for-large-scale-learning",children:"ROLL: Reinforcement Learning Optimization for Large-Scale Learning"})}),(0,s.jsx)("h4",{children:"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80"}),(0,s.jsxs)("p",{children:[(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/blob/main/LICENSE",children:(0,s.jsx)("img",{src:"https://img.shields.io/badge/license-Apache%202.0-blue.svg",alt:"License"})}),(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/issues",children:(0,s.jsx)("img",{src:"https://img.shields.io/github/issues/alibaba/ROLL",alt:"GitHub issues"})}),(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/stargazers",children:(0,s.jsx)("img",{src:"https://img.shields.io/github/stars/alibaba/ROLL?style=social",alt:"Repo stars"})}),(0,s.jsx)("a",{href:"https://arxiv.org/abs/2506.06122",children:(0,s.jsx)("img",{src:"https://img.shields.io/static/v1?label=arXiv&message=Paper&color=red"})}),(0,s.jsx)("a",{href:"https://img.alicdn.com/imgextra/i4/O1CN01MICK0T28fHMzy5P84_!!6000000007959-2-tps-756-850.png",target:"_blank",children:(0,s.jsx)("img",{src:"https://img.shields.io/badge/WeChat-green?logo=wechat",alt:"WeChat QR"})})]})]}),"\n",(0,s.jsx)(i.p,{children:"ROLL is an efficient and user-friendly RL library designed for Large Language Models (LLMs) utilizing Large Scale GPU resources. It significantly enhances LLM performance in key areas such as human preference alignment, complex reasoning, and multi-turn agentic interaction scenarios."}),"\n",(0,s.jsx)(i.p,{children:"Leveraging a multi-role distributed architecture with Ray for flexible resource allocation and heterogeneous task scheduling, ROLL integrates cutting-edge technologies like Megatron-Core, SGLang and vLLM to accelerate model training and inference."}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"[08/11/2025]"})," \ud83c\udf89 Our Paper released, see ",(0,s.jsx)(i.a,{href:"https://arxiv.org/abs/2508.08221",children:"Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}),".\n",(0,s.jsx)(i.strong,{children:"[06/09/2025]"})," \ud83c\udf89 ROLL tech report is now available! Access the report ",(0,s.jsx)(i.a,{href:"https://arxiv.org/abs/2506.06122",children:"here"}),"."]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"-get-started",children:"\ud83d\ude80 Get Started"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/",children:"Documents"})}),"\n",(0,s.jsx)(i.h3,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/installation",children:"Installation"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/config_system",children:"Config System Explanation"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/debugging_guide_en",children:"Debugging Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/UserGuide/trackers_and_metrics",children:"Trackers and Metrics"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/UserGuide/checkpoint_and_resume",children:"Checkpoint Saving and Resuming Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/UserGuide/megatron_convert_2_hf",children:"Converting MCoreAdapter Models to Hugging Face Format"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/single_node_quick_start",children:"Quick Start: Single-Node Deployment Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/multi_node_quick_start",children:"Quick Start: Multi-Node Deployment Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/qa_issues",children:"Frequently Asked Questions"})]}),"\n",(0,s.jsx)(i.h3,{id:"userguide",children:"UserGuide"}),"\n",(0,s.jsx)(c,{folder_label:"UserGuide"}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)("div",{align:"center",children:(0,s.jsx)(i.p,{children:"We welcome contributions from the community! \ud83e\udd1d"})})]})}function b(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(g,{...e})}):g(e)}}}]);