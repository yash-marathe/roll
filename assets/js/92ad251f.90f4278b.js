"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[3283],{28453:(e,i,r)=>{r.d(i,{R:()=>a,x:()=>o});var t=r(96540);const s={},n=t.createContext(s);function a(e){const i=t.useContext(n);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(n.Provider,{value:i},e.children)}},36690:(e,i,r)=>{r.r(i),r.d(i,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"Overview","title":"Overview","description":"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80","source":"@site/docs/Overview.mdx","sourceDirName":".","slug":"/Overview","permalink":"/ROLL/docs/Overview","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/Overview.mdx","tags":[],"version":"current","lastUpdatedAt":1764581625000,"frontMatter":{"title":"Overview"},"sidebar":"tutorialSidebar","next":{"title":"Image Provided","permalink":"/ROLL/docs/Getting Started/Installation/image_address"}}');var s=r(74848),n=r(28453);const a={title:"Overview"},o="ROLL: Reinforcement Learning Optimization for Large-Scale Learning",l={},d=[{value:"\ud83d\ude80 Get Started",id:"-get-started",level:2},{value:"User Guides",id:"user-guides",level:3},{value:"Configuration",id:"configuration",level:4},{value:"Pipeline",id:"pipeline",level:4},{value:"Algorithms",id:"algorithms",level:4},{value:"Agentic",id:"agentic",level:4},{value:"Advanced Features",id:"advanced-features",level:4},{value:"Tracker &amp; Metrics",id:"tracker--metrics",level:4},{value:"Hardware Support",id:"hardware-support",level:4},{value:"Development",id:"development",level:3},{value:"Architecture",id:"architecture",level:5},{value:"Developer Guide",id:"developer-guide",level:4}];function h(e){const i={a:"a",br:"br",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",hr:"hr",p:"p",strong:"strong",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{align:"center",children:[(0,s.jsx)("img",{src:"https://img.alicdn.com/imgextra/i2/O1CN01R6uYoU1VrrET7d1G6_!!6000000002707-0-tps-1292-407.jpg",width:"40%",alt:"ROLL Logo"}),(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"roll-reinforcement-learning-optimization-for-large-scale-learning",children:"ROLL: Reinforcement Learning Optimization for Large-Scale Learning"})}),(0,s.jsx)("h4",{children:"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80"}),(0,s.jsxs)("p",{children:[(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/blob/main/LICENSE",children:(0,s.jsx)("img",{src:"https://img.shields.io/badge/license-Apache%202.0-blue.svg",alt:"License"})}),(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/issues",children:(0,s.jsx)("img",{src:"https://img.shields.io/github/issues/alibaba/ROLL",alt:"GitHub issues"})}),(0,s.jsx)("a",{href:"https://github.com/alibaba/ROLL/stargazers",children:(0,s.jsx)("img",{src:"https://img.shields.io/github/stars/alibaba/ROLL?style=social",alt:"Repo stars"})}),(0,s.jsx)("a",{href:"https://arxiv.org/abs/2506.06122",children:(0,s.jsx)("img",{src:"https://img.shields.io/static/v1?label=arXiv&message=Paper&color=red"})}),(0,s.jsx)("a",{href:"https://img.alicdn.com/imgextra/i4/O1CN01MICK0T28fHMzy5P84_!!6000000007959-2-tps-756-850.png",target:"_blank",children:(0,s.jsx)("img",{src:"https://img.shields.io/badge/WeChat-green?logo=wechat",alt:"WeChat QR"})})]})]}),"\n",(0,s.jsx)(i.p,{children:"ROLL is an efficient and user-friendly RL library designed for Large Language Models (LLMs) utilizing Large Scale GPU resources. It significantly enhances LLM performance in key areas such as human preference alignment, complex reasoning, and multi-turn agentic interaction scenarios."}),"\n",(0,s.jsx)(i.p,{children:"Leveraging a multi-role distributed architecture with Ray for flexible resource allocation and heterogeneous task scheduling, ROLL integrates cutting-edge technologies like Megatron-Core, SGLang and vLLM to accelerate model training and inference."}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"[08/11/2025]"})," \ud83c\udf89 Our Paper released, see ",(0,s.jsx)(i.a,{href:"https://arxiv.org/abs/2508.08221",children:"Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"}),".\n",(0,s.jsx)(i.strong,{children:"[06/09/2025]"})," \ud83c\udf89 ROLL tech report is now available! Access the report ",(0,s.jsx)(i.a,{href:"https://arxiv.org/abs/2506.06122",children:"here"}),"."]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)(i.h2,{id:"-get-started",children:"\ud83d\ude80 Get Started"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/",children:"Documents"})}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Getting%20Started/Installation/",children:"Installation"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Getting%20Started/Quick%20Start/single_node_quick_start",children:"Quick Start: Single-Node Deployment Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Getting%20Started/Quick%20Start/multi_nodes_quick_start",children:"Quick Start: Multi-Node Deployment Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Getting%20Started/Debugging%20Guide/debug_guide",children:"Debugging Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Getting%20Started/FAQ/qa_issues",children:"Frequently Asked Questions"})]}),"\n",(0,s.jsx)(i.h3,{id:"user-guides",children:"User Guides"}),"\n",(0,s.jsx)(i.h4,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/config_system",children:"Config System Explanation"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/config_guide",children:"Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/device_mapping",children:"Resource Configuration"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/offpolicy_setting",children:"Off-Policy Algorithms Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/vllm",children:"vLLM Inference Backend Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/sglang",children:"SGLang Inference Backend Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/megatron",children:"Megatron Inference and Training Backend Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/lora",children:"LoRA Fine-tuning Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/fp8_rollout",children:"FP8 Quantization Configuration Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Configuration/deepspeed",children:"DeepSpeed Training Backend Configuration Guide"})]}),"\n",(0,s.jsx)(i.h4,{id:"pipeline",children:"Pipeline"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/vl_rlvr_pipeline_start",children:"RLVR Pipeline for VLM"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/rlvr_pipeline_start",children:"RLVR Pipeline"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/dpo_pipeline_start",children:"DPO Pipeline"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/distill_pipeline_start",children:"Distill Pipeline"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/agentic_pipeline_start",children:"Agentic Pipeline"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Pipeline/agent_pipeline_start",children:"Comprehensive Guide: Using the Agentic Part of ROLL"})]}),"\n",(0,s.jsx)(i.h4,{id:"algorithms",children:"Algorithms"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/TOPR",children:"TOPR (Tapered Off-Policy REINFORCE)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/Reward_FL",children:"Reward Feedback Learning (Reward FL)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/Reinforce_Plus_Plus",children:"Reinforce++"}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/RAFT_Plus_Plus",children:"RAFT++ (Reward rAnked Fine-Tuning)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/PPO",children:"Proximal Policy Optimization (PPO)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/LitePPO",children:"Lite PPO"}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/GSPO",children:"Group Sequence Policy Optimization (GSPO)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Algorithms/GRPO",children:"Group Relative Policy Optimization (GRPO)"})]}),"\n",(0,s.jsx)(i.h4,{id:"agentic",children:"Agentic"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Agentic/agentic_engineer_practice",children:"Agentic Engineering Practice Documentation"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Agentic/agentic_StarPO",children:"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Agentic/agentic_GiGPO",children:"StepWiseLearning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Agentic/Tool_Use",children:"Tool Use Guide"})]}),"\n",(0,s.jsx)(i.h4,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Advanced%20Features/async_parallel_rollout",children:"Agentic Asynchronous Parallel Rollout"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Advanced%20Features/async_training",children:"ROLL Asynchronous Training User Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Advanced%20Features/checkpoint_and_resume",children:"Checkpoint Saving and Resuming Guide"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Advanced%20Features/megatron_convert_2_hf",children:"Converting MCoreAdapter Models to Hugging Face Format"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Advanced%20Features/offload_reload_control",children:"GPU Time-Division Multiplexing Control Guide"})]}),"\n",(0,s.jsx)(i.h4,{id:"tracker--metrics",children:"Tracker & Metrics"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Tracker%20&%20Metrics/trackers_and_metrics",children:"Trackers and Metrics"})}),"\n",(0,s.jsx)(i.h4,{id:"hardware-support",children:"Hardware Support"}),"\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/User%20Guides/Hardware%20Support/ascend_usage",children:"ROLL x Ascend"})}),"\n",(0,s.jsx)(i.h3,{id:"development",children:"Development"}),"\n",(0,s.jsx)(i.h5,{id:"architecture",children:"Architecture"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Development/Architecture/AgenticPipeline",children:"AgenticPipeline"}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Development/Architecture/RLVRPipeline",children:"RLVRPipeline"})]}),"\n",(0,s.jsx)(i.h4,{id:"developer-guide",children:"Developer Guide"}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Development/Developer%20Guide/support_new_models",children:"How to Add Support for a New Model"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Development/Developer%20Guide/customer_env",children:"Customer Env"}),(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.a,{href:"https://alibaba.github.io/ROLL/docs/Development/Developer%20Guide/prompt_intro",children:"Prompt Generation Guide"})]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsx)("div",{align:"center",children:(0,s.jsx)(i.p,{children:"We welcome contributions from the community! \ud83e\udd1d"})})]})}function c(e={}){const{wrapper:i}={...(0,n.R)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);