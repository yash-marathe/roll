"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[8898],{357:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/log_pipeline_in_training-24ad92a3612a1c18937a60ddde03f385.png"},4717:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"QuickStart/single_node_quick_start","title":"Quick Start: Single-Node Deployment Guide","description":"Environment Preparation","source":"@site/docs/QuickStart/single_node_quick_start.md","sourceDirName":"QuickStart","slug":"/QuickStart/single_node_quick_start","permalink":"/ROLL/docs/QuickStart/single_node_quick_start","draft":false,"unlisted":false,"editUrl":"https://github.com/alibaba/ROLL/tree/main/docs_roll/docs/QuickStart/single_node_quick_start.md","tags":[],"version":"current","lastUpdatedAt":1763034215000,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Frequently Asked Questions (Q&A)","permalink":"/ROLL/docs/QuickStart/qa_issues"},"next":{"title":"Tool Use Guide","permalink":"/ROLL/docs/UserGuide/agentic/Tool_Use"}}');var r=t(4848),a=t(8453);const o={},s="Quick Start: Single-Node Deployment Guide",l={},c=[{value:"Environment Preparation",id:"environment-preparation",level:2},{value:"Environment Configuration",id:"environment-configuration",level:2},{value:"Pipeline Execution",id:"pipeline-execution",level:2},{value:"Reference: Single V100 GPU Memory Configuration Key Points",id:"reference-single-v100-gpu-memory-configuration-key-points",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"quick-start-single-node-deployment-guide",children:"Quick Start: Single-Node Deployment Guide"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-preparation",children:"Environment Preparation"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Purchase a machine equipped with GPU and install GPU drivers synchronously"}),"\n",(0,r.jsx)(n.li,{children:"Connect to the GPU instance remotely and enter the machine terminal"}),"\n",(0,r.jsx)(n.li,{children:"Run the following command to install the Docker environment and NVIDIA container toolkit"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"curl -fsSL https://github.com/alibaba/ROLL/blob/main/scripts/install_docker_nvidia_container_toolkit.sh | sudo bash\n"})}),"\n",(0,r.jsx)(n.h2,{id:"environment-configuration",children:"Environment Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Choose your desired Docker image from the ",(0,r.jsx)(n.a,{href:"https://alibaba.github.io/ROLL/docs/QuickStart/image_address",children:"image addresses"}),". The following example uses ",(0,r.jsx)(n.em,{children:"torch2.6.0 + vLLM0.8.4"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"# 1. Start a Docker container with GPU support, expose container ports, and keep the container running\nsudo docker run -dit \\\n  --gpus all \\\n  -p 9001:22 \\\n  --ipc=host \\\n  --shm-size=10gb \\\n  roll-registry.cn-hangzhou.cr.aliyuncs.com/roll/pytorch:nvcr-24.05-py3-torch260-vllm084 \\\n  /bin/bash\n\n# 2. Enter the Docker container\n#    You can use the `sudo docker ps` command to find the running container ID or name.\nsudo docker exec -it <container_id> /bin/bash\n\n# 3. Verify that GPUs are visible\nnvidia-smi\n\n# 4. Clone the project code\ngit clone https://github.com/alibaba/ROLL.git\n\n# 5. Install project dependencies (choose the requirements file corresponding to your image)\ncd ROLL\npip install -r requirements_torch260_vllm.txt -i https://mirrors.aliyun.com/pypi/simple/\n"})}),"\n",(0,r.jsx)(n.h2,{id:"pipeline-execution",children:"Pipeline Execution"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-shell",children:"bash examples/agentic_demo/run_agentic_pipeline_frozen_lake_single_node_demo.sh\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Example log screenshots during pipeline execution:\n",(0,r.jsx)(n.img,{alt:"log_pipeline_start",src:t(9243).A+"",width:"2868",height:"650"})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"log_pipeline_in_training",src:t(357).A+"",width:"2876",height:"904"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"log_pipeline_complete",src:t(4986).A+"",width:"1904",height:"206"})}),"\n",(0,r.jsx)(n.h2,{id:"reference-single-v100-gpu-memory-configuration-key-points",children:"Reference: Single V100 GPU Memory Configuration Key Points"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# Reduce the expected number of GPUs from 8 to the 1 V100 you actually have\nnum_gpus_per_node: 1 \n# Training processes now only map to GPU 0\nactor_train.device_mapping: list(range(0,1))\n# Inference processes now only map to GPU 0\nactor_infer.device_mapping: list(range(0,1))\n# Reference model processes now only map to GPU 0\nreference.device_mapping: list(range(0,1))\n\n# Significantly reduce the batch size during Rollout/Validation stages to prevent out-of-memory errors when a single GPU processes large batches\nrollout_batch_size: 16\nval_batch_size: 16\n\n# V100 has better native support for FP16 than BF16 (unlike A100/H100). Switching to FP16 can improve compatibility and stability while saving GPU memory.\nactor_train.model_args.dtype: fp16\nactor_infer.model_args.dtype: fp16\nreference.model_args.dtype: fp16\n\n# Switch the large model training framework from DeepSpeed to Megatron-LM, where parameters can be sent in batches for faster execution\nstrategy_name: megatron_train\nstrategy_config:\n  tensor_model_parallel_size: 1\n  pipeline_model_parallel_size: 1\n  expert_model_parallel_size: 1\n  use_distributed_optimizer: true\n  recompute_granularity: full\n\n# In Megatron training, the global training batch size is per_device_train_batch_size * gradient_accumulation_steps * world_size\nactor_train.training_args.per_device_train_batch_size: 1\nactor_train.training_args.gradient_accumulation_steps: 16  \n\n# Reduce the maximum number of actions per trajectory to make each Rollout trajectory shorter, reducing the length of LLM-generated content\nmax_actions_per_traj: 10    \n\n# Reduce the number of parallel training environment groups and validation environment groups to accommodate single GPU resources\ntrain_env_manager.env_groups: 1\ntrain_env_manager.n_groups: 1\nval_env_manager.env_groups: 2\nval_env_manager.n_groups: [1, 1]\nval_env_manager.tags: [SimpleSokoban, FrozenLake]\n\n# Reduce the total number of training steps to run a complete training process faster for quick debugging\nmax_steps: 100\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},4986:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/log_pipeline_complete-3e33d8f8e3007b5184d9e0ba1badb7df.png"},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>s});var i=t(6540);const r={},a=i.createContext(r);function o(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),i.createElement(a.Provider,{value:n},e.children)}},9243:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/log_pipeline_start-1b28c489a3d9d8cc9fef5dc2aab7ead7.png"}}]);