"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[2634],{8959:(e,s,i)=>{i.r(s),i.d(s,{default:()=>ee});var n=i(6540),a=i(4586),r=i(6840);var c=i(8895),l=i(9522),t=i(1260),d=i(6823),o=i(9754),h=i(9815),m=i(8366),x=i(1676),j=i(1449),g=i(9715),v=i(8042),u=i(53),A=i(6025),p=i(5293),N=i(1312);const b="container_gPnP",f="count_K2wP",y="content__wyW";var L=i(4848);const _=({count:e,content:s})=>(0,L.jsxs)("div",{className:b,children:[(0,L.jsx)("div",{className:f,children:e}),(0,L.jsx)("div",{className:y,children:s})]}),w="container_msET",k="img_lP7H",R="whiteImg_G2tW",O="subTitle_D4QN",C="title_TIxS",G="names_lTG_",P="desc_HXOV",I="buttons_qeJV",S="btn_ULHW",T="github_iz2O",B="mainImg_cTpB",z="overview_knAL",M="left_N5GB",H="right_NqT5",W="choose_VbF4",E="wrap_Hg5K",D="label_Go4Q",U="content_i9tt",q="collapse_hBB3",F="isActive_qkd8",K="default_zzyW",J="core_f57d",Q="research_T8OZ",V="items_mSoM",$="cards_CQBh",X="card_WYrq",Y="card2_vIdg",Z=()=>{const[e,s]=(0,n.useState)(!1),{colorMode:i}=(0,p.G)(),{i18n:r}=(0,a.A)(),{currentLocale:b}=r,f="en"!==b,y=f?"/ROLL/zh-Hans/":"/ROLL/";return(0,L.jsx)(c.Ay,{theme:{algorithm:"dark"===i?l.A.darkAlgorithm:l.A.defaultAlgorithm},children:(0,L.jsxs)("div",{className:(0,u.A)("container",w),id:"home",children:[(0,L.jsxs)("div",{children:[(0,L.jsx)("div",{className:O,children:(0,L.jsx)(N.A,{children:"Open Source Framework \xb7 Powerful & Easy"})}),(0,L.jsxs)("div",{className:C,children:[(0,L.jsx)("div",{className:G,children:"Reinforcement\xa0Learning"}),"\xa0",(0,L.jsx)("div",{className:G,children:"Optimization"}),"\xa0 for\xa0",(0,L.jsx)("div",{className:G,children:"Large-scale"}),"\xa0",(0,L.jsx)("div",{className:G,children:"Learning"})]}),f&&(0,L.jsx)("div",{className:C,children:"\u9762\u5411\u5927\u89c4\u6a21\u5b66\u4e60\u7684\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6846\u67b6"}),(0,L.jsx)("div",{className:P,children:(0,L.jsx)(N.A,{children:"An open-source reinforcement learning library by Alibaba, optimized for large-scale language models. Supporting distributed training, multi-task learning, and agent interaction for simpler and more efficient AI model training."})}),(0,L.jsxs)("div",{className:I,children:[(0,L.jsx)(t.Ay,{href:`${y}docs/UserGuide/start/`,target:"_blank",className:S,children:(0,L.jsx)(N.A,{children:"Get Started >"})}),(0,L.jsx)(t.Ay,{className:T,target:"_blank",href:"https://github.com/alibaba/ROLL",variant:"outlined",icon:(0,L.jsx)(g.A,{}),children:"Github >"}),(0,L.jsx)(t.Ay,{className:T,target:"_blank",href:"https://deepwiki.com/alibaba/ROLL",variant:"outlined",icon:(0,L.jsx)(d.A,{width:14,src:(0,A.Ay)("/img/deepwiki.svg"),preview:!1}),children:"DeepWiki >"})]}),(0,L.jsx)("div",{className:B,children:(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/home_main.png"),preview:!1})}),(0,L.jsxs)("div",{className:z,children:[(0,L.jsxs)("div",{className:M,children:[(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/icon1.svg"),preview:!1}),(0,L.jsx)("div",{children:"ROLL"}),(0,L.jsx)("div",{children:(0,L.jsx)(N.A,{children:"Framework Overview"})})]}),(0,L.jsx)("div",{className:H,children:(0,L.jsx)(N.A,{children:"ROLL (Reinforcement Learning Optimization for Large-scale Learning) is an open-source reinforcement learning framework by Alibaba, designed for large-scale language models. Built on Ray distributed architecture, supporting mainstream algorithms like PPO and GRPO, providing complete solutions from research to production."})})]}),(0,L.jsx)(o.A,{style:{borderColor:"var(--home-divider-color)"}}),(0,L.jsx)("div",{children:(0,L.jsxs)(h.A,{gutter:16,children:[(0,L.jsx)(m.A,{span:8,children:(0,L.jsx)(_,{count:"1.9k",content:(0,N.T)({message:"Github Stars"})})}),(0,L.jsx)(m.A,{span:8,children:(0,L.jsx)(_,{count:"30+",content:(0,N.T)({message:"Contributors"})})}),(0,L.jsx)(m.A,{span:8,children:(0,L.jsx)(_,{count:"200+",content:(0,N.T)({message:"Commits"})})})]})}),(0,L.jsxs)("div",{className:W,children:[(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/icon2.svg"),preview:!1}),(0,L.jsxs)("div",{className:E,children:[(0,L.jsxs)("div",{className:M,children:[(0,L.jsx)("div",{children:(0,L.jsx)(N.A,{children:"Why"})}),(0,L.jsx)("div",{children:(0,L.jsx)(N.A,{children:"Choose ROLL"})}),(0,L.jsx)("div",{className:q,children:(0,L.jsx)(x.A,{ghost:!0,defaultActiveKey:["1"],expandIcon:({isActive:e})=>(0,L.jsx)("div",{className:e?F:K}),items:[{key:"1",label:(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Distributed Architecture"})}),children:(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Ray-based distributed architecture supporting mainstream engines like vLLM, SGLang, Megatron-Core, seamlessly scaling from single machine to large GPU clusters"})})},{key:"2",label:(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Multi-task Learning"})}),children:(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Support for multi-task joint training including math reasoning, code generation, and dialogue, with dynamic sampling rate and data weight adjustment"})})},{key:"3",label:(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Extremely Easy to Use"})}),children:(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Gym-style clean API design with modular architecture for flexible extension, one-click switching between different backend engines and algorithm configurations"})})}]})})]}),(0,L.jsx)("div",{className:H,children:(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/choose.png"),preview:!1})})]})]}),(0,L.jsxs)("div",{className:J,id:"core",children:[(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/icon3.svg"),preview:!1}),(0,L.jsxs)("div",{children:[(0,L.jsx)("div",{className:C,children:(0,L.jsx)(N.A,{children:"Core Advantages"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"ROLL framework provides comprehensive reinforcement learning support, from model training to agent deployment, every aspect is carefully optimized to make AI training more efficient"})})]}),(0,L.jsxs)("div",{className:E,children:[(0,L.jsx)(o.A,{style:{borderColor:"var(--home-divider-color)",marginBottom:0}}),(0,L.jsxs)(h.A,{gutter:[0,0],align:"bottom",children:[(0,L.jsx)(m.A,{span:12,children:(0,L.jsxs)("div",{className:V,children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Born for Scale"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Built on a Ray-based distributed architecture, it supports large-scale cluster training at the thousand-GPU level. Its innovative Rollout scheduler and AutoDeviceMapping module dramatically improve GPU resource utilization ."})})]})}),(0,L.jsx)(m.A,{span:12,children:(0,L.jsxs)("div",{className:V,style:{paddingLeft:30,borderRight:"none"},children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Extreme Training Efficiency"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Integrates cutting-edge technologies like Megatron-Core, SGLang, and vLLM to significantly accelerate the model training and inference sampling processes ."})})]})})]}),(0,L.jsxs)(h.A,{gutter:[0,0],align:"bottom",children:[(0,L.jsx)(m.A,{span:12,children:(0,L.jsxs)("div",{className:V,style:{borderBottom:"none"},children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Rich Algorithms & Scenarios"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Comes with built-in mainstream RL algorithms like PPO and GRPO, and supports multi-task RL and agent interaction scenarios. Its effectiveness has been validated in numerous real-world business applications ."})})]})}),(0,L.jsx)(m.A,{span:12,children:(0,L.jsxs)("div",{className:V,style:{paddingLeft:30,borderRight:"none",borderBottom:"none"},children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Open Source and Accessible"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"ROLL is open-sourced on GitHub (https://github.com/alibaba/ROLL) under the Apache License 2.0, backed by an active community and comprehensive documentation ."})})]})})]})]})]}),(0,L.jsxs)("div",{className:Q,id:"research",children:[(0,L.jsx)(d.A,{className:k,src:(0,A.Ay)("/img/icon4.svg"),preview:!1}),(0,L.jsxs)("div",{children:[(0,L.jsx)("div",{className:C,children:(0,L.jsx)(N.A,{children:"Open Source Community"})}),(0,L.jsx)("div",{className:U,children:(0,L.jsx)(N.A,{children:"Join our vibrant open source community, explore cutting-edge reinforcement learning technologies with global AI researchers, and jointly promote the future of LLM and RL"})})]}),(0,L.jsxs)("div",{className:$,children:[(0,L.jsxs)("div",{className:X,children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"How to Contribute"})}),(0,L.jsxs)("div",{children:[(0,L.jsx)("p",{children:(0,L.jsx)(N.A,{children:"Contribute algorithm implementations and performance optimizations"})}),(0,L.jsx)("p",{children:(0,L.jsx)(N.A,{children:"Share experimental results and best practices"})}),(0,L.jsx)("p",{children:(0,L.jsx)(N.A,{children:"Improve tutorials and learning resources"})})]})]}),(0,L.jsxs)("div",{className:Y,style:{width:300},children:[(0,L.jsx)("div",{className:D,children:(0,L.jsx)(N.A,{children:"Join Discussion"})}),(0,L.jsxs)("div",{className:I,children:[(0,L.jsx)(t.Ay,{className:S,onClick:()=>s(!0),icon:(0,L.jsx)(v.A,{}),children:(0,L.jsx)(N.A,{children:"WeChat"})}),(0,L.jsx)(t.Ay,{className:T,href:"https://github.com/alibaba/ROLL",variant:"outlined",icon:(0,L.jsx)(g.A,{}),children:(0,L.jsx)(N.A,{children:"Follow GitHub Repository"})})]})]})]})]})]}),(0,L.jsx)(j.A,{open:e,onCancel:()=>s(!1),footer:null,getContainer:()=>document.getElementById("home")||document.body,children:(0,L.jsx)(d.A,{className:R,src:"https://img.alicdn.com/imgextra/i4/O1CN01MICK0T28fHMzy5P84_!!6000000007959-2-tps-756-850.png",preview:!1})})]})})};function ee(){const{siteConfig:e}=(0,a.A)();return(0,L.jsx)(r.A,{title:`Hello from ${e.title}`,description:"Description will go into a meta tag in <head />",children:(0,L.jsx)("main",{children:(0,L.jsx)(Z,{})})})}}}]);