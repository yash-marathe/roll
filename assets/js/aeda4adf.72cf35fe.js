"use strict";(globalThis.webpackChunkdocs_roll=globalThis.webpackChunkdocs_roll||[]).push([[3851],{76331:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/ROLL/docs/Overview","label":"Overview","docId":"Overview","unlisted":false},{"type":"category","label":"Getting Started","collapsed":false,"items":[{"type":"category","label":"Installation","items":[{"type":"link","href":"/ROLL/docs/Getting Started/Installation/image_address","label":"Image Provided","docId":"Getting Started/Installation/image_address","unlisted":false},{"type":"link","href":"/ROLL/docs/Getting Started/Installation/","label":"Installation","docId":"Getting Started/Installation/installation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Quick Start","items":[{"type":"link","href":"/ROLL/docs/Getting Started/Quick Start/multi_nodes_quick_start","label":"Quick Start: Multi-Node Deployment Guide","docId":"Getting Started/Quick Start/multi_nodes_quick_start","unlisted":false},{"type":"link","href":"/ROLL/docs/Getting Started/Quick Start/single_node_quick_start","label":"Quick Start: Single-Node Deployment Guide","docId":"Getting Started/Quick Start/single_node_quick_start","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Debugging Guide","items":[{"type":"link","href":"/ROLL/docs/Getting Started/Debugging Guide/debug_guide","label":"ROLL Debugging Guide","docId":"Getting Started/Debugging Guide/debug_guide","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"FAQ","items":[{"type":"link","href":"/ROLL/docs/Getting Started/FAQ/qa_issues","label":"Frequently Asked Questions (Q&A)","docId":"Getting Started/FAQ/qa_issues","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsible":true},{"type":"category","label":"User Guides","collapsed":false,"items":[{"type":"category","label":"Configuration","items":[{"type":"link","href":"/ROLL/docs/User Guides/Configuration/config_guide","label":"Configuration Guide","docId":"User Guides/Configuration/config_guide","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/config_system","label":"ROLL Configuration System Detailed Explanation","docId":"User Guides/Configuration/config_system","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/deepspeed","label":"DeepSpeed Training Backend Configuration Guide","docId":"User Guides/Configuration/deepspeed","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/device_mapping","label":"ROLL Resource Configuration","docId":"User Guides/Configuration/device_mapping","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/fp8_rollout","label":"FP8 Quantization Configuration Guide","docId":"User Guides/Configuration/fp8_rollout","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/lora","label":"LoRA Fine-tuning Configuration Guide","docId":"User Guides/Configuration/lora","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/megatron","label":"Megatron Inference and Training Backend Configuration Guide","docId":"User Guides/Configuration/megatron","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/offpolicy_setting","label":"Off-Policy Algorithms Configuration Guide","docId":"User Guides/Configuration/offpolicy_setting","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/sglang","label":"SGLang Inference Backend Configuration Guide","docId":"User Guides/Configuration/sglang","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Configuration/vllm","label":"vLLM Inference Backend Configuration Guide","docId":"User Guides/Configuration/vllm","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Pipeline","items":[{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/agent_pipeline_start","label":"Comprehensive Guide: Using the Agentic Part of ROLL","docId":"User Guides/Pipeline/agent_pipeline_start","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/agentic_pipeline_start","label":"Agentic Pipeline","docId":"User Guides/Pipeline/agentic_pipeline_start","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/distill_pipeline_start","label":"Distill Pipeline","docId":"User Guides/Pipeline/distill_pipeline_start","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/dpo_pipeline_start","label":"DPO Pipeline","docId":"User Guides/Pipeline/dpo_pipeline_start","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/rlvr_pipeline_start","label":"RLVR Pipeline","docId":"User Guides/Pipeline/rlvr_pipeline_start","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Pipeline/vl_rlvr_pipeline_start","label":"RLVR Pipeline for VLM","docId":"User Guides/Pipeline/vl_rlvr_pipeline_start","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Algorithms","items":[{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/GRPO","label":"Group Relative Policy Optimization (GRPO)","docId":"User Guides/Algorithms/GRPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/GSPO","label":"Group Sequence Policy Optimization (GSPO)","docId":"User Guides/Algorithms/GSPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/LitePPO","label":"Lite PPO","docId":"User Guides/Algorithms/LitePPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/PPO","label":"Proximal Policy Optimization (PPO)","docId":"User Guides/Algorithms/PPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/RAFT_Plus_Plus","label":"RAFT++ (Reward rAnked Fine-Tuning)","docId":"User Guides/Algorithms/RAFT_Plus_Plus","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/Reinforce_Plus_Plus","label":"Reinforce++","docId":"User Guides/Algorithms/Reinforce_Plus_Plus","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/Reward_FL","label":"Reward Feedback Learning (Reward FL)","docId":"User Guides/Algorithms/Reward_FL","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Algorithms/TOPR","label":"TOPR (Tapered Off-Policy REINFORCE)","docId":"User Guides/Algorithms/TOPR","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Agentic","items":[{"type":"link","href":"/ROLL/docs/User Guides/Agentic/Tool_Use","label":"Tool Use Guide","docId":"User Guides/Agentic/Tool_Use","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Agentic/agentic_GiGPO","label":"StepWiseLearning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","docId":"User Guides/Agentic/agentic_GiGPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Agentic/agentic_StarPO","label":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","docId":"User Guides/Agentic/agentic_StarPO","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Agentic/agentic_engineer_practice","label":"Agentic Engineering Practice Documentation","docId":"User Guides/Agentic/agentic_engineer_practice","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Advanced Features","items":[{"type":"link","href":"/ROLL/docs/User Guides/Advanced Features/async_parallel_rollout","label":"Agentic Asynchronous Parallel Rollout","docId":"User Guides/Advanced Features/async_parallel_rollout","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Advanced Features/async_training","label":"ROLL Asynchronous Training User Guide","docId":"User Guides/Advanced Features/async_training","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Advanced Features/checkpoint_and_resume","label":"Checkpoint Saving and Resuming Guide","docId":"User Guides/Advanced Features/checkpoint_and_resume","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Advanced Features/megatron_convert_2_hf","label":"Converting MCoreAdapter Models to Hugging Face Format","docId":"User Guides/Advanced Features/megatron_convert_2_hf","unlisted":false},{"type":"link","href":"/ROLL/docs/User Guides/Advanced Features/offload_reload_control","label":"GPU Time-Division Multiplexing Control Guide","docId":"User Guides/Advanced Features/offload_reload_control","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Tracker & Metrics","items":[{"type":"link","href":"/ROLL/docs/User Guides/Tracker & Metrics/trackers_and_metrics","label":"Trackers and Metrics","docId":"User Guides/Tracker & Metrics/trackers_and_metrics","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Hardware Support","items":[{"type":"link","href":"/ROLL/docs/User Guides/Hardware Support/ascend_usage","label":"ROLL x Ascend","docId":"User Guides/Hardware Support/ascend_usage","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsible":true},{"type":"category","label":"Development","collapsed":false,"items":[{"type":"category","label":"Architecture","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ROLL/docs/Development/Architecture/AgenticPipeline","label":"AgenticPipeline","docId":"Development/Architecture/AgenticPipeline","unlisted":false},{"type":"link","href":"/ROLL/docs/Development/Architecture/RLVRPipeline","label":"RLVR Pipeline","docId":"Development/Architecture/RLVRPipeline","unlisted":false}]},{"type":"category","label":"Developer Guide","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ROLL/docs/Development/Developer Guide/support_new_models","label":"How to Add Support for a New Model","docId":"Development/Developer Guide/support_new_models","unlisted":false},{"type":"link","href":"/ROLL/docs/Development/Developer Guide/customer_env","label":"Customer Env","docId":"Development/Developer Guide/customer_env","unlisted":false},{"type":"link","href":"/ROLL/docs/Development/Developer Guide/prompt_intro","label":"Prompt Generation Guide","docId":"Development/Developer Guide/prompt_intro","unlisted":false}]}],"collapsible":true}]},"docs":{"Development/Architecture/AgenticPipeline":{"id":"Development/Architecture/AgenticPipeline","title":"AgenticPipeline","description":"Agentic Pipeline Architecture Diagram","sidebar":"tutorialSidebar"},"Development/Architecture/RLVRPipeline":{"id":"Development/Architecture/RLVRPipeline","title":"RLVR Pipeline","description":"RLVR Pipeline (Reinforcement Learning with Verifiable Rewards Pipeline) is a core component in the ROLL framework, specifically designed as an efficient distributed training pipeline for large language model reinforcement learning. Through virtual reward mechanisms, this pipeline can significantly improve LLM performance on key tasks such as complex reasoning, code generation, and mathematical calculations.","sidebar":"tutorialSidebar"},"Development/Developer Guide/customer_env":{"id":"Development/Developer Guide/customer_env","title":"Customer Env","description":"Reinforcement Learning Environment","sidebar":"tutorialSidebar"},"Development/Developer Guide/prompt_intro":{"id":"Development/Developer Guide/prompt_intro","title":"Prompt Generation Guide","description":"In the architecture of Large Language Model (LLM)-based Reinforcement Learning Agents, the Prompt serves as the sole medium for LLMs to interact with the environment. Unlike traditional agents that directly receive numerical states or output discrete action IDs, LLMs \\"perceive\\" the environment (observations) and \\"express\\" their decisions (actions) through prompts in text format.","sidebar":"tutorialSidebar"},"Development/Developer Guide/support_new_models":{"id":"Development/Developer Guide/support_new_models","title":"How to Add Support for a New Model","description":"To integrate a new model into ROLL, you must supply:","sidebar":"tutorialSidebar"},"Getting Started/Debugging Guide/debug_guide":{"id":"Getting Started/Debugging Guide/debug_guide","title":"ROLL Debugging Guide","description":"When developing and using the ROLL framework, debugging is an essential step. This document will introduce several effective debugging methods to help you quickly locate and resolve issues.","sidebar":"tutorialSidebar"},"Getting Started/FAQ/qa_issues":{"id":"Getting Started/FAQ/qa_issues","title":"Frequently Asked Questions (Q&A)","description":"This document compiles common issues that may be encountered when using the ROLL framework and their solutions.","sidebar":"tutorialSidebar"},"Getting Started/Installation/image_address":{"id":"Getting Started/Installation/image_address","title":"Image Provided","description":"We provide pre-built Docker images for a quick start (Links will be updated):","sidebar":"tutorialSidebar"},"Getting Started/Installation/installation":{"id":"Getting Started/Installation/installation","title":"Installation","description":"\ud83d\udc33 Install from Docker","sidebar":"tutorialSidebar"},"Getting Started/Quick Start/multi_nodes_quick_start":{"id":"Getting Started/Quick Start/multi_nodes_quick_start","title":"Quick Start: Multi-Node Deployment Guide","description":"Environment Preparation","sidebar":"tutorialSidebar"},"Getting Started/Quick Start/single_node_quick_start":{"id":"Getting Started/Quick Start/single_node_quick_start","title":"Quick Start: Single-Node Deployment Guide","description":"Environment Preparation","sidebar":"tutorialSidebar"},"Overview":{"id":"Overview","title":"Overview","description":"\ud83d\ude80 An Efficient and User-Friendly Scaling Library for Reinforcement Learning with Large Language Models \ud83d\ude80","sidebar":"tutorialSidebar"},"User Guides/Advanced Features/async_parallel_rollout":{"id":"User Guides/Advanced Features/async_parallel_rollout","title":"Agentic Asynchronous Parallel Rollout","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Advanced Features/async_training":{"id":"User Guides/Advanced Features/async_training","title":"ROLL Asynchronous Training User Guide","description":"The ROLL framework now supports asynchronous training for both RLVR and Agentic pipelines, significantly improving training efficiency. This document provides detailed instructions on how to use this feature.","sidebar":"tutorialSidebar"},"User Guides/Advanced Features/checkpoint_and_resume":{"id":"User Guides/Advanced Features/checkpoint_and_resume","title":"Checkpoint Saving and Resuming Guide","description":"In the ROLL framework, the checkpoint mechanism allows you to save the model state during training so that you can resume training when needed. This document will provide detailed instructions on how to configure and use the checkpoint saving and resuming functionality.","sidebar":"tutorialSidebar"},"User Guides/Advanced Features/megatron_convert_2_hf":{"id":"User Guides/Advanced Features/megatron_convert_2_hf","title":"Converting MCoreAdapter Models to Hugging Face Format","description":"MCoreAdapter provides tools for converting between Megatron(McoreAdapter) and Hugging Face model formats. This document will guide you on how to convert a trained Megatron model to Hugging Face format for use in other projects.","sidebar":"tutorialSidebar"},"User Guides/Advanced Features/offload_reload_control":{"id":"User Guides/Advanced Features/offload_reload_control","title":"GPU Time-Division Multiplexing Control Guide","description":"The ROLL framework implements GPU time-division multiplexing functionality, which allows flexible sharing of GPU resources between different roles through offload/reload capabilities. This document will provide detailed instructions on how to use this feature.","sidebar":"tutorialSidebar"},"User Guides/Agentic/agentic_engineer_practice":{"id":"User Guides/Agentic/agentic_engineer_practice","title":"Agentic Engineering Practice Documentation","description":"This document introduces the development practices of the Agentic component in the ROLL framework, including environment manager development protocols, GlobalDataset usage, validation mode configuration, and trajectory synthesis functionality.","sidebar":"tutorialSidebar"},"User Guides/Agentic/agentic_GiGPO":{"id":"User Guides/Agentic/agentic_GiGPO","title":"StepWiseLearning\u2014\u2014GiGPO (Group-in-Group Policy Optimization)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Agentic/agentic_StarPO":{"id":"User Guides/Agentic/agentic_StarPO","title":"TrajWiseLearning\u2014\u2014StarPO (State-Thinking-Actions-Reward Policy Optimization)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Agentic/Tool_Use":{"id":"User Guides/Agentic/Tool_Use","title":"Tool Use Guide","description":"Overview","sidebar":"tutorialSidebar"},"User Guides/Algorithms/GRPO":{"id":"User Guides/Algorithms/GRPO","title":"Group Relative Policy Optimization (GRPO)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/GSPO":{"id":"User Guides/Algorithms/GSPO","title":"Group Sequence Policy Optimization (GSPO)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/LitePPO":{"id":"User Guides/Algorithms/LitePPO","title":"Lite PPO","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/PPO":{"id":"User Guides/Algorithms/PPO","title":"Proximal Policy Optimization (PPO)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/RAFT_Plus_Plus":{"id":"User Guides/Algorithms/RAFT_Plus_Plus","title":"RAFT++ (Reward rAnked Fine-Tuning)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/Reinforce_Plus_Plus":{"id":"User Guides/Algorithms/Reinforce_Plus_Plus","title":"Reinforce++","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/Reward_FL":{"id":"User Guides/Algorithms/Reward_FL","title":"Reward Feedback Learning (Reward FL)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Algorithms/TOPR":{"id":"User Guides/Algorithms/TOPR","title":"TOPR (Tapered Off-Policy REINFORCE)","description":"Introduction","sidebar":"tutorialSidebar"},"User Guides/Configuration/config_guide":{"id":"User Guides/Configuration/config_guide","title":"Configuration Guide","description":"Pipeline Config","sidebar":"tutorialSidebar"},"User Guides/Configuration/config_system":{"id":"User Guides/Configuration/config_system","title":"ROLL Configuration System Detailed Explanation","description":"The ROLL framework adopts a structured configuration system that defines experimental parameters through YAML files. This document will provide a detailed introduction to ROLL\'s configuration design, helping new users understand the framework\'s configuration structure and extension methods.","sidebar":"tutorialSidebar"},"User Guides/Configuration/deepspeed":{"id":"User Guides/Configuration/deepspeed","title":"DeepSpeed Training Backend Configuration Guide","description":"DeepSpeed is Microsoft\'s efficient deep learning optimization library that provides memory optimization, distributed training, and performance optimization features. This document will provide detailed instructions on how to configure and use the DeepSpeed training backend in the ROLL framework.","sidebar":"tutorialSidebar"},"User Guides/Configuration/device_mapping":{"id":"User Guides/Configuration/device_mapping","title":"ROLL Resource Configuration","description":"In the ROLL framework, resource settings are specified through the device_mapping parameter in YAML configuration files to determine which GPU devices each worker uses. This document will provide detailed instructions on how to configure resources, including colocated and disaggregated modes, multi-role resource configuration, and how worker counts are calculated.","sidebar":"tutorialSidebar"},"User Guides/Configuration/fp8_rollout":{"id":"User Guides/Configuration/fp8_rollout","title":"FP8 Quantization Configuration Guide","description":"This document describes how to use FP8 quantization in ROLL to optimize inference performance and VRAM usage.","sidebar":"tutorialSidebar"},"User Guides/Configuration/lora":{"id":"User Guides/Configuration/lora","title":"LoRA Fine-tuning Configuration Guide","description":"LoRA (Low-Rank Adaptation) is an efficient parameter-efficient fine-tuning method that achieves parameter-efficient fine-tuning by adding low-rank matrices to pre-trained models. This document will provide detailed instructions on how to configure and use LoRA fine-tuning in the ROLL framework.","sidebar":"tutorialSidebar"},"User Guides/Configuration/megatron":{"id":"User Guides/Configuration/megatron","title":"Megatron Inference and Training Backend Configuration Guide","description":"Megatron is NVIDIA\'s large-scale language model training and inference framework that supports efficient distributed training and inference. This document will provide detailed instructions on how to configure and use the Megatron backend in the ROLL framework.","sidebar":"tutorialSidebar"},"User Guides/Configuration/offpolicy_setting":{"id":"User Guides/Configuration/offpolicy_setting","title":"Off-Policy Algorithms Configuration Guide","description":"The ROLL framework supports multiple Off-Policy algorithm variants for reinforcement learning training. This document provides detailed configuration methods and usage examples for various algorithms.","sidebar":"tutorialSidebar"},"User Guides/Configuration/sglang":{"id":"User Guides/Configuration/sglang","title":"SGLang Inference Backend Configuration Guide","description":"SGLang is a fast and easy-to-use inference engine, particularly suitable for inference tasks of large-scale language models. This document will provide detailed instructions on how to configure and use the SGLang inference backend in the ROLL framework.","sidebar":"tutorialSidebar"},"User Guides/Configuration/vllm":{"id":"User Guides/Configuration/vllm","title":"vLLM Inference Backend Configuration Guide","description":"vLLM is a fast and easy-to-use large language model inference library that efficiently manages attention key-value cache through PagedAttention technology. This document will provide detailed instructions on how to configure and use the vLLM inference backend in the ROLL framework.","sidebar":"tutorialSidebar"},"User Guides/Hardware Support/ascend_usage":{"id":"User Guides/Hardware Support/ascend_usage","title":"ROLL x Ascend","description":"Last updated: 11/25/2025.","sidebar":"tutorialSidebar"},"User Guides/Pipeline/agent_pipeline_start":{"id":"User Guides/Pipeline/agent_pipeline_start","title":"Comprehensive Guide: Using the Agentic Part of ROLL","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Pipeline/agentic_pipeline_start":{"id":"User Guides/Pipeline/agentic_pipeline_start","title":"Agentic Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Pipeline/distill_pipeline_start":{"id":"User Guides/Pipeline/distill_pipeline_start","title":"Distill Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Pipeline/dpo_pipeline_start":{"id":"User Guides/Pipeline/dpo_pipeline_start","title":"DPO Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Pipeline/rlvr_pipeline_start":{"id":"User Guides/Pipeline/rlvr_pipeline_start","title":"RLVR Pipeline","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Pipeline/vl_rlvr_pipeline_start":{"id":"User Guides/Pipeline/vl_rlvr_pipeline_start","title":"RLVR Pipeline for VLM","description":"Table of Contents","sidebar":"tutorialSidebar"},"User Guides/Tracker & Metrics/trackers_and_metrics":{"id":"User Guides/Tracker & Metrics/trackers_and_metrics","title":"Trackers and Metrics","description":"The ROLL framework supports multiple experiment tracking tools to help you monitor and analyze the training process. This document will provide detailed instructions on how to configure and use these trackers.","sidebar":"tutorialSidebar"}}}}')}}]);